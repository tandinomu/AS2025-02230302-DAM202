{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2530a5fc-e6a7-4074-b6cf-21f700a87a7b",
   "metadata": {},
   "source": [
    "## **0. Change working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20e74ec7-71aa-4bcc-b42d-e59effea371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/Users/macbookairm4chip/Desktop/DAM202/Practical2\" # Your Working Directory\n",
    "import os\n",
    "os.chdir(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba58cf-a68f-4625-a163-d964c51134c2",
   "metadata": {},
   "source": [
    "- Set up working directory for the practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3a36453-f776-46f9-8f04-c1e6e77a2ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['optimized_alice_word2vec.model',\n",
       " 'bin',\n",
       " 'Untitled.ipynb',\n",
       " 'include',\n",
       " 'etc',\n",
       " 'pyvenv.cfg',\n",
       " 'my_word2vec_model.model',\n",
       " 'cbow_word2vec_model.model',\n",
       " 'lib',\n",
       " 'text.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'share']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd4f3c-5316-4ce6-9267-cfe9ab2e6ece",
   "metadata": {},
   "source": [
    "- Lists all the files and folders in the directory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8aad9",
   "metadata": {},
   "source": [
    "## **1. Introduction**\n",
    "\n",
    "### **1.1 Need for Data Feed**\n",
    "\n",
    "While pretrained models like Google News Word2Vec are powerful, training our own model offers several advantages:\n",
    "\n",
    "* **Domain Specificity**: Captures terminology and relationships specific to our field (medical, legal, technical)\n",
    "* **Custom Vocabulary**: Includes words and phrases unique to your dataset\n",
    "* **Control**: Full control over training parameters and data quality\n",
    "* **Privacy**: No need to rely on external models for sensitive data\n",
    "* **Learning**: Deep understanding of how Word2Vec actually works\n",
    "\n",
    "### **The Neural Network Architecture**\n",
    "\n",
    "Word2Vec uses a simple neural network with three layers:\n",
    "\n",
    "* **Input Layer**: One-hot encoded word vectors\n",
    "* **Hidden Layer**: Dense representation (the embeddings we want)\n",
    "* **Output Layer**: Probability distribution over vocabulary\n",
    "\n",
    "### **1.2 CBOW vs Skip-gram Training**\n",
    "\n",
    "#### **CBOW (Continuous Bag of Words):**\n",
    "* **Input**: Context words → **Output**: Center word\n",
    "* **Example**: [\"the\", \"cat\", \"on\", \"mat\"] → \"sat\"\n",
    "* **Advantages**: \n",
    "  - Faster training\n",
    "  - Better for frequent words\n",
    "  - Good for syntactic relationships\n",
    "\n",
    "#### **Skip-gram:**\n",
    "* **Input**: Center word → **Output**: Context words\n",
    "* **Example**: \"sat\" → [\"the\", \"cat\", \"on\", \"mat\"]\n",
    "* **Advantages**:\n",
    "  - Better for rare words\n",
    "  - Excellent for semantic relationships\n",
    "  - Slower training but higher quality\n",
    "\n",
    "## **2. Training Objectives**\n",
    "\n",
    "The model learns by:\n",
    "* **Maximizing** probability of actual word pairs that appear together\n",
    "* **Minimizing** probability of random word pairs (negative sampling)\n",
    "* **Adjusting** word vectors to achieve these objectives\n",
    "\n",
    "### **2.1 Key Training Concepts**\n",
    "\n",
    "#### **Context Window**\n",
    "Number of words around target word to consider:\n",
    "* **Small window (2-3)**: Captures syntactic relationships\n",
    "* **Large window (5-10)**: Captures semantic/topical relationships\n",
    "\n",
    "#### **Negative Sampling**\n",
    "Instead of computing probabilities for entire vocabulary, sample a few \"negative\" examples:\n",
    "* Dramatically speeds up training\n",
    "* 5-20 negative samples typically used\n",
    "\n",
    "#### **Hierarchical Softmax**\n",
    "Alternative to negative sampling using binary tree structure:\n",
    "* Better for rare words\n",
    "* More memory efficient for large vocabularies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7eaa0-da4b-46d8-996d-caf64c2882d9",
   "metadata": {},
   "source": [
    "### **3.1 Data Collection and Preparation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc1677f0-0455-4940-aba4-7ee949fa4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'r', encoding='utf-8') as f: # Remember your data set path should be specified if not in same working directory\n",
    "    texts = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7b6bb-9345-4beb-b23b-60e78414f247",
   "metadata": {},
   "source": [
    "What it does:\n",
    "\n",
    "- Opens the Alice in Wonderland text file\n",
    "- Reads every line from the file\n",
    "- Puts all those lines into a list called texts\n",
    "- Each line becomes one item in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3c63e03-2287-4d27-b3dc-a1e26dae6457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"                ALICE'S ADVENTURES IN WONDERLAND\\n\",\n",
       " '\\n',\n",
       " '                          Lewis Carroll\\n',\n",
       " '\\n',\n",
       " '               THE MILLENNIUM FULCRUM EDITION 3.0\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '                            CHAPTER I\\n']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf439553-be73-4a83-847e-48cc4a905188",
   "metadata": {},
   "source": [
    "### **3.2 Data Quality Assessment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "422f43ec-d649-46af-a81a-245970d1f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 3,598\n",
      "Vocabulary size: 4,950\n",
      "Unique Words: {'hedgehogs;', \"extras?'\", 'turkey,', 'feeble,', \"shouldn't\", \"i--'\", 'labelled', 'sneezed', '`because', 'king', 'soothing', \"is--'\", 'their', 'ring,', \"nonsense!'\", \"answer?'\", '\"much', \"sir,'\", '(with', 'character,', 'bank,', 'rapidly;', 'turtle:', 'accidentally', 'morning,', \"stay!'\", \"`shan't,'\", \"toes?'\", 'herself,', '`this', 'parchment', \"`she'd\", \"stuff,'\", \"is,'\", 'peering', 'me!', '`for', 'queer-', 'form', \"done.'\", 'melancholy', 'thinking', \"hot-tempered,'\", \"trial.'\", 'like,', 'conversation.', 'shaped', 'writhing,', 'a-piece', \"pleases!'\", 'sea,', \"mind,'\", 'course--', 'lives.', 'lest', 'promising,', 'escape', 'tasted', 'bird', 'hedgehog', 'cheeks,', \"we've\", 'beasts,', 'sharply.', 'till', 'waited', 'how', 'join', 'officers', 'mushroom', \"asleep,'\", 'farm-yard--while', 'pleaded', 'pulling', \"again!'\", 'invited', 'scream', \"caucus-race.'\", 'round,', 'yesterday,', 'able!', 'loudly', 'opened', 'shakespeare,', 'answered', 'smile:', '`did', 'adventures', 'upstairs,', 'night', 'glaring', 'miles', 'joined):--', 'friend.', 'when', 'two,', 'bright', 'dream,', '`nor', '\"up', 'not', 'balls', 'further', 'hatching', 'porpoise?\"\\'', 'things--i', 'fan', 'mouse--a', 'branches,', 'inquisitively,', 'after-time,', '`at', '`--change', \"attending!'\", 'be\"--or', 'nose.', 'tortoise', 'crying', 'leaves,', 'flown', 'goldfish', 'feeling', 'flamingo.', 'move', 'machines', \"grin.'\", '`--it', 'encouraged', 'nibbled', 'speaking', \"enough.'\", \"`idiot!'\", 'sluggard,\"\\'', 'uneasily', 'doorway;', \"me?'\", '`cheshire', 'ii', 'loveliest', 'you--all', 'suppressed.', 'hastily', 'banks,', 'cannot', 'see:', 'tea-things', 'adventures--beginning', \"didn't,'\", \"draw?'\", 'pause:', 'out,', 'uncommonly', 'sight', \"stupid?'\", 'deepest', 'happy', 'ridge', 'one,', 'jumped', 'waiting', 'learned', 'prize', 'shifting', 'shape', 'shoulder,', 'sell', \"way?',\", 'rabbit.', 'soldiers', \"m?'\", 'dodo,', '`go', 'purple.', \"instead!'\", 'justice', 'ordering', 'wink', \"`yes,'\", 'else\"--but,', 'position', \"to.'\", 'feebly', \"trying.'\", '`can', '`get', 'juror', \"muchness?'\", 'longer', '`any', '(not', 'ask!', \"`treacle,'\", '`yes,', \"dear?'\", 'garden.\"\\'', 'one;', 'funny', 'trotting', 'finished', \"were,'\", 'managing', 'excellent', \"head!'\", 'pebbles', '`write', \"fact.'\", 'finishing', 'beasts', 'earth.', 'twenty', 'he', 'say.', 'clapping', 'it;', '`behead', \"tea,'\", 'buttons,', 'rules', 'printed', 'conversation', 'pity.', 'find', \"shorter.'\", 'wood', 'out', \"then.'\", 'hopeless', \"from,'\", 'place', \"knot!'\", 'growing', 'names', 'curly', 'mournful', 'bristling', 'whisper,', 'fit)', 'happened,', \"dreadful,'\", 'tea--not', 'too:', 'moment:', 'bit.', \"dance,'\", '`how', 'thought', 'eagerly,', 'yours:', 'search', 'uncomfortable,', \"now,'\", 'once.', 'words', 'thought,', 'either,', 'hour', 'beginning', 'uncomfortable.', \"lesson-books!'\", 'floor:', 'caused', 'flame', 'sang', 'is,', 'contemptuously.', 'seen:', \"breathe.'\", 'magic', 'bad,', 'old', 'locks,', 'guard', 'side,', 'happen:', \"case,'\", 'poor', 'climb', 'curtain', 'riddles.--i', 'written', 'voice.', 'whispers', 'duchess:', 'questions,', 'grin', \"guilt,'\", '`suppose', 'sight:', 'evidence', \"then?'\", 'together,', \"that,'\", 'executioner,', 'eye;', 'goes', 'seated', 'stupidest', 'tale,', 'day', 'conclusion,', 'knowledge.', 'buttered', 'tears!', \"time!'\", 'trees', 'cat.)', 'sent', 'uglify', 'brave', \"chimney!'\", 'stamping', 'country', \"places!'\", 'own.', 'lessons:', 'said,)', 'sight,', '`now,', 'together.', 'pie', 'mabel,', 'middle.', 'teacup', 'you,', 'fun', 'glanced', 'denial;', \"quadrille?'\", 'longitude', 'difficult', 'pepper', 'helpless', '`sure', 'saying,', '(`i', 'set', \"alice's,\", 'involved', '(and,', \"see.'\", \"do?'\", \"size,'\", 'side', 'here!', \"verses.'\", 'sneeze', \"execution.'\", \"`that's\", 'spoken', 'rate!', \"crumbs.'\", \"figures!'\", 'court', 'gravy,', 'angry,', 'puppy', 'alice,)', 'distraction,', '(`the', 'ever;', \"`what's\", \"witness.'\", '`talking', 'variations.', 'nose;', 'cunning', 'next!', 'small', 'eyes.', \"much,'\", 'wonderful', \"meant,'\", 'first--they', 'thought.', \"they'll\", \"bats?'\", 'wood.', 'humbly:', \"ma!'\", 'yer', 'understand', '`not', 'these', 'vanished', 'gather', \"one.'\", 'sharp', '(and', \"go,'\", 'as,', 'tide', 'round', 'instead', 'everything', 'dears?', \"axes,'\", 'doubt', 'anxious', 'pine-apple,', 'gravely,', 'suppose,', 'that;', 'behind', 'near', 'footsteps,', 'mine', 'terribly', 'uncommon', 'sounded', \"first.'\", 'hippopotamus,', 'forehead', \"dinah'll\", 'flamingoes,', '`stupid', 'sigh:', 'better', 'low,', 'to--to', \"needn't\", \"lower,'\", 'live.', \"say!'\", '`oh!', 'flustered', 'many', 'unlocking', 'choking', 'not,', 'purring', 'treat.', 'asking', 'touch', 'tea.', 'denying', 'today.', 'viii', 'sharply,', '`\"we', '`no', 'subject!', 'beast,', 'spectacles', \"moment!'\", 'white;', \"lines!'\", \"`don't\", 'unjust', 'grass', 'footmen,', \"oyster!'\", 'twinkle,', 'sometimes', 'box', 'taken', 'sleepy', 'right,', 'ornamented', 'waving', 'knocking,', \"finished,'\", 'triumphantly,', 'sister;', 'sir,', 'lately,', 'mouse--of', 'hint;', \"growing.'\", 'strange,', 'ledge', 'day!', 'yelp', 'you', 'silent.', \"`hadn't\", 'ear,', \"concert!'\", 'little', 'is--\"be', 'xi', \"that'll\", 'another!', \"things?'\", 'hare:', 'fountains.', 'cat:', 'comfortably', 'dormouse.', 'bat,', '\"uglification,\"\\'', 'frightened', '`shall', 'delight,', 'rock,', 'presents', \"`let's\", 'minded', \"queen?'\", 'generally', 'talk:', \"executioner's\", 'run', 'cards:', 'here,', 'flapper', \"little!'\", \"`i'd\", 'cucumber-frames', 'kid', 'jogged', 'gryphon;', 'it!', 'somersault', 'learn', \"in?'\", \"see!'\", \"doing?'\", 'graceful', 'softly', 'flinging', 'appear,', 'northumbria,', 'speak', 'pat,', 'dripping', 'digging', \"ever,'\", \"not.'\", 'pattern', \"rate,'\", 'knife,', 'wash', 'generally,', 'chorus.', 'growing,', 'delight', 'sight;', \"business?'\", 'go!', 'watched', 'dormouse:', 'sort', 'seven.', 'fond', 'sisters--they', 'are,', 'leading', 'ferrets!', 'hookah', '`herald,', 'atheling', 'paws!', 'knelt', 'paw,', 'up,', 'blown', 'cool', 'down:', 'deep,', 'continued', '`as', 'visit', 'growls', '`was,', 'hurry:', \"said,'\", '(for', 'waste', 'remember', 'est', \"feet!'\", \"different!'\", \"alive!'\", 'raising', \"shoes!'\", 'time.', '`so', 'place,', 'scroll,', 'reply.', 'signed', 'thousand', \"weren't\", 'thin--and', 'examining', 'say,', 'they', 'noises,', 'agree', \"caucus-race?'\", \"a--i'm\", '`living', 'then;', 'subdued', 'before', \"certainly,'\", 'watching', 'sends', 'courage.', 'shelves', 'voice:--', 'queen.', \"evidence,'\", 'say', 'dreamy', 'this:', 'snatch', 'accounting', \"nose';\", 'doubt:', '`why', 'savage', 'did:', 'tried', \"treacle-well.'\", 'trims', 'tone', 'work,', 'vague', 'free,', 'thistle', 'mouths.', 'furrow', 'queer,', 'animal', 'two:', 'front', 'mark', 'am!', 'anything,', 'executioner:', 'wood,', 'his', 'crown.', 'dodo.', 'silent', 'nobody', 'exact', 'something;', 'downwards,', 'brass', 'meat,', 'again,', 'through', 'little,', 'line:', \"weeks!'\", '`two', 'pack', 'was,', 'muchness--', 'yet--and', 'listening,', 'hot', 'plate', 'something', \"thimble,'\", 'grew', 'slate--oh,', 'now,', 'nasty,', \"suppose.'\", 'narrow,', 'tremble.', \"twinkle--'\", 'wore', 'nothing:', 'foot', 'chief', 'busy', 'taller,', 'porpoise,', '\"come', 'words,', '`let', 'push', 'home;', 'happened.', 'farmer,', \"mad.'\", 'farther', 'croqueted', 'ugh,', 'race-course,', 'camomile', '`look', 'saw.', \"won't\", 'fading', 'beautiful,', 'certainly', 'regular', \"`well!'\", \"to-day?'\", 'wag', 'round!\"\\'', 'trouble,', 'account', 'and,', 'win,', 'table', 'remarked', 'swam', 'worse.', '`their', 'temper,', 'it.)', 'crocodile', '\"he\\'s', 'finished,', 'something,', '(for,', \"serpent?'\", 'subject', 'eye,', 'managed?', 'shade:', 'mushroom,', 'accounts', 'please', 'own', '\"french,', \"she's\", 'history,', 'cat!', 'once:', \"think!'\", 'way.', 'wood--(she', 'yet,', 'though.', 'chanced', 'timidly,', 'proves', 'father,', 'name,', 'remarked.', 'safe', 'nice', 'shore.', 'heads.', 'returned', 'last,', 'by', 'shall', 'history', 'violently', 'condemn', 'free', 'minding', 'station.)', 'gryphon,', \"afraid,'\", '`drink', 'pocket)', 'listened,', \"everything's\", 'easily', 'him,)', 'real', 'exclaimed,', 'creatures,', 'jury,', 'plainly', \"croquet?'\", '`call', \"king,'\", 'itself', 'tired', 'waistcoat-pocket,', '`--and', 'pleasure', 'themselves', 'blew', 'remembering', 'obliged', 'else', 'boldly:', 'mark;', \"all.'\", 'wonder', 'year', 'carefully,', 'nurse--and', 'conqueror,', '`sit', 'any.', 'immense', 'that,', 'suddenly:', 'effect', 'pigs,', 'alice', \"lobsters!'\", 'writing', 'hall;', 'talk', 'knot,', 'hot,', 'leaves.', 'yours.\"\\'', 'contemptuous', 'boon,', 'next', 'disagree', \"like?'\", 'always', 'frying-pan', 'trusts', 'wherever', 'forepaws', 'deep', 'must,', \"majesty?'\", 'rosetree;', 'times', 'it', '`a', 'live', 'scrambling', 'received', 'course', 'roast', 'happened.)', 'flamingo', 'tea-time.', \"'tis\", 'clock', '\"--said', 'queer', 'fellow!', 'stop', 'globe', 'child:', 'downward!', 'tunnel', \"queen,'\", 'fire-irons', 'croqueting', 'angry', 'fact,', 'made', \"back!'\", 'bathing', \"wonder?'\", \"then!--bill's\", 'otherwise.\"\\'', '`nine', 'and--oh', 'stoop?', 'snail,', 'legs', 'escape,', 'belt', 'lap', 'books,', 'flat', 'remembered', 'getting', 'treading', 'undo', '`ou', 'arms', 'livery,', 'race', 'bone', 'growl', \"fellow?'\", 'quiet', 'beloved', \"find?'\", 'glad', 'want', 'little.', 'pale,', 'breath,', 'our', 'mice', 'curious,', \"`very,'\", \"life!'\", \"plan!'\", 'explanation;', \"animal's\", \"far,'\", 'passing', 'snappishly.', 'sign', 'at', \"time.'\", 'taller', 'roared', 'whom', \"to-day.'\", 'more:', \"`you'd\", 'precious', 'temper', 'execute', 'trial', 'reply', 'now!', 'tongue,', 'around', 'height', 'way,', 'law,', 'girls', 'kings', \"think,'\", 'invented', 'boots', 'slightest', 'canterbury,', 'that?--it', 'dare', \"said--'\", 'myself,', \"here?'\", 'execution.', 'politely', 'tones', 'answer.', 'taste', 'pool--she', 'show', 'impatiently:', 'ago', 'sleep\"', 'again.)', 'shillings', 'exclaimed', 'hedgehog,', 'for?\"\\'', 'fat;', 'deal', 'outside,', 'mouse--to', 'gryphon', 'spectacles.', 'pool?', 'mean', \"shan't!\", 'her;', \"child?'\", \"see,'\", 'trying,', 'hard', '(or', 'no,', 'desperate', '\"coming', 'creep', 'knave.', 'lost:', 'across', 'it),', 'and', \"`no,'\", 'must', \"are,'\", 'noticed,', 'crab,', \"others!'\", 'in:', 'reason,', 'custard,', 'end,', 'below', \"`i'm\", 'mentioned', 'afterwards,', 'choked', 'ground', 'allow', 'sorrow,', 'readily:', 'song', 'several', 'head--brandy', 'anger,', 'oh,', \"water-well,'\", 'mouse:', 'directly.', 'noticed', \"say--that's\", 'locks', 'on:', \"over!'\", 'listen,', 'fainting', 'stuff', 'personal', 'days.', \"ground.'\", \"direction,'\", 'towards', 'english', 'uncomfortable', 'grammar,', 'length', 'procession', 'mouse?', \"somebody.'\", \"dormouse,'\", \"coward!'\", 'soft', 'alice.', 'feelings.', \"is.'\", 'truthful', 'respectful', 'sleep', \"game's\", 'asking!', 'placed', 'completely.', 'unhappy.', 'panting,', 'seaography:', 'hastily.', 'ever', 'liked', 'good-bye,', 'green', '`in', 'neither', 'tucked', 'disappeared.', '\"such', 'messages', 'shark,', 'alice)--', 'hoped)', 'present', \"court!'\", 'jury-box', 'learning', 'waited.', 'fact', 'flock', 'moral,', \"this,'\", 'repeated', \"partner!'\", 'punished', \"i!'\", \"duchess's\", \"begun.'\", 'declared', \"with?'\", 'toast,)', 'severely.', 'words:', 'tone.', 'nowhere', 'with;', 'zigzag,', 'crown', 'lowing', 'fills', 'seems', 'rose-tree,', 'sense,', 'paris', 'man,', 'cross-examine', 'guinea-pigs,', 'invent', \"talk,'\", 'explain', 'out-of-the-way', 'happens;', \"you'll\", 'pitied', 'william', 'kitchen.', 'sides', 'crawled', 'morals', 'head,', 'flower-pot', 'over)', \"sorrow?'\", \"crazy!'\", 'whiting.', '`either', 'indeed.', 'twelve?', 'grunted,', 'hare,', 'woman--', 'about.', 'throwing', 'hide', 'laughed', 'pulled', 'mistake', \"queen!'\", \"suppose?'\", '`up,', 'fairy-tales,', 'arches.', 'largest', 'impatient', 'severely', '`twenty-four', 'beating.', 'fancy,', '`what!', 'face', 'quarrelled', 'suddenly', 'neatly', 'uncorked', 'sneezing,', 'exclamation', 'of', \"too,'\", 'then--i', 'simply', 'ear', 'idea', 'silence:', \"hadn't\", 'feared', 'eel', 'mad.', 'soup.', \"'em\", 'offended.', 'plan', 'processions;', 'all', 'shining', 'claws', \"was,'\", 'interrupted,', 'buttercup', 'lark,', 'hungry', 'honour:', 'telescope', 'nice,', 'bread-and-butter.', '`read', \"simpleton.'\", 'in.', 'hiss', 'bit', 'present--', 'hours,', 'tree.', \"true,'\", 'chose', \"you?'\", 'cause,', 'wandering,', 'hastily;', 'gazing', \"bite,'\", 'promised', \"little,'\", 'moved.', 'appeared', 'handed', 'remarked;', 'eyes', 'is', 'barrowful', 'having', 'nervous', \"`there's\", 'air.', '`no,', 'sun.', \"one?'\", 'half-past', 'swim', '\"keep', 'tone;', 'crossly:', 'few', 'to', 'garden', 'shiver.', \"fashion.'\", \"where.'\", 'cheered.', 'conversations', 'limbs', 'rather', 'teapot.', 'rapped', 'questions.--how', \"so,'\", 'tight', \"must,'\", \"throat,'\", 'cup', 'remarked:', 'threw', \"so.'\", 'chimney', 'think', 'dance', 'usual', \"bit,'\", 'jack-in-the-box,', 'resting', 'small.', 'entirely', 'rabbits.', 'eating', 'grins', 'impatiently,', 'heap', \"derision.'\", 'below,', 'daughter', 'dreaming', 'considered', \"conversation?'\", 'morcar,', 'wonderland', 'time.)', 'kills', \"wouldn't\", 'experiment', 'drive', 'rose', \"(`that's\", \"didn't\", 'deeply.', 'child', 'before.', '`everybody', \"bit!'\", 'turtle', 'nurse!', \"one,'\", 'carried', 'burning', 'first,', 'clamour', 'counting', 'rearing', 'yawning.', 'though', 'forgot', 'tone,', \"home,'\", '`boots', 'knowledge', 'pleased,', \"king's\", '`change', 'doubling', 'pigs', 'educations--in', 'listen.', \"sing,'\", 'memory,', 'stood', 'lory,', \"writing-desk?'\", 'proceed.', 'writing-desks,', 'lifted', \"serpent!'\", 'wind,', 'entangled', 'child,', 'kitchen', 'aloud.', 'my', '`sentence', 'picked', 'appearance', 'keeping', 'does,', 'shrimp', \"man,'\", 'knife', 'voices--`hold', 'otherwise,', 'catch', 'walked', \"croquet.'\", 'frog-footman', 'old,', 'die.', 'talking:', \"remember,'\", 'know.', \"kind,'\", 'summer', 'eat\"', 'duck:', 'cautiously', '`really,', 'queen:', 'dropped', 'dodo', \"rabbit's\", '`only,', \"child,'\", \"this!'\", 'turtle,', 'raven', 'feeble', 'was', '`oh,', 'speech,', 'me?', \"yet?'\", \"ordered';\", 'distance,', 'chimneys', 'coming.', \"ma'am,\", '(the', 'prisoner', 'attending', 'hedge.', 'shrieked', 'hurrying', '\"with', \"it--'\", 'became', '\"turtle', \"me,'\", 'thing', \"wrong!'\", 'within', 'nicely', 'chrysalis--you', 'head', \"sort,'\", 'soo--oop', 'tail,', 'paws', 'butterfly,', 'bat!', 'effect,', 'other.', 'yesterday', \"t!'\", 'trumpet,', 'grey', 'swim,', 'delightful', 'eager', 'attempt', \"order,'\", 'surprise.', 'rabbit', 'reeds--the', '\"too', 'annoy,', '`--yes,', 'verse', \"mind.'\", 'sage,', \"you,'\", 'tied', 'plenty', 'not.', 'uncomfortably', 'chimney?--nay,', \"say.'\", 'from', 'stretching', 'smile.', \"answers.'\", 'however,', \"you'd\", 'kettle', \"present!'\", 'size,', 'blacking,', 'tea-party', 'shook', 'natural', 'life;', '`\"will', 'replied,', \"here.'\", \"down!'\", 'what?', \"mine.'\", 'shedding', 'roses', '`fury', 'zealand', 'it.', \"story,'\", 'broken', 'wept', 'rush', \"usual,'\", 'pig-baby', 'schoolroom,', 'were', 'salt', \"creatures,'\", 'sound', 'done', 'go.', 'mouse,', 'spread', 'flower-beds', 'said:', 'notion', 'gave', 'found:', 'overcome', 'king.', 'delay', 'drop', 'bottle.', 'listen', 'head:', 'eats', 'could!', 'besides,', \"pardon!'\", 'latitude', 'decidedly,', \"hasn't\", 'tea', \"sea,'\", 'creatures', 'kiss', 'belong', 'blame', 'air:', 'languid,', 'foot.', 'hated', 'face,', '\"let', '(a', 'suddenly,', \"he's\", 'ran;', \"mad?'\", \"know,'\", 'to-night,', 'tarts?', \"day,'\", 'possible', 'all,', 'dreadful', 'in', 'curious', 'arches', 'eyes.--`tell', 'lock,', 'say.)', 'all!', 'pictured', 'sink', '\"purpose\"?\\'', 'exclaimed.', 'also', 'end', 'themselves.\"\\'', 'ix', 'brain;', 'together', 'courtiers,', \"`she's\", 'vii', 'box--', 'call', 'crash)--`now,', 'ink,', 'gay', 'lastly,', 'assembled', \"question?'\", 'relieved', \"fig?'\", '`there', 'comfortable,', \"grunt,'\", 'oldest', \"indeed!'\", \"heads!'\", 'would', '(before', 'questions', 'sneezes;', 'answered,', '`sure,', 'turtle.', 'spectacles,', '`rule', 'pretty', 'him!', 'fashion,', 'tells', \"sell,'\", 'fix', \"ears--'\", 'hers', 'door.', 'but,', 'on', 'chance', 'things--everything', 'slate-pencil,', 'ringlets,', 'wrote', 'manner,', '`pray', 'guess', 'cried.', 'ways', 'it?)', \"twelfth?'\", 'things,', 'cartwheels,', \"cakes,'\", 'disappeared;', 'chorus,', 'all;', 'birthday', 'adventures,', 'instantly,', 'round.', 'half', 'shriek', 'depends', 'tie', \"likes.'\", 'curls', 'years,', 'currants.', 'cart-horse,', 'tremulous', 'question,', \"pig,'\", 'nothing', 'least--at', 'high', 'thimble,', 'duchess.', 'already', 'bank--the', 'mice--oh,', 'toss', 'lives', 'offended,', 'pointed', 'merely', 'matters', 'dropped,', 'age', \"`yes!'\", \"more.'\", 'led', 'games', 'decided', 'son,', 'acceptance', 'rightly', 'royal', 'footsteps', \"business!'\", 'looking', 'handsome', \"bat?'\", 'miss,', 'arguments', 'there,', 'carry', 'awfully', 'like', 'laugh;', 'concert', 'rudeness', \"do!'\", 'ought', 'be', 'usurpation', 'spite', 'confusing', 'get\"', 'lory', 'fitted!', 'offer', 'five.', \"dogs.'\", \"`fifteenth,'\", 'rushed', '(it', \"haven't,'\", 'is--oh', 'life.', 'mabel!', 'marked,', 'accident,', 'foot!', 'entrance', 'move.', 'grow', 'down!', 'other;', 'mouse-traps,', 'dish?', 'child;', \"finished.'\", \"rabbit'\", \"tongue!'\", 'rome,', 'high,', \"beginning!'\", 'tarts', 'throw', 'keep', 'swim.', 'dried', \"`moral,'\", 'stole', 'advise', 'ringlets', \"witness,'\", 'going,', \"any,'\", 'series', 'leaves', 'five!', \"`i--i'm\", 'thing.', '`--but', 'curtsey', 'older', 'someone', '(pointing', 'here;', 'share', 'lay', 'stoop', 'wandered', 'sand', 'inkstand', 'know--and', \"carrier,'\", '`right,', 'lobster;', \"important,'\", 'injure', 'shrieks,', 'bats?', \"honour!'\", \"pocket?'\", 'stigand,', 'home', 'close,', 'going', 'listeners', 'dear', '`one', 'secret,', 'insult', 'leaders,', 'circumstances.', '`\"--found', 'queerest', 'usual,', 'mabel', \"pace,'\", 'daresay', 'passed', 'off;', '`nobody', \"names,'\", 'think!', \"holiday?'\", 'become', 'stiff.', 'birds', 'question', \"getting!'\", 'at!\"', \"`stolen!'\", \"axis--'\", 'hoarse', 'if', 'pink', 'inside,', 'meal,', '`hand', 'direction', '`just', \"history,'\", 'under', 'had', \"yet--it's\", \"part.'\", 'moving', 'key;', 'shouted', 'distance.', 'dears!', 'croquet', 'seriously,', \"they'd\", \"works!'\", 'earnestly.', 'jury', 'company', 'voices', '`consider,', 'go', 'though),', 'neat', 'she', 'case', 'extremely', 'reading,', 'came', 'calling', '`who', 'shut', 'five', \"this?'\", \"no!'\", '\"there\\'s', \"dormouse's\", 'wondered', '`serpent,', \"mouse's\", '`mine', 'rule', '`they', \"to?'\", '(we', 'sea.', 'sobs.', 'advice,', 'gallons', \"then,'\", 'size:', \"afterwards.'\", 'chin.', 'nonsense', 'honest', 'dry,', 'paws.', 'asleep,', 'inches', 'now?', 'twelve', 'ready', \"proceed,'\", 'slates.', 'contradicted', 'have', \"warning,'\", 'audibly.', 'steam-engine', 'luckily', 'play', 'slipped', 'replied', 'bite.', 'missed', 'surprise', 'alice!', 'fanning', 'bore', 'wide,', 'dormouse;', \"well,'\", 'great', 'roughly', 'fur', 'simply--\"never', '`seals,', 'knows', '`--well', 'second', 'faster', \"perhaps,'\", '`seven', 'violent', \"behind?'\", 'ground,', 'doing', 'encourage', 'changing', 'sleepy,', 'noticing', 'pointing', 'fish)--and', 'you.', \"i'll\", 'ran.', 'one', 'list,', 'sensation', 'supple', 'tureen!', \"dogs?'\", \"treacle,'\", \"mouse!')\", 'incessantly', 'good,', 'for', 'drowned', 'further:', 'rat-hole:', 'arithmetic--', 'do:', 'trouble', '`perhaps', 'silence', 'asked', \"they've\", 'done.', 'talking', 'eagerly', 'delighted', 'mind,', 'bent', 'pinched', 'until', 'gardeners,', 'label', \"he'll\", 'fish-footman', 'tinkling', '`bring', \"tomorrow--'\", 'sour--and', 'insolence', \"believe.'\", \"really?'\", 'most', 'certain!', 'perhaps', 'enormous', 'still', 'introduce', \"porpoise.'\", 'rome--no,', 'pronounced', 'cucumber-frame,', \"onions.'\", \"think.'\", 'eaten', 'asked.', 'brought', 'washing', 'finger,', 'coaxing', 'home!', 'flying', 'shake', 'consultation', 'started', 'herself;', 'barking', '`it', 'arch', 'morning', 'flurry', 'him;', 'chapter', 'cook', 'ordered', 'others.', 'break', \"down,'\", 'rabbit-hole', \"washing?'\", 'it:', 'applause,', \"is!'\", 'ann,', 'book,', 'voice--the', 'hatter.', 'gloomily:', 'doubtfully,', 'lesson', 'first;', 'eyes;', 'up:', 'bound', 'caterpillar;', 'left', 'commotion', \"lady,'\", 'judge,', 'think,', 'arm,', 'manage', 'signifies', 'appearing', 'thoughtfully:', 'duchess;', 'back,', \"beginning,'\", 'difficulty', 'went,', 'imitated', 'then--always', \"morning,'\", \"on.'\", 'away.', 'slate.', 'longed', 'hopeful', 'began:', 'last:', \"tea--'\", 'aloud,', 'snail.', 'wild', \"adventures.'\", 'gloves.', 'been.', 'was:', 'question.', \"day.'\", 'solemnly.', 'squeezed', 'week', \"didn't!'\", \"about!'\", \"that's\", 'went', 'rose-tree', 'sleepy;', '`silence', 'hunting', 'story', 'lasted', 'new', 'geography.', 'showing', \"better';\", 'shrill', 'spoke;', 'row', '`may', '(luckily', 'altogether', 'dinah,', 'garden,', 'given', 'occurred', 'much.', 'fulcrum', 'trying', '`nearly', 'turns', 'well', 'airs!', '\"twinkle,', 'book-shelves;', 'dismay,', \"ache!'\", 'bend,', 'true):', \"moment's\", 'begins', 'suppress', 'raised', 'carrying', 'direction,', 'lost,', \"talking!'\", 'tidy', 'sudden', 'bill!', 'creature', 'seem', 'first.', 'sound.]', \"done,'\", \"cat,'\", 'frog;', 'other', 'change,', 'conduct', \"off,'\", 'submitted', 'soup,\"', 'less', 'worse', 'strings:', 'animals', \"`can't\", \"`why?'\", 'spoon:', 'eyes,', 'bowed,', 'latin', 'alas', 'shrill,', \"up,'\", 'shouting', 'sorrows,', 'last', 'tail', \"wig.'\", 'scream,', \"here,'\", 'sadly.', 'trumpet', \"she'd\", 'fly,', \"turtle's\", 'folding', 'shyly,', 'boy,', 'reasons.', 'wags', 'slates,', 'into', 'fell', 'impossible.', 'talk.', 'meant', \"hedges,'\", 'quite', 'walking', 'some', 'grass,', 'white,', 'mad', 'that--only', 'humbly;', 'patience', 'flew', 'lady', 'officers:', 'fountains,', 'produced', 'forgotten', 'grave', 'ma', 'follows', 'larger,', 'ready?', '`fourteenth', \"book,'\", 'to-day!', '`here!', 'footman', 'soup', \"procession,'\", 'uneasy:', 'paint', 'loving', 'cattle', 'window,', 'mineral,', 'asleep.', 'result', 'else.', 'hurriedly', 'absence,', \"lobster--'\", 'interrupted:', 'yet--oh!', 'make', 'pinch', 'doth', 'plates,', 'here.', 'stupid),', 'mouse', 'sigh.', 'timidly.', 'friend', 'cackled', 'contempt.', \"rabbit's--`pat!\", '`are', 'protection.', 'sun,', \"had!'\", 'expression', 'askance--', '`soles', 'tears', 'different,', 'way', 'powdered', 'this,', 'hurry.', 'caterpillar', 'neighbour', 'executes', \"fancy--who's\", \"william's\", \"know.'\", 'glass;', 'crab', \"it,'\", 'pig', 'voice,', 'drew', 'three,', 'feathers,', \"well?'\", 'speak.', 'sulky,', 'persons', 'holding,', 'serpents!', 'it,', 'maps', 'prevent', 'feet!', 'content', \"couldn't\", 'what', 'trees,', 'stopping', 'fireplace', 'hung', 'repeating', 'bough', 'prosecute', 'feet', 'shepherd', \"verdict,'\", 'perfectly', '`hm!', \"pun!'\", 'dear!\"', 'dull', 'butter,', 'true.)', 'pattering', 'go?\"', 'losing', 'lost', 'drawing', 'telescopes:', 'interrupting', 'prove', 'laid', 'work', 'passage,', '`without', 'off,', \"throat!'\", 'past', '`--i', 'dreadfully', 'difficulties,', 'can', \"`stupid,'\", 'read:--', 'vegetable.', 'itself,)', 'courtiers;', 'marched', \"`wouldn't\", \"`where's\", 'a', 'ye;', 'choice,', 'confused', 'see', 'grant', \"else's\", \"shan't\", 'agony', 'french', 'come,', 'family', 'yards', 'this),', 'civil', \"feeling!'\", 'size;', 'argued', \"nonsense,'\", '`anything', 'lessons,', 'flat,', 'whiskers!', 'twelve,', 'hurried', 'somebody,', \"bill!'\", 'letter,', \"hatter's\", 'finger;', 'riddles', 'give', 'deeply', 'wrong', 'walk!\"', 'you?', 'opening', 'feel', 'people!', '`crumbs', \"that.'\", 'too,', 'reminding', 'asking,', 'sure!', 'dates', 'cross,', \"dinn--'\", 'yawned', '`swim', 'way!', \"that?'\", 'this:--', '`after', 'dancing', '`reeling', '3.0', \"`never!'\", 'wow!', 'smallest', 'angrily,', 'time,', 'only', 'elsie,', 'stairs!', 'voice', 'eaglet.', 'timidly;', 'one!', 'remarked,', 'cares', 'hastily,', 'out.\"', 'too', \"jury--'\", 'already,', 'flowers', 'here?', 'civil,', '`twinkle,', 'might,', 'understand.', \"song?'\", 'execution--once', 'duck', 'bringing', 'door', 'manners', \"here!'\", \"puzzle!'\", 'planning', 'sighing', 'persisted.', 'hanging', 'went.', \"once.'\", 'scroll', 'mine,', 'impatiently;', 'guinea-pig', 'reaching', '`three', 'cats', 'affair,', 'corners:', 'drawling,', '`unless', 'broke', 'xii', 'pardon,', 'stairs.', 'cat', \"different,'\", 'know', 'pencil', 'dig', 'it,)', 'air!', 'hurt,', '`off', 'sensation,', \"person!'\", 'murder', 'once', 'way:--', 'settling', 'two', 'england', 'things', 'me', '\"i\\'ll', \"jurors.'\", '`turn', 'vulgar', 'key', 'rope--will', '`ah!', 'capital', 'soo--oop!', 'paused', 'speech.', 'piece', 'jumping', 'unpleasant', 'tortoise,', 'candle.', \"`creatures,'\", 'herself.', 'upset', \"offended!'\", 'means', 'wonderland,', \"do.'\", \"him.'\", 'queer-looking', 'gone.', '`somebody', 'pencils', 'suit', 'footman.', 'playing', 'pity', 'calmly,', 'minute,', 'unless', \"altered.'\", 'verses', 'made.', 'passionate', 'to?', 'deny', 'write', \"things--'\", \"sisters,'\", \"mind!'\", 'furrows;', 'could,', 'shilling', 'favourite', 'fine', 'those', 'soon', 'sneeze,', 'garden--how', 'back', 'lazily', 'reality--the', 'shrink', 'exactly', 'fast', 'startled', 'unusually', 'multiplication', 'because', 'eat', \"day--'\", 'whispered,', '`come,', 'hearing.', 'manner', \"window.'\", 'hearts,', 'laughing:', 'hold', 'dear,', '`shy,', 'respectable', 'no!', 'particular.', 'owl,', 'certain', 'gloves:', 'roof.', 'on?', 'us', 'lazy', 'open', 'childhood:', 'moment,', 'thoughtfully.', \"court.'\", \"it'll\", 'addressed', 'hearthrug,', 'existence;', 'tell', 'let', 'creatures.', 'common', 'stirring', 'dinn', \"days.'\", 'complaining', \"`it's--it's\", 'sort.', 'change:', \"majesty!'\", 'dears', 'despair', 'heard', \"chatte?'\", 'matter', 'thought;', 'speak--and', 'remaining', \"sobbing,'\", \"now--don't\", 'finish', 'anywhere', 'dead', \"twice--'\", \"baby?'\", 'sending', 'ground--and', 'bowing', 'paris,', 'without', '`an', 'difficulty,', 'liked,', 'alarm', 'learnt', 'along--`catch', 'while,', \"soup!'\", 'stretched', 'shoes', \"puss,'\", 'ann!', 'modern,', 'right', 'straightening', '(dinah', \"beheaded!'\", 'knave,', 'puzzled', \"sort!'\", 'crash', 'tittered', 'gone', \"uglifying!'\", 'oblong', 'shoulders', 'ask.', 'asleep', 'children,', 'gloves', 'vanishing', '`digging', 'night-air', 'paper.', 'sure,', 'stalk', 'wrong,', \"idea,'\", 'off', 'larger:', 'mixed', 'stand', 'order', \"speak?'\", \"mean,'\", 'merrily', 'ever:', \"pardoned.'\", 'sing', 'larger', 'ran', 'angrily:', \"head's\", 'frowning,', '`then', 'squeaked.', \"be!'\", \"`here!'\", 'besides', \"you.'\", \"me.'\", 'crept', 'cautiously:', 'splash!', 'sneezing', 'played', \"begin?'\", 'again:', 'mercia', 'barley-sugar', 'banquet--]', \"like!'\", \"remedies--'\", '`stuff', 'fact.', 'blow', \"late!'\", 'away:', \"d,'\", \"eggs,'\", 'steady', '`w.', \"us,'\", 'tree', '\"william', 'deserved', 'party.', 'would,', \"much!'\", 'may', '`have', 'earnestly,', 'eagerly:', 'youth,', 'us,', \"them--'\", \"they're\", 'milk-jug', '`please,', 'earth', 'hate', 'saucepans,', 'tail;', 'seldom', \"stairs!'\", 'taking', 'same,', 'clubs;', '`repeat,', 'water,', 'nearer', 'grown', 'normans--\"', 'proud', \"hand,'\", 'altogether.', 'curled', 'bottle', 'good-', 'you,\"\\'', 'question;', 'frighten', 'wondering', 'dormouse!', \"temper,'\", 'life!', \"elbow.'\", 'odd', \"you!'\", 'course;', \"`poison,'\", 'jumped;', 'off.', 'with,', 'shrinking', 'this.', 'argument', 'immediately', 'word)', 'is--\"take', \"wow!'\", 'month', 'lizard', 'becoming.', 'sticks', 'interrupt', 'are;', 'severity;', \"indeed,'\", 'says', \"yet,'\", 'teaching', \"never')\", 'snail', 'linked', \"mayn't\", '`soo--oop', 'ventured', 'wide', 'arms,', 'seaside', \"executed.'\", 'loose', 'turning', 'soup!', '`all', 'rubbed', 'shore,', 'salmon,', 'passion.', 'sounds', 'affectionately', 'filled', 'ignorant', '`keep', 'saw', 'high.', 'person', 'added', 'hatter', 'collected', 'brightened', 'dog', 'glass,', 'jelly-fish', \"shiny?'\", 'kick,', \"wood,'\", 'twenty-four', 'cherry-tart,', 'cat.', 'skimming', 'empty:', 'here', 'overhead;', 'only,', \"hat,'\", 'who', 'saucepan', 'died', \"experiment?'\", 'appear', 'knocked.', 'nothing;', \"is?'\", 'again:--', 'muscular', 'indeed:--', '`some', 'follow', 'dipped', \"wine,'\", \"myself,'\", '`--for', 'by--the', 'turn', 'pleased', \"won't,\", 'time', 'crowd', '`please', 'fetch', 'heavy', 'directions,', 'story.', '`besides,', \"roses?'\", 'court,\"', 'poky', 'inquired', 'arm', 'her', 'broken.', \"`who's\", 'saves', 'won,', 'sight.', \"sir'\", '`that', \"does.'\", 'reading', 'king,', 'kind', \"to,'\", 'pennyworth', '\"you', \"i've\", 'engaged', 'opportunity', 'never-ending', 'pressed', 'officer', 'solemnly', \"cards!'\", 'encouraging', 'really', 'grinning', 'is--\"the', 'figure', 'seemed', 'executioner', 'absurd,', 'dark', 'did.', 'lacie,', 'fork', 'beautify', 'care', 'drawling--the', '`or', \"`you!'\", 'day.', 'doubtfully:', 'himself,', \"bread-knife.'\", 'child-life,', \"means.'\", 'proposal.', 'began:--', 'air', 'hare', 'leaning', \"australia?'\", 'deeply,', \"yourself,'\", 'putting', \"time,'\", 'edwin', 'caterpillar,', 'tillie;', '`he', 'london', \"heard!'\", '`nothing', 'closed', 'table.', 'branches', \"ada,'\", \"know!'\", 'producing', 'useful,', 'herself', \"idiotic!'\", 'again', \"duchess,'\", 'ah,', 'lying', \"garden!'\", 'presented', 'cards,', 'somebody', 'clearer', 'panther', 'see,', 'meaning.', \"course,'\", 'key,', 'clinging', \"about,'\", 'tongue', 'diligently', 'fury:', 'rabbit;', \"`sixteenth,'\", 'clock.', 'meekly:', 'english);', \"yourself!'\", 'sugar', 'waters', 'whiskers,', 'sleep,', 'fancying', 'death.\"\\'', 'provoking', 'archbishop', 'thank', 'refused', '`--as', 'mind', \"words,'\", 'was!', 'cake,', 'room.', 'hedgehog.', 'swim--\"', 'dodged', 'anything', 'living', 'spoke,', \"shall!'\", 'all:', 'advance!', 'kindly,', 'used', \"`i've\", \"`it'll\", 'master,', 'pair', 'wrapping', \"prison,'\", \"youth,'\", 'hare.', 'dainties', 'distance', 'listening:', 'none,', 'is--\"birds', 'faces', 'more.', 'pocket,', 'lived', 'then,', 'smiling', '`do', 'which', \"sea!'\", 'rate,', \"all!'\", 'repeated,', 'shoulder', 'rabbit,', \"other.'\", 'afore', 'serpent.', 'even', 'howling', 'seem,', \"words.'\", 'guests', \"bit.'\", 'remained', 'shock', \"`i'll\", 'croquet-ground.', 'particular--', 'head!\"\\'', 'comes', 'conger-eel,', 'now', \"up!'\", '(he', 'height.', 'rats', 'setting', 'blows', 'curiosity,', 'himself:', 'rest', 'together.\"\\'', \"was!'\", 'them--and', 'lesson-book.', 'fear', 'ravens', \"cutting,'\", 'little!', \"somewhere,'\", 'faster,', 'head.', 'far,', 'mallets', \"prizes!'\", 'short', \"late.'\", 'mostly', 'thoughts', 'others', 'that.', 'snorting', 'ladder?--why,', 'clasped', \"it!'\", 'sulky', 'throne', 'guinea-pigs', 'eyes--and', 'honour,', 'fishes', 'on,', 'well!', 'bit,', '`pepper,', 'away,', 'voice;', 'am,', 'him:', 'angrily', 'smaller,', \"did!'\", \"sky-rocket!'\", 'directed', '`with', 'glass.', 'dunce?', 'rustled', 'muttering', 'heads', 'ashamed', \"`they're\", \"course.'\", 'you--are', \"it?'\", 'slippery;', 'suppose', 'pat!', 'had,', 'door:', 'patriotic', 'howled', 'lessons', \"prizes?'\", 'peeped', 'with', 'helped', \"all,'\", 'hungry,', \"`you've\", \"would,'\", 'm,', \"annoyed,'\", 'temper.', 'them--all', \"puppy's\", 'ago:', 'sneezing.', 'said', 'meekly', \"people,'\", \"window!'\", 'break.', \"she,'\", 'forget', 'unfortunate', '\"edwin', 'that:', 'toes', 'grand', \"not?'\", '`mouse', 'enjoy', '`certainly', 'nose--', 'guinea-pig,', 'except', 'also,', \"doing!'\", 'hundred', \"majesty,'\", 'livery', 'wearily.', 'put', '`give', 'attempted', 'cushion;', 'leave', 'caterpillar.', 'there.', 'us!\"\\'', 'speed', 'hedgehogs,', 'pepper-box', \"lizard's\", 'pretending', 'love,', 'splendidly', 'jury.', 'crawling', 'knew', 'bread-', 'welcome', \"figure,'\", 'pressing', 'took', \"coils.'\", 'cheerfully', 'worth', \"one's\", \"enough,'\", 'dance?\"\\'', 'bottom', 'get', 'as', 'afraid', \"what's\", 'more--as', 'duchess', '`does', 'arm-in-arm', 'fit', \"won't'\", 'got', \"watch,'\", '`ah,', 'apples,', 'rabbit-hole--and', 'moved', 'cupboards', 'tricks', \"witness!'\", 'checked', 'sharks', 'hear', 'to,', 'happen', 'rise', \"thing!'\", \"off--'\", 'door--i', 'desperately:', 'cake.', 'once,', 'wretched', 'changed', 'happens', 'speaking,', 'soup,', \"`we're\", 'bill,', '`what', \"happen,'\", 'room!', 'number', '`fetch', 'father;', 'staring', 'two--\"', '\"they', 'bother', 'end!', 'sighing.', 'diamonds,', 'house,', \"it.'\", 'lizard,', 'rule:', \"off.'\", 'sky', 'none', \"prisoner's\", 'almost', 'minute.', 'neck', 'stupidly', \"extremely--'\", 'crowded', 'creature,', 'unhappy', 'comfits,', \"the--'\", \"spot.'\", '`--mystery,', \"were',\", 'ceiling,', 'puzzling', \"caterpillar's\", 'silent,', 'mock', 'alone.', 'declare,', 'knave', 'pigeon.', 'failure.', 'began.', 'conquest.', 'mistake;', \"question,'\", 'wildly', \"which?'\", 'appeared;', 'all.', \"three.'\", 'back-somersault', 'politely;', 'word,', 'fur.', 'crash,', 'any', 'ear.', 'splashed', 'pop', '`we', 'tops', \"learn?'\", 'cats:', 'nurse', 'beautiful', \"bill,'\", 'nothing,', 'mean,', 'reach', 'imagine', 'slates', 'within--a', 'knee,', \"`arrum.')\", \"subject,'\", 'passage:', \"nothing.'\", 'sad', 'anything.', 'corner--no,', 'edge', 'forwards', 'line', 'day:', '`if', 'sprawling', 'them--`i', \"for.'\", 'elbow', \"together!'\", 'mine--a', \"man.'\", 'cushion,', 'faint', 'draw,', 'blades', 'twice,', 'table:', 'laughter.', \"savage!'\", \"girl,'\", 'fellow?', \"partners--'\", 'cheshire', \"temper!'\", \"fourth.'\", \"pie--'\", 'animals,', 'hookah,', 'lonely', 'has', 'begged', 'instance,', 'subjects', 'puzzled.)', 'dressed,', 'grand,', 'tumbled', 'miserable', '`back', '`--so', 'soldiers,', 'turtle--we', 'leap', 'cried', 'about', \"dull!'\", '`curiouser', \"cats!'\", 'grief,', '`she', 'breathe\"!\\'', 'best.', \"chose,'\", 'angrily.', 'mile', \"him,'\", 'singing', 'being', 'outside.', 'adjourn,', \"say?'\", '`one,', 'begin,', 'means,', 'guests,', 'size', 'panted', 'turns,', \"sea--'\", 'hall:', 'sooner', 'parts', 'baby;', 'swallowing', 'crumbs', 'down,', 'rising', \"`jury-men'\", 'sigh,', 'hurt', 'witness', 'corner,', 'worry', 'fond--of--of', 'denied', 'baked', 'court;', 'days', 'pigeon,', 'lobsters', 'capering', 'is--\"oh,', \"whiting!'\", 'holding', 'notice', 'from:', 'treacle', '`--that', 'tea-time,', 'sometimes,', 'hatter;', \"trouble!'\", 'patiently.', 'signify:', 'drunk', 'cut', 'making', 'needs', 'middle,', '`begin', 'could', 'righthand', 'lullaby', 'day;', 'proper', 'sands', 'rate', 'different', \"whatever,'\", 'canvas', 'carroll', 'minute', 'expecting', '`\"miss', 'lips.', \"ill.'\", 'violence', 'eyes:', 'licking', 'fight', 'stay', \"think--'\", 'laughing', 'begin', 'replied:', \"you're\", 'above', 'feather', 'low', 'sorts', 'spoke.', 'vinegar', 'kindly', \"next!'\", 'eaglet,', 'jar', \"you've\", 'it--once', 'song,', 'picture.)', 'course,', 'followed', \"sir--'\", 'footman,', 'fanned', '`i', 'woman;', 'antipathies,', \"first,'\", 'nothing.', 'with.', 'snout', 'person,', \"mine,'\", 'down', \"them,'\", 'together:', 'slate', 'roses.', 'clear', 'spell', \"telescope.'\", 'serpents', \"pig!'\", 'doubt,', 'wandering', 'whole', '(alice', 'likely', 'night!', 'wings.', 'feelings', 'long,', 'see\"!\\'', 'though,', 'head--', 'water', \"before,'\", 'gloves--that', 'alice:', 'birds!', \"cat's\", 'over.', 'appealed', 'often,', 'expressing', 'roots', 'march,', 'worried.', 'peeping', '`--likely', 'tails', 'newspapers,', 'whose', 'politely,', 'offended', 'further.', '`found', 'follow,', \"dear,'\", \"curiouser!'\", 'players,', 'red.', \"`everything's\", 'double', \"march.'\", 'breath.\"', 'judging', \"plan.'\", 'gryphon:', 'stockings', \"slates'll\", 'mischief,', 'feet,', 'sentenced', 'such', \"thimble';\", 'day-school,', 'on.', \"begin.'\", 'general', '(`which', 'out.', 'inwards,', 'words:--', 'sharply', 'dishes', 'burst', 'draggled', '(she', 'long', 'confusion,', 'effect:', 'suppressed', 'cheated', 'field', 'mustard-mine', \"her,'\", 'upsetting', 'quickly', \"i,'\", 'joys,', 'fifth', 'esq.', 'cook.', 'shoulders.', '`poor', 'you:', \"opinion,'\", 'trial:', \"confusing.'\", 'an', 'tiptoe,', \"then!'\", 'harm', \"can--'\", 'twinkling!', \"`you'll\", 'nevertheless', 'fits,', 'love).', 'fidgeted.', 'claws,', 'sorrowful', 'over', \"with,'\", 'beak--', 'this;', \"hedge!'\", 'tipped', 'stingy', \"trial's\", 'fit--\"', 'stretching,', 'mad,', 'hall,', 'changes', 'trampled', \"m--'\", \"not';\", 'bill', 'turned', 'folded,', 'somewhere', 'humble', 'pleased.', 'using', 'spoon', 'owl', 'comes,', 'sixpence.', 'riper', 'saucer', 'i,', 'size?', '`till', 'balanced', \"fairly,'\", 'secondly,', 'nearer,', 'so.', 'chimney,', 'whispered', 'vi', 'bread-and-butter,', \"whiskers!'\", 'players', 'interrupted.', \"school,'\", 'answer', \"bird,'\", 'choosing', 'unwillingly', 'smoke', \"grin,'\", \"there,'\", 'think:', 'singers.', 'does', '`hold', \"never!'\", 'memorandum', \"`--where's\", 'instantly', 'thought:', \"`nothing,'\", \"it's\", 'brown', \"of?'\", 'uncivil.', 'hearts', 'sulkily', \"right?'\", 'shower', 'trembling', 'minutes.', \"below!'\", 'shut.', '`whoever', \"somewhere.'\", \"me'\", \"from?'\", 'no', 'month,', 'rapidly:', 'high:', 'attends', 'go,', 'cheap', 'walk', 'pack,', 'about;', 'nest.', 'whereupon', 'appeared.', \"house!'\", 'fire,', 'alive;', 'moral', 'measure', 'places--', 'gained', 'hands,', 'spades,', 'iv', '`hush!', 'thunderstorm.', 'waistcoat-', \"housemaid,'\", 'among', 'pictures', 'grumbled:', 'did,', 'puzzled.', 'around,', \"now.'\", 'each', 'growled', \"speaker,'\", 'look-out', 'do:--', \"lessons,'\", 'true--\"', 'please,', 'ugly;', 'fortunately', 'wriggling', 'hope', 'door,', 'could.', 'milk', 'burn', 'fighting', '`well,', 'hit', 'i?', \"them!'\", 'wig,', 'catching', 'march', '\"how', 'quarrelling', 'down.', \"advantage,'\", 'winter', 'alarm.', 'over,', \"prizes.'\", 'iii', \"these?'\", 'drink', 'untwist', 'shriek,', 'very', 'houses,', 'shared', \"not!'\", \"liked.'\", \"tasted--'\", 'everybody', \"curious.'\", 'rate:', 'cardboard.)', 'wider.', 'game', 'upon', 'enough--i', 'o', 'pleasanter', '`where', 'ten', 'alice;', 'denies', \"verse.'\", 'sharing', '\"who', 'much,', 'giving', 'way--never', 'disobey,', 'whisper', 'histories', 'again!', 'remarkable', 'engraved', 'timidly:', 'dreamed', 'is!', 'other:', 'weak', '`from', \"teases.'\", 'twice', '`consider', 'strange', 'mary', 'on!\"', 'speak,', 'meaning', 'thick', 'actually', 'indignantly,', \"things!'\", 'up', 'law:', 'hand,', 'mouse.', 'porpoise', 'yourself,', \"room!'\", '`explanations', \"yet!'\", 'so--and', 'driest', 'denied,', 'time).', 'along', 'quietly', \"`hjckrrh!'\", 'marked', 'pet:', 'enough;', 'sentence', 'doubtful', 'was)', 'pig,', 'remarking,', \"table,'\", 'please!', 'which),', 'coming', 'been', 'jury,\"', 'baby:', 'looking-', 'bend', 'try', '`prizes!', \"ask.'\", 'than', 'elbows', 'we', 'sister,', 'dormouse', 'taught', 'hatters', 'morning?', \"`it's\", 'evening,', 'name:', \"she'll\", 'sneezes:', 'appeared,', 'loud', 'backs', \"removed!'\", \"`you're\", 'nursing', \"story.'\", 'court,', 'sweet-tempered.', 'seen', 'hair', 'red-hot', \"a--'\", 'either', 'indeed:', 'sat', 'nodded.', \"sea-shore--'\", 'terrier,', 'obstacle', 'caught', 'felt', 'him', \"well--'\", \"that!'\", 'been,', 'atom', 'do,', \"guinea-pigs!'\", 'now.', 'courage', 'goose,', 'retire', \"waist,'\", 'patiently', \"be,'\", 'pieces', 'deal:', 'alive', 'near.', 'tears.', 'shutting', 'act', 'hid', 'slipped,', 'sky!', \"something!'\", 'minutes,', 'cold', 'cost', 'yelled', 'wish', 'late,', 'on;', \"off?'\", 'low-spirited.', 'proved', 'flamingo,', \"way--'\", 'kissed', \"brother's\", 'mouths;', 'fifteen', \"be.'\", 'lefthand', \"nonsense.'\", 'lewis', 'fellows', \"`serpent!'\", 'silence,', '`then,', 'cat,', 'silence.', 'terror.', 'millennium', \"sad?'\", '--come,', \"bill's\", 'high).', 'book', '`--you', 'foolish', 'emphasis,', 'minutes', 'truth:', 'trickling', 'hers--she', 'arrived,', \"egg!'\", 'cry', \"mushroom,'\", 'thoughtfully', 'tea,', 'red', 'screaming', 'sobbed', \"alice's\", 'drinking.', 'neighbouring', 'where', 'interesting', 'english,', 'stays', 'tut,', 'timid', 'beau--ootiful', 'send', \"pardon,'\", 'over;', 'turtles', '`collar', \"can't\", 'reply,', 'held', 'hearth', 'pretexts', 'choke', 'cause', \"on?'\", 'happened', 'dance?', 'birds,)', 'william,\"\\'', 'replied.', 'permitted', 'interesting,', 'letters.', 'riddle', 'then--she', 'chin', \"won?'\", 'eye', 'addressing', 'like\"!\\'', 'yours', 'so', \"`he's\", '`the', 'beauti--ful', 'things!', 'pity!\"?\\'', 'undertone,', 'pretend', 'squeeze', 'why.', 'duchess,', 'cur,', \"isn't,'\", 'chuckled.', \"longer!'\", 'read', 'smoking', \"waiting!'\", 'frontispiece', \"right!'\", 'poker', 'sobbing', 'your', 'coast', 'flamingo:', \"sea.'\", \"do,'\", 'bursting', 'e--e--evening,', \"them.'\", \"removed,'\", '`chorus', 'other--bill!', 'said,', 'theirs,', 'draw', 'why,', 'use,', 'lad!--here,', 'tea;', '`to', 'beating', 'charges', \"star-fish,'\", 'advisable', \"first!'\", \"rude.'\", '`mary', 'mouth', 'narrow', 'her:', \"know--'\", 'chains,', 'label,', 'crashed', 'toffee,', 'cakes', \"up.'\", \"sister's\", \"together.'\", 'replied;', 'offend', \"explained,'\", \"to--'\", '\"what', 'back.', \"dream!'\", 'seven', 'jurymen.', 'burnt,', '--the', 'night?', \"child!'\", \"seems,'\", 'its', 'crossed', '(if', 'far!\"', 'since', 'eggs', 'pieces.', \"all?'\", 'curving', \"whiles.'\", \"invited,'\", 'duchess!', 'terms', 'fender,', 'fancied', \"knocking,'\", 'presently', 'recovered', 'sobs,', 'busily', 'do.\"', 'pause.', 'said.', 'fallen', 'do.', 'chin:', 'timidly', 'turn;', 'murdering', 'life', 'adoption', 'roof', \"away!'\", 'stick,', \"`they'd\", 'time!', 'does.', 'immediate', \"was.'\", 'surprised', '`when', 'twinkled', 'ugly', 'invitation', 'against', 'consider', 'pale', 'enough', 'foot,', 'children;', '`of', \"hatter.'\", 'sharply;', 'procession,', \"end.'\", 'rippling', 'interrupted', 'quadrille,', '`important--unimportant--', 'tossing', 'itself.', 'unrolled', 'jaws', '[later', 'lamps', \"game.'\", 'breeze', \"outside,'\", 'scaly', 'decidedly', 'turtle;', 'settle', 'piteous', 'accident', 'persisted', 'fall', 'muddle', \"like.'\", 'laughed,', 'ordered.', 'remain', '`is', 'angry.', 'gloves,', 'floor,', 'nose', 'fixed', 'elegant', 'much', 'spoke', 'running', 'rustling', 'comfits:', 'sobs', 'eyelids,', 'rich', 'solid', \"draw,'\", 'politely:', 'good', 'ridiculous', 'that!', 'shorter,', 'france--', 'song.', '`and', 'close', 'distance--but', 'hand.', 'tiny', 'note-book,', 'eleventh', 'wet', 'thatched', 'left,', 'gravely.', 'dozing', 'upright', 'changed,', 'extraordinary', \"mostly,'\", 'done,', \"too.'\", \"conqueror.'\", 'makes', 'growl,', 'bleeds;', '`stand', \"whiting,'\", 'ancient', \"tale!'\", \"`dinah's\", 'undoing', 'treacle-well--eh,', 'accustomed', 'tail.', \"thing,'\", 'reason', 'confusion', 'occasionally;', '`speak', 'ointment--one', 'first--verdict', '`you', 'quiver', 'complained', '`until', '`chop', 'trial,', 'door;', \"tortoise--'\", 'english.', 'possibly', 'reasonable', 'anxious.)', 'resource,', 'thunder,', \"english!'\", '(though', 'puffed', 'teacups', 'trials,', 'dream:--', 'next.', 'wants', 'door--', 'rubbing', 'locked;', 'mad--at', \"happens!'\", \"i'd\", 'five,', 'room,', 'usually', 'face.', 'worm.', 'earls', \"choice!'\", 'faster?\"', 'knew)', 'hours', \"whatever?'\", 'teeth,', \"high,'\", '`--or', 'telling', 'hair.\"', 'impossible', 'like:', '`first', 'rises', 'certainly:', 'wanted', '`once', \"stop.'\", 'it!--that', 'boy--and', 'forty-two.', 'watch', 'picking', \"yourself.'\", 'young', 'loud,', 'best,', 'air,', 'then?', 'disappointment', 'golden', 'scratching', 'x', 'sits', 'whistling.', 'anything;', 'fair', 'plate.', 'father', 'them:', \"jury-box,'\", 'later.', 'rumbling', \"`unimportant.'\", 'hair!', '\"\\'tis', 'skurried', \"`once,'\", 'pence.', 'gryphon.', 'dive', \"for?'\", \"crumbs,'\", 'tastes!', '`really', 'between', \"`why,'\", \"fun!'\", \"we're\", 'hurry,', '`his', 'different.', 'thanked', 'executions', \"hush!'\", 'sitting', 'crimson', 'speech', 'nile', 'grinned', 'sternly.', 'caucus-race', 'dish', 'looked', \"alice!'\", 'ran,', \"william,'\", \"enough!'\", 'raving', 'fury,', 'quick,', 'cat;', 'met', 'indignantly.', 'fly', \"cats?'\", 'myself', \"dear!'\", 'believed', 'quietly,', 'another', 'executed', 'friends', 'serpent;', 'world!', \"there's\", 'used--and', 'fright', 'passed;', \"dormouse!'\", 'hand', 'saying', \"say,'\", \"`ahem!'\", 'sadly', 'end:', 'kneel', 'editions', 'pool,', 'little--\"\\'', 'follows:--', 'flung', 'low.', 'patted', 'gardeners', 'the', 'ferrets', \"like,'\", '`o', 'see--how', 'clean', 'master', 'louder', 'pray', '`ten', '`sh!', 'part', '(as', 'meeting', 'him,', 'top', 'slowly,', \"cats.'\", 'rabbit!', 'upset,', \"trying--'\", 'edition', 'jaw,', 'house', 'distant', 'then', '\"there', 'or', 'full', 'sure', 'curiosity.', 'triumphantly.', 'look!', 'hall', 'vote', 'aloud;', 'advantage', '`well!', 'you!', 'kept', 'guess,', 'escape;', 'him--it', 'lasted.)', 'particular;', 'twinkling', '`lives', 'breathe', 'passion,', 'disgust,', 'more', 'indignant', 'more;', '`tut,', 'grinned;', 'best', \"less,'\", '`tell', \"talk!'\", 'vanished.', \"day!'\", \"mouse!'\", 'consented', 'wooden', 'ourselves,', \"remarks,'\", \"again,'\", 'duck.', 'please:', '`but,', 'declare', 'children.', 'explanation.', 'called', \"turtle.'\", \"lessons!'\", \"away,'\", 'indeed', 'anxiously.', 'sense', 'expected:', 'cheered,', 'good-naturedly', 'glass', 'i', 'children', 'painting', 'happens.', 'keep,', 'list', \"watch!'\", 'bawled', 'knee', 'turtles,', \"on!'\", 'advice', 'advisable--\"\\'', \"i'm\", 'anger', 'queen!', 'branch', 'swallowed', 'word', \"better.'\", 'surprised,', \"marmalade',\", \"game,'\", '`allow', 'daisies,', 'leant', '`advance', '`wake', 'answer,', 'pigeon;', 'loudly.', 'trembled', 'nonsense.', 'jurymen', 'whisper.)', '`\"what', 'known', \"raw.'\", 'dream', 'next,', 'subject.', 'managed', 'fish,', 'canary', 'favoured', \"escape!'\", 'pour', 'eels,', '`flamingoes', 'grin,', 'earth!', 'majesty', 'concluded', 'nine', 'remarking', 'returning,', 'strength,', \"isn't\", '`explain', 'attempts', 'ate', 'world', 'fright.', 'particular', '\"i', 'succeeded', 'skirt,', 'came,', 'dispute', \"saying.'\", 'conclusion', 'nobody,', 'away', 'glass.)', 'me,', 'corner', 'telescope!', 'take', 'told', 'tea-tray', 'meanwhile', 'tale', 'history.', 'save', 'side.', 'uglification,', 'usual.', 'prizes.', \"english,'\", 'scolded', 'way?', 'right-hand', 'happening.', 'two.', 'attended', 'curtseying', \"time?'\", 'them.', 'after', 'executed,', \"coming!'\", 'thump!', 'remark,', 'well,', \"dog's\", \"dinner!'\", 'baby,', 'muchness\"--did', \"did,'\", 'witness.', 'pigeon', 'neck,', 'state', 'thought),', 'three-legged', 'tulip-roots', '_i_', 'sadly:--', 'down--here,', 'knock,', 'large,', 'hedgehogs', \"lessons?'\", '`your', 'use', '\"poison\"', 'fly;', \"through,'\", 'large', 'tears,', 'quadrille', 'seen,', 'brush,', 'itself,', 'abide', 'thistle,', 'miss', 'happen,', 'hatter,', 'classics', 'spreading', 'once;', 'think;', 'hatter:', 'venture', 'one--but', \"matter,'\", \"sh!'\", 'swallow', \"`important,'\", 'again.', 'easy', 'pocket', 'never!', 'knuckles.', 'them,', 'poured', 'fan,', 'began,', 'do', 'ones', 'himself', 'clever', 'respect.', 'gone,', 'ask:', 'important', '`eat', \"with.'\", \"won't!'\", 'promise.', \"again.'\", 'ask', 'interest', 'business', 'same', 'day,', 'talking.', 'stuff?', 'solemnly,', \"right,'\", 'railway', 'music,', 'pleasant', 'puzzled,', 'puppy;', 'adding,', 'change', 'open,', 'grunted', 'queen,', 'interesting.', \"before.'\", 'toys', 'march--just', 'constant', 'lobsters,', 'altogether;', 'absurd', 'goose!', 'might', \"`they--you've\", 'yourself', 'magpie', 'help', '(when', 'business,', 'room', 'long;', 'confused,', 'ears', 'whistle', 'eagerly.', \"sing?'\", 'forgetting', \"alone!'\", 'shaking', 'hoarsely', 'shingle--will', 'screamed', 'gently', \"life.'\", '`on', \"accusation!'\", 'know,', 'solemn', 'directions', 'pegs.', 'rabbit:', 'jurors', 'said;', '`wow!', '`never', 'seen--everything', 'cook,', 'for,', 'nervous,', 'soldier', 'look', 'beheading', 'wait,', 'arm-chair', 'rest,', 'lose', 'pope,', 'soup?', 'croquet-ground', 'turn-up', 'leaves:', 'knew,', 'beg', 'but', 'doors', \"music.'\", 'hare,)', 'pass', 'bells,', 'eggs,', 'washing--extra.\"\\'', 'reduced', \"`silence!'\", 'simple', 'cauldron', 'dream.', '`leave', 'rattling', 'treated', 'butter', 'learn!', '`orange', 'wasting', \"now!'\", 'remarks,', 'king;', 'suet;', 'squeaking', 'introduced', 'begun', 'stop.', \"dinah!'\", '`however,', 'authority', 'far', \"can,'\", 'haste,', 'come', 'guessed', 'six', 'edgar', 'dishes.', 'voice:', 'asked,', 'chorus', 'practice', 'well.', 'whiting', 'hint', 'hoping', 'three', 'can;', 'rattle', \"fellow!'\", '`thinking', 'fluttered', 'quarrel', 'struck', \"bed!'\", \"doesn't\", 'joined', 'thing,', 'sea!\"', 'middle', \"haven't\", 'somehow', 'hands;', 'that', 'hate--c', 'purring,', 'while', 'pool', '`oh', 'again;', 'dear!', 'every', \"ann!'\", 'are', 'knowing', 'directly,', 'coaxing.', 'oneself', \"mystery,'\", 'lie', 'finger', 'land', 'wander', 'unable', 'frog', 'pounds!', 'leaving', 'least', 'twist', 'yawning', 'are!', 'argue.', 'never', 'rule,', 'pie-crust,', \"old,'\", \"minute!'\", 'therefore', \"`'tis\", 'darkness', '`whenever', 'wise', 'bones', 'stupid', 'tarts,', 'woke', 'thoroughly', 'flashed', 'fancy', 'found', 'bottle,', 'dance.', 'blasts', 'him--how', 'sure;', 'noise', '`now', 'garden.', '`take', 'moderate.', 'wife;', 'mustard', 'lovely', 'positively', \"butter,'\", 'us.', \"wasn't\", 'beat', 'should', 'finish,', 'violently,', 'paw', 'belongs', 'remark.', 'note-book', 'falling', 'did', 'now--but', 'boxed', \"couple?'\", 'beautifully', 'court!', 'head!', '`than', 'bats', 'closely', \"maybe,'\", 'couples:', 'centre', 'yet', 'natural);', 'quicker.', 'bowed', \"toes.'\", \"myself.'\", \"giddy.'\", 'if--if', 'slowly', 'game.', 'paper', 'table,', 'drawling-master', 'bats,', 'eaglet', 'bear:', 'velvet', \"let's\", 'game,', 'passage', 'nor', 'pairs', 'bad', 'there', \"shoes.'\", '`thank', \"footman's\", 'altogether,', '*', \"again?'\", 'faces,', '`each', 'bitter--and--and', 'sit', 'hoarse,', 'bread-and-butter', \"o'clock\", 'livery:', \"clearly,'\", \"whiting?'\", 'bee,\"', 'straightened', 'fish', 'school', 'am', 'ought!', \"perhaps?'\", 'her,', \"either!'\", 'fan!', \"christmas.'\", 'him.', 'improve', \"window?'\", 'fumbled', '(sounds', 'repeat', 'cakes,', \"`alice!'\", 'beds', 'v', 'relief.', 'unfolded', 'oh', \"two!'\", 'sister', 'dogs', \"clever?'\", 'about,', 'finished.', 'killing', 'splashing', \"handwriting?'\", 'knowledge,', 'so,', 'kitchen,', 'were.', \"think?'\", \"are!'\", 'surprise,', 'sizes', 'people', \"now?'\", 'uneasily,', 'brushing', 'highest', 'stool', 'just', 'arrow.', 'hearts.', \"in.'\", 'standing', 'opposite', 'week:', 'flavour', \"jaws!'\", 'morsel', 'heart', 'lobster', 'king:', 'faintly', 'lizard)', 'more,', 'understood', \"curious!'\", \"railway,'\", 'folded', 'without--maybe', '(in', 'again--\"before', \"business,'\", 'lessen', 'hall.', \"end,'\", \"be?'\", 'ambition,', 'garden:', 'moon,', 'considering', '`beautiful', 'alice,', 'custody', 'off).', 'whether', 'often', \"yet.'\", 'lit', 'energetic', 'mouths', '`very', 'stand,', 'jury-box,', 'alternately', 'ending', 'party', \"know?'\", 'mouth;', \"dancing.'\", \"fun?'\", 'otherwise', \"last!'\", 'late', 'be,', \"unimportant--important--'\", 'singers', 'occasional', 'closer', '`my', 'finding', 'least,', \"figure!'\", 'wet,', 'queens,', '\"it\"', 'swimming', 'tried.', 'twentieth', 'life,', \"queen's\", 'comfort,', \"means--to--make--anything--prettier.'\", 'hearing', 'dinner,', 'name', 'dinah!', 'afraid,', 'remark', \"duchess?'\", 'man', 'other,', 'cries', 'anxiously', 'irritated', 'circle,', 'mouse--o', 'indeed,', '--but', 'courage,', 'she,', '`by-the-bye,', 'afford', 'court.', '(which', '`which', 'continued,', 'age,', \"don't\", 'opened,', 'dry', 'candle', 'brown,', 'will', 'remarks', 'dropping', \"not,'\", 'furious', 'bear?--mind', 'bring', \"and-butter--'\", \"course?'\", 'plates', 'slates;', 'punching', 'doubled-up', 'hardly', 'trot', 'believe', 'plan,', 'arranged;', 'kill', 'settled', 'know--no', \"growling,'\", '`dear,', 'spoke--fancy', 'doze;', 'nearly', \"story!'\", 'moment.', 'daisy-chain', 'enough,', 'tone:', 'girl', 'muttered', 'recognised', \"cup,'\", 'quick', 'nibbling', 'bark', 'body', 'before,', \"`dinah'll\", 'familiarly', '`but', 'grazed', \"what?'\", 'knee.', 'right;', 'ridges', '`why,', 'them', 'flappers,', 'white', \"manage?'\", 'soon.', 'him),', 'serpent,', 'her.', 'ours', 'evidently', 'sky.', 'began', '`exactly', 'seeing', 'sheep-', \"`nonsense!'\", 'avoid', 'dear:', 'alarmed', 'shoulders,', 'pray,', 'kick', 'walrus', 'finds', 'furiously,', 'cleared', 'mournfully.', \"he'd\", 'journey,', 'twinkle--\"\\'', 'pleasing', 'nose,', \"home?'\", 'water.', \"verse,'\", 'alas!', 'loud.', 'dinah', \"impertinent,'\", '`drive', 'hands', 'lodging', 'lory.', 'thrown', 'crouched', 'meet', 'both', 'underneath', 'undertone', 'fall,', 'small,', 'frowning', \"where--'\", '`would', 'sighed', \"judge,'\", '(look', 'oh!', 'thirteen,', 'faces.', 'northumbria--\"\\'', 'dinah:', \"`ugh!'\", 'baby', 'moment', 'sorry', \"refreshments!'\", 'green,', 'tougher', 'sea', 'hurry;', 'dormouse,', 'queen', 'tumbling', 'people.', 'why', 'added,', 'sob,', 'smiled', \"wits!'\", 'bright-eyed', '`unimportant,', \"he?'\", 'rude,', \"more!'\", 'first', 'heels', '`i--i', 'straight', 'this', 'takes', 'stopped', 'natured,', 'advance', 'bag,', 'four', 'scale!', 'inclined', 'various', '`come', \"outside.'\", 'whatever', \"better,'\", '`only', '`same', 'beheaded,', 'hollow', 'mouths--and', 'hurry', \"don't!'\", 'face--and', 'mouth,', 'alone'}\n",
      "Average sentence length: 7.4\n",
      "Vocabulary diversity: 0.1870\n"
     ]
    }
   ],
   "source": [
    "def assess_data_quality(texts):\n",
    "    \"\"\"Analyze text data quality for Word2Vec training\"\"\"\n",
    "\n",
    "    stats = {\n",
    "        'total_documents': len(texts),\n",
    "        'total_words': 0,\n",
    "        'unique_words': set(),\n",
    "        'sentence_lengths': [],\n",
    "        'word_frequencies': {}\n",
    "    }\n",
    "\n",
    "    for text in texts:\n",
    "        words = text.lower().split()\n",
    "        stats['total_words'] += len(words)\n",
    "        stats['sentence_lengths'].append(len(words))\n",
    "        stats['unique_words'].update(words)\n",
    "\n",
    "        for word in words:\n",
    "            stats['word_frequencies'][word] = stats['word_frequencies'].get(word, 0) + 1\n",
    "\n",
    "    stats['vocabulary_size'] = len(stats['unique_words'])\n",
    "    stats['avg_sentence_length'] = sum(stats['sentence_lengths']) / len(stats['sentence_lengths'])\n",
    "\n",
    "    # Find most common words\n",
    "    sorted_words = sorted(stats['word_frequencies'].items(), key=lambda x: x[1], reverse=True)\n",
    "    stats['top_words'] = sorted_words[:20]\n",
    "\n",
    "    # Quality indicators\n",
    "    stats['quality_score'] = {\n",
    "        'vocabulary_diversity': stats['vocabulary_size'] / stats['total_words'],\n",
    "        'avg_word_frequency': stats['total_words'] / stats['vocabulary_size'],\n",
    "        'rare_words_ratio': sum(1 for count in stats['word_frequencies'].values() if count == 1) / stats['vocabulary_size']\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Example usage\n",
    "quality_report = assess_data_quality(texts)\n",
    "print(f\"Total documents: {quality_report['total_documents']:,}\")\n",
    "print(f\"Vocabulary size: {quality_report['vocabulary_size']:,}\")\n",
    "print(f\"Unique Words: {quality_report['unique_words']}\")\n",
    "print(f\"Average sentence length: {quality_report['avg_sentence_length']:.1f}\")\n",
    "print(f\"Vocabulary diversity: {quality_report['quality_score']['vocabulary_diversity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6b041-933b-4a18-9474-382c97c9a3cc",
   "metadata": {},
   "source": [
    "This code **analyzes the text dataset and gives a detailed quality report.**\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "- Counts total documents, words, and unique vocabulary\n",
    "\n",
    "- Calculates average sentence length and word frequencies\n",
    "\n",
    "- Finds the 20 most common words\n",
    "\n",
    "- Measures vocabulary diversity (how varied the words are)\n",
    "\n",
    "- Identifies rare words that appear only once\n",
    "\n",
    "- Generates quality scores to assess if the dataset is good for Word2Vec training\n",
    "\n",
    "**Result:** We get statistics about Alice in Wonderland text - like how many unique words it has, average sentence length, and whether the vocabulary is rich enough for effective Word2Vec training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013945f-14a4-419b-adf1-0f548bd78ce1",
   "metadata": {},
   "source": [
    "### **3.3 Text Preprocessing Pipeline**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50b0a263-eb7e-41b9-9b4b-4a72fb475afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "\n",
    "#Import Packages\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66ea207d-a0ef-40c9-b13e-d3c72f69cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0be9b684-7a34-47b7-8698-e593cc61fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedTextPreprocessor:\n",
    "    \"\"\"Comprehensive text preprocessing for Word2Vec training\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 lowercase=True,\n",
    "                 remove_punctuation=True,\n",
    "                 remove_numbers=False,\n",
    "                 remove_stopwords=False,\n",
    "                 min_word_length=2,\n",
    "                 max_word_length=50,\n",
    "                 lemmatize=False,\n",
    "                 remove_urls=True,\n",
    "                 remove_emails=True,\n",
    "                 keep_sentences=True):\n",
    "\n",
    "        self.lowercase = lowercase\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.remove_numbers = remove_numbers\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.min_word_length = min_word_length\n",
    "        self.max_word_length = max_word_length\n",
    "        self.lemmatize = lemmatize\n",
    "        self.remove_urls = remove_urls\n",
    "        self.remove_emails = remove_emails\n",
    "        self.keep_sentences = keep_sentences\n",
    "\n",
    "        if remove_stopwords:\n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        if lemmatize:\n",
    "            self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean individual text string\"\"\"\n",
    "\n",
    "        # Remove URLs\n",
    "        if self.remove_urls:\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "        # Remove email addresses\n",
    "        if self.remove_emails:\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "        #Combined\n",
    "         #(r'https?://\\S+|www\\.\\S+|<.*?>|\\S+@\\S+\\.\\S+|@\\w+|#\\w+|[^A-Za-z0-9\\s])\n",
    "\n",
    "        return text\n",
    "\n",
    "    def tokenize_text(self, text):\n",
    "        \"\"\"Tokenize text into sentences or words\"\"\"\n",
    "\n",
    "        if self.keep_sentences:\n",
    "            # Tokenize into sentences first\n",
    "            sentences = sent_tokenize(text)\n",
    "            processed_sentences = []\n",
    "\n",
    "            for sentence in sentences:\n",
    "                words = self.process_sentence(sentence)\n",
    "                if len(words) >= 3:  # Keep sentences with at least 3 words\n",
    "                    processed_sentences.append(words)\n",
    "\n",
    "            return processed_sentences\n",
    "        else:\n",
    "            # Return single list of words\n",
    "            return self.process_sentence(text)\n",
    "\n",
    "    def process_sentence(self, sentence):\n",
    "        \"\"\"Process individual sentence\"\"\"\n",
    "\n",
    "        # Lowercase\n",
    "        if self.lowercase:\n",
    "            sentence = sentence.lower()\n",
    "\n",
    "        # Tokenize into words\n",
    "        words = word_tokenize(sentence)\n",
    "\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "\n",
    "            # Remove punctuation\n",
    "            if self.remove_punctuation:\n",
    "                word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            # Skip if empty after punctuation removal\n",
    "            if not word:\n",
    "                continue\n",
    "\n",
    "            # Remove numbers\n",
    "            if self.remove_numbers and word.isdigit():\n",
    "                continue\n",
    "\n",
    "            # Check word length\n",
    "            if len(word) < self.min_word_length or len(word) > self.max_word_length:\n",
    "                continue\n",
    "\n",
    "            # Remove stopwords\n",
    "            if self.remove_stopwords and word in self.stop_words:\n",
    "                continue\n",
    "\n",
    "            # Lemmatize\n",
    "            if self.lemmatize:\n",
    "                word = self.lemmatizer.lemmatize(word)\n",
    "\n",
    "            processed_words.append(word)\n",
    "\n",
    "        return processed_words\n",
    "\n",
    "    def preprocess_corpus(self, texts):\n",
    "        \"\"\"Preprocess entire corpus\"\"\"\n",
    "\n",
    "        all_sentences = []\n",
    "\n",
    "        for text in texts:\n",
    "            if not isinstance(text, str):\n",
    "                continue\n",
    "\n",
    "            # Clean text\n",
    "            cleaned_text = self.clean_text(text)\n",
    "\n",
    "            # Tokenize and process\n",
    "            processed = self.tokenize_text(cleaned_text)\n",
    "\n",
    "            if self.keep_sentences:\n",
    "                all_sentences.extend(processed)\n",
    "            else:\n",
    "                all_sentences.append(processed)\n",
    "\n",
    "        return all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b81f3-adeb-441b-b727-f35da412a55b",
   "metadata": {},
   "source": [
    "**What it does:**\n",
    "\n",
    "- **Cleans text**: Removes URLs, emails, extra spaces, and punctuation\n",
    "\n",
    "- **Converts to lowercase**: Makes all words consistent \n",
    "\n",
    "- **Tokenizes**: Splits text into sentences and individual words\n",
    "\n",
    "- **Filters words**: Removes very short/long words, numbers, and stopwords if needed\n",
    "\n",
    "- **Processes entire dataset**: Takes raw text and converts it into clean, organized sentences\n",
    "\n",
    "- **Customizable**: turn different cleaning options on/off\n",
    "\n",
    "**Result:** Transforms messy raw text like \"Alice's Adventures in Wonderland!\" into clean word lists like [\"alice\", \"adventures\", \"wonderland\"] that Word2Vec can effectively learn from. This preprocessing step is crucial for good Word2Vec performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b20243d-0896-4fe7-ac9d-88d4ce789873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2941 sentences\n",
      "Sample sentence: ['alice', 'adventures', 'in', 'wonderland']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "preprocessor = AdvancedTextPreprocessor(\n",
    "    lowercase=True,\n",
    "    remove_punctuation = True,\n",
    "    remove_numbers=True,\n",
    "    remove_stopwords=False,  # Keep stopwords for Word2Vec\n",
    "    lemmatize=False,  # Usually not needed for Word2Vec\n",
    "    keep_sentences=True\n",
    ")\n",
    "\n",
    "# Processing corpus\n",
    "processed_sentences = preprocessor.preprocess_corpus(texts)\n",
    "print(f\"Processed {len(processed_sentences)} sentences\")\n",
    "print(f\"Sample sentence: {processed_sentences[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0c09f-fc4b-47ca-b4f6-fc1475d36863",
   "metadata": {},
   "source": [
    "\n",
    "This code **creates a text preprocessor with specific settings and cleans the Alice in Wonderland text**.\n",
    "\n",
    "**What it does:**\n",
    "- **Creates preprocessor**: Sets up cleaning rules (lowercase, remove punctuation/numbers, keep stopwords)\n",
    "- **Processes your dataset**: Runs the preprocessor on the text\n",
    "- **Converts raw text**: Transforms messy text into clean sentences of word lists\n",
    "- **Shows results**: Displays how many sentences were processed and shows a sample cleaned sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9bf7bda-5143-418d-88c1-97c5cbfdcefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['alice', 'adventures', 'in', 'wonderland'],\n",
       " ['the', 'millennium', 'fulcrum', 'edition'],\n",
       " ['down', 'the', 'rabbithole']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ee4be-4863-4b57-bb25-0aca97183ff5",
   "metadata": {},
   "source": [
    "### **3.4 Training Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41c5a45b-9d16-4b05-ac4c-1813f89a5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_parameters(corpus_size, vocab_size, domain_type, computing_resources):\n",
    "    \"\"\"\n",
    "    Recommend Word2Vec parameters based on corpus characteristics\n",
    "\n",
    "    Args:\n",
    "        corpus_size: Number of sentences/documents\n",
    "        vocab_size: Unique words in vocabulary\n",
    "        domain_type: 'general', 'technical', 'social_media', 'academic'\n",
    "        computing_resources: 'limited', 'moderate', 'high'\n",
    "    \"\"\"\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    # Vector size based on corpus and vocab size\n",
    "    if corpus_size < 10000:\n",
    "        recommendations['vector_size'] = 50\n",
    "    elif corpus_size < 100000:\n",
    "        recommendations['vector_size'] = 100\n",
    "    elif corpus_size < 1000000:\n",
    "        recommendations['vector_size'] = 200\n",
    "    else:\n",
    "        recommendations['vector_size'] = 300\n",
    "\n",
    "    # Window size based on domain\n",
    "    domain_windows = {\n",
    "        'general': 5,\n",
    "        'technical': 3,  # More syntactic focus\n",
    "        'social_media': 4,\n",
    "        'academic': 6    # More semantic focus\n",
    "    }\n",
    "    recommendations['window'] = domain_windows.get(domain_type, 5)\n",
    "\n",
    "    # Min count based on corpus size\n",
    "    if corpus_size < 10000:\n",
    "        recommendations['min_count'] = 1\n",
    "    elif corpus_size < 100000:\n",
    "        recommendations['min_count'] = 2\n",
    "    elif corpus_size < 1000000:\n",
    "        recommendations['min_count'] = 5\n",
    "    else:\n",
    "        recommendations['min_count'] = 10\n",
    "\n",
    "    # Algorithm selection\n",
    "    if domain_type in ['technical', 'academic']:\n",
    "        recommendations['sg'] = 1  # Skip-gram for rare technical terms\n",
    "    else:\n",
    "        recommendations['sg'] = 0  # CBOW for general text\n",
    "\n",
    "    # Epochs based on corpus size and resources\n",
    "    if computing_resources == 'limited':\n",
    "        recommendations['epochs'] = 5\n",
    "    elif corpus_size < 100000:\n",
    "        recommendations['epochs'] = 15\n",
    "    else:\n",
    "        recommendations['epochs'] = 10\n",
    "\n",
    "    # Hierarchical softmax vs negative sampling\n",
    "    if vocab_size > 100000:\n",
    "        recommendations['hs'] = 1\n",
    "        recommendations['negative'] = 0\n",
    "    else:\n",
    "        recommendations['hs'] = 0\n",
    "        recommendations['negative'] = 10\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4cbcf-dd0d-4aa5-9366-624e0db0c851",
   "metadata": {},
   "source": [
    "\n",
    "This code **automatically suggests the best Word2Vec training settings** based on the dataset characteristics.\n",
    "\n",
    "**What it does:**\n",
    "- **Analyzes the data**: Takes corpus size, vocabulary size, text type, and computing power as input\n",
    "- **Recommends vector size**: Bigger datasets get higher-dimensional word vectors (50-300 dimensions)\n",
    "- **Sets window size**: How many surrounding words to consider (3-6 words)\n",
    "- **Chooses algorithm**: CBOW for general text, Skip-gram for technical/academic text\n",
    "- **Determines training time**: More epochs for smaller datasets, fewer for larger ones\n",
    "- **Optimizes performance**: Selects best training method based on vocabulary size\n",
    "\n",
    "**Result:** Instead of guessing Word2Vec parameters, we get smart recommendations tailored to  dataset - like \"use 100-dimension vectors, 5-word window, CBOW algorithm, 15 epochs\" for optimal training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5793ce6d-23a8-4d0f-808a-0b5bfbd3a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Size: 2941\n",
      "Vocabulary Size: 2519\n"
     ]
    }
   ],
   "source": [
    "corpus_size = len(processed_sentences)\n",
    "print(f\"Corpus Size: {corpus_size}\")\n",
    "\n",
    "# Calculate vocabulary size (unique words in vocabulary)\n",
    "vocab = set(word for sentence in processed_sentences for word in sentence)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7719410-4745-4935-99cd-a4fb8f420e96",
   "metadata": {},
   "source": [
    "- Calculates key statistics about processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ac2f3839-d17f-4cf1-b3b2-2fad0a7cc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended parameters: {'vector_size': 50, 'window': 6, 'min_count': 1, 'sg': 1, 'epochs': 15, 'hs': 0, 'negative': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = recommend_parameters(\n",
    "    corpus_size=corpus_size,\n",
    "    vocab_size=vocab_size,\n",
    "    domain_type='academic',\n",
    "    computing_resources='moderate'\n",
    ")\n",
    "print(\"Recommended parameters:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b677a-1849-4117-976e-bf055d651e66",
   "metadata": {},
   "source": [
    "This code **gets personalized Word2Vec training recommendations** for the specific dataset.\n",
    "\n",
    "**What it does:**\n",
    "- **Uses data stats**: Takes actual corpus size and vocabulary size\n",
    "- **Sets domain type**: Specifies 'general' text (since Alice is general literature, not technical)\n",
    "- **Sets computing power**: Uses 'moderate' resources (standard laptop/desktop)\n",
    "- **Gets recommendations**: Returns optimal parameter settings tailored to your dataset\n",
    "- **Shows results**: Displays the recommended settings like vector size, window size, epochs, etc.\n",
    "\n",
    "**Result:** output like \"Recommended parameters: {'vector_size': 100, 'window': 5, 'min_count': 2, 'sg': 0, 'epochs': 15}\" - gives the perfect settings to train Word2Vec effectively on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77f41e-84b7-4a6f-9f74-c8a27c2e71ed",
   "metadata": {},
   "source": [
    "### **3.5 Step-by-Step Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04beb293-9f10-4454-8a95-77a2bdf60945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f96074-a056-4c41-9bdf-abf6ec567306",
   "metadata": {},
   "source": [
    "**Gensim** is a Python library specifically designed for topic modeling and document similarity analysis. \n",
    "\n",
    "Main Purpose:\n",
    "\n",
    "- Processes large collections of text documents\n",
    "- Extracts semantic patterns and relationships between words\n",
    "- Creates mathematical representations of text meaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ccb511e-36e4-44ae-b49f-76535d4425c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import time\n",
    "import multiprocessing\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \"\"\"Callback to log information about training progress\"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.start_time = time.time()\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"Epoch #{self.epoch} start\")\n",
    "    def on_epoch_end(self, model):\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"Epoch #{self.epoch} end - Time elapsed: {elapsed:.2f}s\")\n",
    "        self.epoch += 1\n",
    "def train_word2vec_model(sentences, save_path=None, **params):\n",
    "    \"\"\"\n",
    "    Train Word2Vec model with given parameters\n",
    "    Args:\n",
    "        sentences: List of tokenized sentences\n",
    "        save_path: Path to save the model\n",
    "        **params: Word2Vec parameters\n",
    "    \"\"\"\n",
    "    # Set default parameters optimized for Alice in Wonderland dataset\n",
    "    default_params = {\n",
    "        'vector_size': 150,\n",
    "        'window': 8,\n",
    "        'min_count': 2,\n",
    "        'workers': multiprocessing.cpu_count() - 1,\n",
    "        'sg': 0,  # Skip-gram\n",
    "        'epochs': 50,\n",
    "        'alpha': 0.025,\n",
    "        'min_alpha': 0.0001,\n",
    "        'hs': 0,\n",
    "        'negative': 15\n",
    "    }\n",
    "    # Update with provided parameters\n",
    "    default_params.update(params)\n",
    "    print(\"Training Word2Vec model with parameters:\")\n",
    "    for key, value in default_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    # Add callback for progress monitoring\n",
    "    epoch_logger = EpochLogger()\n",
    "    # Train the model\n",
    "    print(f\"\\nTraining on {len(sentences)} sentences...\")\n",
    "    start_time = time.time()\n",
    "    model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        callbacks=[epoch_logger],\n",
    "        **default_params\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Vocabulary size: {len(model.wv)} words\")\n",
    "    # Save model if path provided\n",
    "    if save_path:\n",
    "        model.save(save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc3d8f-6d27-4bd4-b99a-35dbb1f32b1a",
   "metadata": {},
   "source": [
    "- Sets up the complete Word2Vec training infrastructure with progress monitoring and customizable parameters.\n",
    "\n",
    "- A complete Word2Vec training system that will show real-time progress as it learns word relationships from the dataset. When we call this function later, it will train the model and give detailed feedback about the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ab17e9f-3209-4ecd-92ba-8ca8f40da4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec model with parameters:\n",
      "  vector_size: 150\n",
      "  window: 8\n",
      "  min_count: 2\n",
      "  workers: 9\n",
      "  sg: 1\n",
      "  epochs: 50\n",
      "  alpha: 0.025\n",
      "  min_alpha: 0.0001\n",
      "  hs: 0\n",
      "  negative: 15\n",
      "  compute_loss: True\n",
      "\n",
      "Training on 2941 sentences...\n",
      "Epoch #0 start\n",
      "Epoch #0 end - Time elapsed: 0.07s\n",
      "Epoch #1 start\n",
      "Epoch #1 end - Time elapsed: 0.12s\n",
      "Epoch #2 start\n",
      "Epoch #2 end - Time elapsed: 0.17s\n",
      "Epoch #3 start\n",
      "Epoch #3 end - Time elapsed: 0.22s\n",
      "Epoch #4 start\n",
      "Epoch #4 end - Time elapsed: 0.26s\n",
      "Epoch #5 start\n",
      "Epoch #5 end - Time elapsed: 0.31s\n",
      "Epoch #6 start\n",
      "Epoch #6 end - Time elapsed: 0.36s\n",
      "Epoch #7 start\n",
      "Epoch #7 end - Time elapsed: 0.41s\n",
      "Epoch #8 start\n",
      "Epoch #8 end - Time elapsed: 0.45s\n",
      "Epoch #9 start\n",
      "Epoch #9 end - Time elapsed: 0.50s\n",
      "Epoch #10 start\n",
      "Epoch #10 end - Time elapsed: 0.55s\n",
      "Epoch #11 start\n",
      "Epoch #11 end - Time elapsed: 0.60s\n",
      "Epoch #12 start\n",
      "Epoch #12 end - Time elapsed: 0.65s\n",
      "Epoch #13 start\n",
      "Epoch #13 end - Time elapsed: 0.69s\n",
      "Epoch #14 start\n",
      "Epoch #14 end - Time elapsed: 0.74s\n",
      "Epoch #15 start\n",
      "Epoch #15 end - Time elapsed: 0.79s\n",
      "Epoch #16 start\n",
      "Epoch #16 end - Time elapsed: 0.84s\n",
      "Epoch #17 start\n",
      "Epoch #17 end - Time elapsed: 0.89s\n",
      "Epoch #18 start\n",
      "Epoch #18 end - Time elapsed: 0.93s\n",
      "Epoch #19 start\n",
      "Epoch #19 end - Time elapsed: 0.98s\n",
      "Epoch #20 start\n",
      "Epoch #20 end - Time elapsed: 1.03s\n",
      "Epoch #21 start\n",
      "Epoch #21 end - Time elapsed: 1.08s\n",
      "Epoch #22 start\n",
      "Epoch #22 end - Time elapsed: 1.13s\n",
      "Epoch #23 start\n",
      "Epoch #23 end - Time elapsed: 1.17s\n",
      "Epoch #24 start\n",
      "Epoch #24 end - Time elapsed: 1.22s\n",
      "Epoch #25 start\n",
      "Epoch #25 end - Time elapsed: 1.27s\n",
      "Epoch #26 start\n",
      "Epoch #26 end - Time elapsed: 1.32s\n",
      "Epoch #27 start\n",
      "Epoch #27 end - Time elapsed: 1.37s\n",
      "Epoch #28 start\n",
      "Epoch #28 end - Time elapsed: 1.41s\n",
      "Epoch #29 start\n",
      "Epoch #29 end - Time elapsed: 1.46s\n",
      "Epoch #30 start\n",
      "Epoch #30 end - Time elapsed: 1.51s\n",
      "Epoch #31 start\n",
      "Epoch #31 end - Time elapsed: 1.56s\n",
      "Epoch #32 start\n",
      "Epoch #32 end - Time elapsed: 1.61s\n",
      "Epoch #33 start\n",
      "Epoch #33 end - Time elapsed: 1.66s\n",
      "Epoch #34 start\n",
      "Epoch #34 end - Time elapsed: 1.70s\n",
      "Epoch #35 start\n",
      "Epoch #35 end - Time elapsed: 1.75s\n",
      "Epoch #36 start\n",
      "Epoch #36 end - Time elapsed: 1.80s\n",
      "Epoch #37 start\n",
      "Epoch #37 end - Time elapsed: 1.85s\n",
      "Epoch #38 start\n",
      "Epoch #38 end - Time elapsed: 1.90s\n",
      "Epoch #39 start\n",
      "Epoch #39 end - Time elapsed: 1.95s\n",
      "Epoch #40 start\n",
      "Epoch #40 end - Time elapsed: 1.99s\n",
      "Epoch #41 start\n",
      "Epoch #41 end - Time elapsed: 2.04s\n",
      "Epoch #42 start\n",
      "Epoch #42 end - Time elapsed: 2.09s\n",
      "Epoch #43 start\n",
      "Epoch #43 end - Time elapsed: 2.14s\n",
      "Epoch #44 start\n",
      "Epoch #44 end - Time elapsed: 2.19s\n",
      "Epoch #45 start\n",
      "Epoch #45 end - Time elapsed: 2.24s\n",
      "Epoch #46 start\n",
      "Epoch #46 end - Time elapsed: 2.29s\n",
      "Epoch #47 start\n",
      "Epoch #47 end - Time elapsed: 2.34s\n",
      "Epoch #48 start\n",
      "Epoch #48 end - Time elapsed: 2.39s\n",
      "Epoch #49 start\n",
      "Epoch #49 end - Time elapsed: 2.44s\n",
      "\n",
      "Training completed in 2.44 seconds\n",
      "Vocabulary size: 1396 words\n",
      "Model saved to my_word2vec_model.model\n"
     ]
    }
   ],
   "source": [
    "# Example usage optimized for Alice in Wonderland dataset\n",
    "model = train_word2vec_model(\n",
    "    sentences=processed_sentences,\n",
    "    save_path='my_word2vec_model.model',\n",
    "    vector_size=150,\n",
    "    window=8,\n",
    "    min_count=2,\n",
    "    epochs=50,\n",
    "    sg=1,\n",
    "    negative=15,\n",
    "    compute_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad9156-b306-4f43-8b45-f6d941668776",
   "metadata": {},
   "source": [
    "- Trains the model on the dataset using the training function defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60bdc9ba-676a-48f6-bfe3-85e81c715c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 1396\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(model.wv.index_to_key)\n",
    "print(\"Vocabulary Size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e3442-dac5-4bdb-b58d-33bc12e8cbde",
   "metadata": {},
   "source": [
    "- Checks how many unique words trained Word2Vec model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "884740b3-f199-4be0-a3a2-67a35aa0fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Words in Vocabulary: ['the', 'and', 'to', 'it', 'she', 'of', 'said', 'you', 'in', 'was']\n"
     ]
    }
   ],
   "source": [
    "all_words = model.wv.index_to_key\n",
    "print(\"All Words in Vocabulary:\", all_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7901893-0c7f-4aa4-ae76-db33d5fefacd",
   "metadata": {},
   "source": [
    "### **3.6 Model Evaluation and Validation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ead98127-e9b7-43d9-8bfb-bad029ba607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/macbookairm4chip/Desktop/DAM202-SEM5/Practical1/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class Word2VecEvaluator:\n",
    "    \"\"\"Comprehensive evaluation suite for Word2Vec models\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.wv = model.wv\n",
    "\n",
    "    def evaluate_word_similarity(self, word_pairs_with_scores):\n",
    "        \"\"\"\n",
    "        Evaluate model on word similarity datasets\n",
    "\n",
    "        Args:\n",
    "            word_pairs_with_scores: List of tuples (word1, word2, human_score)\n",
    "\n",
    "        Returns:\n",
    "            Spearman correlation with human judgments\n",
    "        \"\"\"\n",
    "\n",
    "        model_similarities = []\n",
    "        human_similarities = []\n",
    "\n",
    "        for word1, word2, human_score in word_pairs_with_scores:\n",
    "            try:\n",
    "                model_sim = self.wv.similarity(word1, word2)\n",
    "                model_similarities.append(model_sim)\n",
    "                human_similarities.append(human_score)\n",
    "            except KeyError:\n",
    "                # Skip if words not in vocabulary\n",
    "                continue\n",
    "\n",
    "        if len(model_similarities) < 3:\n",
    "            print(\"Warning: Too few valid word pairs for reliable evaluation\")\n",
    "            return None\n",
    "\n",
    "        correlation, p_value = spearmanr(human_similarities, model_similarities)\n",
    "\n",
    "        print(f\"Word Similarity Evaluation:\")\n",
    "        print(f\"Valid pairs: {len(model_similarities)}\")\n",
    "        print(f\"Spearman correlation: {correlation:.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "        return correlation\n",
    "\n",
    "    def evaluate_analogies(self, analogy_dataset):\n",
    "        \"\"\"\n",
    "        Evaluate model on word analogy tasks\n",
    "\n",
    "        Args:\n",
    "            analogy_dataset: List of tuples (word_a, word_b, word_c, word_d)\n",
    "                           representing \"word_a is to word_b as word_c is to word_d\"\n",
    "\n",
    "        Returns:\n",
    "            Accuracy on analogy task\n",
    "        \"\"\"\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        #('alice', 'girl', 'rabbit', 'animal'),\n",
    "        for word_a, word_b, word_c, expected_d in analogy_dataset:\n",
    "            try:\n",
    "                # Predict word_d\n",
    "                result = self.wv.most_similar(\n",
    "                    positive=[word_b, word_c],\n",
    "                    negative=[word_a],\n",
    "                    topn=1\n",
    "                )\n",
    "\n",
    "                predicted_d = result\n",
    "\n",
    "                if predicted_d[0][0].lower() == expected_d.lower():\n",
    "                    correct += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "            except (KeyError, IndexError):\n",
    "                # Skip if words not in vocabulary\n",
    "                continue\n",
    "\n",
    "        if total == 0:\n",
    "            print(\"Warning: No valid analogies found\")\n",
    "            return 0\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f\"Analogy Evaluation:\")\n",
    "        print(f\"Valid analogies: {total}\")\n",
    "        print(f\"Correct predictions: {correct}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def evaluate_odd_one_out(self, word_groups):\n",
    "        \"\"\"\n",
    "        Evaluate model's ability to identify odd words in groups\n",
    "\n",
    "        Args:\n",
    "            word_groups: List of lists, each containing words where one doesn't belong\n",
    "\n",
    "        Returns:\n",
    "            Accuracy on odd-one-out task\n",
    "        \"\"\"\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for group in word_groups:\n",
    "            if len(group) < 3:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Find the word that doesn't match others\n",
    "                odd_word = self.wv.doesnt_match(group)\n",
    "\n",
    "                # This is tricky - we need ground truth to evaluate properly\n",
    "                # For now, just check if the model can identify AN odd word\n",
    "                correct += 1  # Placeholder - you'd need labeled data\n",
    "                total += 1\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        if total == 0:\n",
    "            return 0\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f\"Odd-One-Out Evaluation:\")\n",
    "        print(f\"  Valid groups: {total}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def analyze_vocabulary_coverage(self, test_texts):\n",
    "        \"\"\"\n",
    "        Analyze how well model vocabulary covers test texts\n",
    "\n",
    "        Args:\n",
    "            test_texts: List of text strings\n",
    "\n",
    "        Returns:\n",
    "            Coverage statistics\n",
    "        \"\"\"\n",
    "\n",
    "        vocab = set(self.wv.index_to_key)\n",
    "\n",
    "        total_words = 0\n",
    "        covered_words = 0\n",
    "        unknown_words = set()\n",
    "\n",
    "        for text in test_texts:\n",
    "            words = text.lower().split()\n",
    "            total_words += len(words)\n",
    "\n",
    "            for word in words:\n",
    "                if word in vocab:\n",
    "                    covered_words += 1\n",
    "                else:\n",
    "                    unknown_words.add(word)\n",
    "\n",
    "        coverage_ratio = covered_words / total_words if total_words > 0 else 0\n",
    "\n",
    "        print(f\"Vocabulary Coverage Analysis:\")\n",
    "        print(f\"  Total words in test: {total_words}\")\n",
    "        print(f\"  Covered words: {covered_words}\")\n",
    "        print(f\"  Coverage ratio: {coverage_ratio:.4f}\")\n",
    "        print(f\"  Unknown words: {len(unknown_words)}\")\n",
    "\n",
    "        return {\n",
    "            'coverage_ratio': coverage_ratio,\n",
    "            'unknown_words': list(unknown_words)[:20],  # Show first 20\n",
    "            'total_unknown': len(unknown_words)\n",
    "        }\n",
    "\n",
    "    def compare_with_baseline(self, baseline_model, test_words):\n",
    "        \"\"\"\n",
    "        Compare model performance with baseline model\n",
    "\n",
    "        Args:\n",
    "            baseline_model: Another Word2Vec model to compare against\n",
    "            test_words: List of words to test\n",
    "\n",
    "        Returns:\n",
    "            Comparison statistics\n",
    "        \"\"\"\n",
    "\n",
    "        common_words = []\n",
    "        for word in test_words:\n",
    "            if word in self.wv and word in baseline_model.wv:\n",
    "                common_words.append(word)\n",
    "\n",
    "        if len(common_words) < 3:\n",
    "            print(\"Warning: Too few common words for reliable comparison\")\n",
    "            return None\n",
    "\n",
    "        # Compare similarity patterns\n",
    "        similarities = []\n",
    "\n",
    "        for i, word1 in enumerate(common_words[:10]):  # Test subset\n",
    "            for word2 in common_words[i+1:11]:  # Avoid too many comparisons\n",
    "\n",
    "                sim1 = self.wv.similarity(word1, word2)\n",
    "                sim2 = baseline_model.wv.similarity(word1, word2)\n",
    "\n",
    "                similarities.append((sim1, sim2))\n",
    "\n",
    "        model_sims = [s[0] for s in similarities]\n",
    "        baseline_sims = [s[1] for s in similarities]\n",
    "\n",
    "        correlation, _ = spearmanr(model_sims, baseline_sims)\n",
    "\n",
    "        print(f\"Model Comparison:\")\n",
    "        print(f\"  Common vocabulary: {len(common_words)}\")\n",
    "        print(f\"  Similarity correlation: {correlation:.4f}\")\n",
    "\n",
    "        return correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50020e3d-058a-45ce-ba27-1ac50301933f",
   "metadata": {},
   "source": [
    "- Creates a comprehensive evaluation toolkit that tests how well the model performs across different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d9095893-566c-4261-9321-3805657e2ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Similarity Evaluation:\n",
      "Valid pairs: 4\n",
      "Spearman correlation: 0.4000\n",
      "P-value: 0.6000\n",
      "Analogy Evaluation:\n",
      "Valid analogies: 3\n",
      "Correct predictions: 1\n",
      "Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Example evaluation datasets optimized for Alice in Wonderland\n",
    "word_similarity_pairs = [\n",
    "    ('alice', 'girl', 8.5),\n",
    "    ('rabbit', 'hare', 9.2),\n",
    "    ('queen', 'king', 8.3),\n",
    "    ('mad', 'crazy', 7.8),\n",
    "    ('tea', 'party', 6.1),\n",
    "    ('big', 'small', 2.1),\n",
    "]\n",
    "\n",
    "analogy_examples = [\n",
    "    ('alice', 'girl', 'rabbit', 'animal'),\n",
    "    ('queen', 'hearts', 'king', 'hearts'),\n",
    "    ('big', 'bigger', 'small', 'smaller'),\n",
    "    ('mad', 'hatter', 'march', 'hare'),\n",
    "]\n",
    "\n",
    "# Usage example\n",
    "evaluator = Word2VecEvaluator(model)\n",
    "sim_score = evaluator.evaluate_word_similarity(word_similarity_pairs)\n",
    "analogy_score = evaluator.evaluate_analogies(analogy_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e30225-ec0f-40bc-a64d-db895405c8df",
   "metadata": {},
   "source": [
    "- Creates improved evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8aee9453-8a69-4ec9-9efc-f6b830d942b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'alice':\n",
      "she: 0.5103\n",
      "uncomfortable: 0.5008\n",
      "cautiously: 0.4914\n",
      "pleaded: 0.4743\n",
      "thoughtfully: 0.4721\n",
      "grave: 0.4625\n",
      "proud: 0.4607\n",
      "tasted: 0.4560\n",
      "doubtfully: 0.4531\n",
      "quickly: 0.4521\n"
     ]
    }
   ],
   "source": [
    "word = \"alice\"\n",
    "if word in model.wv:\n",
    "    similar_words = model.wv.most_similar(word, topn=10)\n",
    "    print(f\"Most similar words to '{word}':\")\n",
    "    for similar_word, similarity in similar_words:\n",
    "        print(f\"{similar_word}: {similarity:.4f}\")\n",
    "else:\n",
    "    print(\"Word is not in the vocabulary.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31b143-d38a-44b4-9fab-030ca85f376e",
   "metadata": {},
   "source": [
    " - Tests if the word \"alice\" exists in your model and shows the 10 most similar words to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ee3cc88-3c89-4da4-8028-0eb35dd9c9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28855118"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('alice', 'rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c82640-68ce-4628-9d4a-d363a31678ac",
   "metadata": {},
   "source": [
    "- Calculates the direct similarity score between the words \"alice\" and \"rabbit\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
