{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2530a5fc-e6a7-4074-b6cf-21f700a87a7b",
   "metadata": {},
   "source": [
    "## **0. Change working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20e74ec7-71aa-4bcc-b42d-e59effea371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/Users/macbookairm4chip/Desktop/DAM202/Practical2\" # Your Working Directory\n",
    "import os\n",
    "os.chdir(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba58cf-a68f-4625-a163-d964c51134c2",
   "metadata": {},
   "source": [
    "- Set up working directory for the practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3a36453-f776-46f9-8f04-c1e6e77a2ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['optimized_alice_word2vec.model',\n",
       " 'bin',\n",
       " 'Untitled.ipynb',\n",
       " 'include',\n",
       " 'etc',\n",
       " 'pyvenv.cfg',\n",
       " 'my_word2vec_model.model',\n",
       " 'lib',\n",
       " 'text.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'share']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd4f3c-5316-4ce6-9267-cfe9ab2e6ece",
   "metadata": {},
   "source": [
    "- Lists all the files and folders in the directory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8aad9",
   "metadata": {},
   "source": [
    "## **1. Introduction**\n",
    "\n",
    "### **1.1 Need for Data Feed**\n",
    "\n",
    "While pretrained models like Google News Word2Vec are powerful, training our own model offers several advantages:\n",
    "\n",
    "* **Domain Specificity**: Captures terminology and relationships specific to our field (medical, legal, technical)\n",
    "* **Custom Vocabulary**: Includes words and phrases unique to your dataset\n",
    "* **Control**: Full control over training parameters and data quality\n",
    "* **Privacy**: No need to rely on external models for sensitive data\n",
    "* **Learning**: Deep understanding of how Word2Vec actually works\n",
    "\n",
    "### **The Neural Network Architecture**\n",
    "\n",
    "Word2Vec uses a simple neural network with three layers:\n",
    "\n",
    "* **Input Layer**: One-hot encoded word vectors\n",
    "* **Hidden Layer**: Dense representation (the embeddings we want)\n",
    "* **Output Layer**: Probability distribution over vocabulary\n",
    "\n",
    "### **1.2 CBOW vs Skip-gram Training**\n",
    "\n",
    "#### **CBOW (Continuous Bag of Words):**\n",
    "* **Input**: Context words → **Output**: Center word\n",
    "* **Example**: [\"the\", \"cat\", \"on\", \"mat\"] → \"sat\"\n",
    "* **Advantages**: \n",
    "  - Faster training\n",
    "  - Better for frequent words\n",
    "  - Good for syntactic relationships\n",
    "\n",
    "#### **Skip-gram:**\n",
    "* **Input**: Center word → **Output**: Context words\n",
    "* **Example**: \"sat\" → [\"the\", \"cat\", \"on\", \"mat\"]\n",
    "* **Advantages**:\n",
    "  - Better for rare words\n",
    "  - Excellent for semantic relationships\n",
    "  - Slower training but higher quality\n",
    "\n",
    "## **2. Training Objectives**\n",
    "\n",
    "The model learns by:\n",
    "* **Maximizing** probability of actual word pairs that appear together\n",
    "* **Minimizing** probability of random word pairs (negative sampling)\n",
    "* **Adjusting** word vectors to achieve these objectives\n",
    "\n",
    "### **2.1 Key Training Concepts**\n",
    "\n",
    "#### **Context Window**\n",
    "Number of words around target word to consider:\n",
    "* **Small window (2-3)**: Captures syntactic relationships\n",
    "* **Large window (5-10)**: Captures semantic/topical relationships\n",
    "\n",
    "#### **Negative Sampling**\n",
    "Instead of computing probabilities for entire vocabulary, sample a few \"negative\" examples:\n",
    "* Dramatically speeds up training\n",
    "* 5-20 negative samples typically used\n",
    "\n",
    "#### **Hierarchical Softmax**\n",
    "Alternative to negative sampling using binary tree structure:\n",
    "* Better for rare words\n",
    "* More memory efficient for large vocabularies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7eaa0-da4b-46d8-996d-caf64c2882d9",
   "metadata": {},
   "source": [
    "### **3.1 Data Collection and Preparation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc1677f0-0455-4940-aba4-7ee949fa4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'r', encoding='utf-8') as f: # Remember your data set path should be specified if not in same working directory\n",
    "    texts = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7b6bb-9345-4beb-b23b-60e78414f247",
   "metadata": {},
   "source": [
    "What it does:\n",
    "\n",
    "- Opens the Alice in Wonderland text file\n",
    "- Reads every line from the file\n",
    "- Puts all those lines into a list called texts\n",
    "- Each line becomes one item in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3c63e03-2287-4d27-b3dc-a1e26dae6457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"                ALICE'S ADVENTURES IN WONDERLAND\\n\",\n",
       " '\\n',\n",
       " '                          Lewis Carroll\\n',\n",
       " '\\n',\n",
       " '               THE MILLENNIUM FULCRUM EDITION 3.0\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '                            CHAPTER I\\n']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf439553-be73-4a83-847e-48cc4a905188",
   "metadata": {},
   "source": [
    "### **3.2 Data Quality Assessment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "422f43ec-d649-46af-a81a-245970d1f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 3,598\n",
      "Vocabulary size: 4,950\n",
      "Unique Words: {'true):', \"back!'\", 'before.', 'waving', 'break', 'whom', \"puss,'\", 'forepaws', 'remain', 'persons', 'besides,', 'think,', 'drinking.', 'lessons,', \"queen,'\", 'though', \"with.'\", 'hopeless', 'coast', 'claws,', \"mean,'\", 'arms,', \"raw.'\", 'sun,', 'neck', 'way,', 'indignantly.', '`fourteenth', \"turtle.'\", 'knee', 'indeed.', \"`ugh!'\", 'fountains.', 'peering', 'drawling,', 'no!', 'sweet-tempered.', 'afford', 'injure', 'chrysalis--you', \"cat's\", '`shy,', 'duchess,', 'forwards', 'ann,', '`\"will', \"stay!'\", \"see.'\", 'pop', 'to-night,', 'do.', \"they've\", \"`ahem!'\", 'subject.', 'plates', 'thirteen,', '`sit', 'welcome', 'hare,', \"dinah'll\", 'honour,', \"me,'\", 'fading', 'tea.', 'suppress', 'strange,', 'howled', 'cat!', \"like?'\", '`lives', 'reaching', 'soon.', 'beg', 'afore', 'hoarsely', 'deeply', \"present!'\", 'clasped', 'shingle--will', 'daisies,', 'bats', 'to--to', 'sleep\"', 'end!', 'dinah', \"child,'\", 'suddenly', \"queen!'\", 'mice', 'ask!', 'could!', 'thing.', 'mark', 'reply.', 'you--are', 'often', '`crumbs', 'that;', 'stretching,', 'executed', 'canterbury,', '`soo--oop', 'lesson-book.', 'keep', 'returned', 'flat', \"them,'\", \"`that's\", 'happens.', 'would', 'we', 'be', 'deep', 'forget', 'remarked', 'next,', 'pulling', \"`hadn't\", 'barrowful', 'sea.', 'guessed', 'whatever', \"hand,'\", 'ordering', \"like.'\", 'wide,', 'explanation.', 'fancied', 'cup', 'golden', 'note-book,', 'bill!', 'children,', 'pleased', \"then?'\", 'earth!', \"so,'\", 'over.', 'five,', 'good-bye,', 'go!', 'her.', 'more.', 'size;', \"`why?'\", 'handed', 'washing', 'from', 'shape', \"twinkle--'\", 'prevent', '(dinah', \"william's\", 'hand,', \"fellow?'\", \"whiskers!'\", 'accustomed', 'crocodile', \"different!'\", 'croquet-ground', 'longed', 'slate--oh,', 'terms', 'shrieked', 'around,', '`dear,', \"on.'\", 'account', \"ears--'\", 'birds,)', 'thimble,', 'appear,', \"court.'\", 'promising,', \"duchess?'\", 'pence.', 'accounting', 'reach', 'jury', 'height.', 'knave,', 'spoon', \"story,'\", 'crept', 'mushroom', \"perhaps,'\", 'foolish', \"be.'\", 'table', 'happening.', 'tongue', 'disobey,', 'dreadfully', \"done.'\", 'wonderful', 'conclusion', 'marched', 'sensation', 'dance?\"\\'', \"hush!'\", 'down!', 'something,', 'laughed,', 'else', 'sides', 'kills', 'together:', 'hit', \"`hjckrrh!'\", 'twinkle,', \"up,'\", \"`they're\", 'earth.', \"`i've\", 'lived', '`poor', \"dinner!'\", 'shaped', \"nonsense,'\", 'duck:', 'us,', 'begun', \"not';\", 'undoing', 'whispered', 'bite.', \"end,'\", '\"twinkle,', 'soo--oop', 'history,', 'snail,', 'flowers', 'spoke--fancy', 'tears.', \"sea!'\", 'odd', 'learnt', '`speak', 'together.\"\\'', 'teapot.', 'little.', \"question?'\", 'walked', 'measure', 'follows', 'nasty,', 'hoarse', 'quarrel', 'voice', 'histories', \"axes,'\", 'ugly;', 'forehead', 'laughed', 'filled', 'involved', 'having', 'this;', \"tomorrow--'\", 'mad.', \"game,'\", 'completely.', 'stiff.', \"thing!'\", \"lessons!'\", 'confusion,', \"subject,'\", \"way?',\", 'water.', 'alice.', 'subjects', \"lizard's\", 'do:--', 'here,', 'gravy,', 'book', \"course,'\", 'cat,', \"here!'\", 'fight', 'belongs', 'balanced', \"outside.'\", '`collar', 'won,', \"late!'\", 'that', 'keeping', 'hour', '\"it\"', 'moved.', 'snorting', \"lady,'\", 'bursting', 'rule,', 'swam', '\"french,', 'green', 'to-day!', 'skimming', 'idea', 'eagerly,', 'head--', 'against', 'them,', 'beautify', \"`you'd\", 'green,', 'hatter', 'sign', 'multiplication', 'him;', 'pray,', 'friend', \"i'm\", 'falling', 'summer', 'bottle,', 'quickly', 'wanted', 'thrown', 'made', 'ways', '`drive', 'that:', 'top', \"hasn't\", 'mad', 'adventures,', 'made.', 'bottle', 'gryphon,', 'noticed', 'first--verdict', 'rabbit.', \"isn't\", 'machines', 'again;', 'fallen', 'tarts,', 'is--\"birds', 'altogether', 'threw', 'stingy', '`advance', 'been,', 'shark,', \"uglifying!'\", 'themselves', 'brightened', \"together!'\", 'farther', \"life!'\", 'arm', 'day!', 'is--\"the', 'inwards,', 'fur', \"true,'\", \"yet.'\", 'classics', 'book,', 'roof', 'footmen,', \"queen?'\", 'serpent.', 'trial', 'trying', 'kneel', \"`very,'\", 'plan,', 'soup,\"', 'mustard', 'splashed', 'oh!', 'first', 'ferrets', 'ought', 'own', 'insolence', 'remaining', 'though),', \"she'll\", 'side', 'baby;', 'leaves.', 'grinning', 'sand', \"stuff,'\", 'catch', 'croqueted', \"shiny?'\", \"longer!'\", 'denies', \"tortoise--'\", 'think:', 'wandered', \"draw,'\", 'sigh:', 'really', \"man.'\", 'flying', \"m--'\", 'door;', 'with,', 'larger,', 'floor:', 'seems', 'ground--and', '`stuff', 'day-school,', \"shoes!'\", 'push', 'dear!', 'difficulty,', 'dancing', 'authority', \"dinn--'\", 'jury,', 'hurt', 'beloved', 'talking', 'character,', 'queerest', '`oh!', 'pieces.', 'hear', 'chin.', \"girl,'\", 'xii', 'thousand', 'belong', 'write', 'before,', 'lobster', 'position', 'mouths--and', 'meeting', 'alarm', 'appealed', 'sigh,', \"you'll\", 'pocket,', 'bill', \"must,'\", \"washing?'\", 'other;', 'month', 'interrupted,', 'untwist', \"guilt,'\", 'now.', 'three,', 'larger:', 'yet', \"is?'\", 'anything', 'agree', 'dinner,', 'answer.', \"days.'\", 'growing', 'here', 'invented', 'school', \"ordered';\", 'grass,', 'meant', 'indeed:--', 'sensation,', 'sorrows,', 'temper.', 'duchess', 'applause,', \"off,'\", 'silence:', 'shoulders,', 'every', 'vanished.', \"room!'\", 'silence', 'spoke', 'teacup', 'rightly', 'straightening', 'somewhere', 'speak--and', '`or', 'enjoy', 'guinea-pigs,', 'worried.', 'verses', \"now.'\", 'eyes:', 'curtseying', 'opened,', 'history', \"rabbit'\", 'march', 'gloves--that', 'learn!', 'rapidly:', 'on;', 'quarrelling', 'seven.', 'lit', 'pulled', 'flustered', 'course,', 'dog', 'oblong', \"removed,'\", 'fear', 'yawning.', 'door.', 'eating', \"`she'd\", 'serpent,', \"pace,'\", \"dormouse's\", 'northumbria,', 'nothing:', 'out,', 'speech', 'depends', 'behind', 'mark;', 'officer', 'conquest.', \"time?'\", 'usurpation', 'over', \"nose';\", 'oh', 'fishes', \"here,'\", '\"uglification,\"\\'', 'too:', 'watching', 'might', \"that?'\", 'arches', 'airs!', '`why', 'nothing,', 'gone.', 'happy', 'unfolded', 'deeply.', \"one's\", 'me,', 'witness.', 'uncommonly', 'out', 'sneezes;', 'hungry,', 'curly', 'loving', 'does', '`just', \"duchess,'\", 'one--but', 'morning?', 'care', 'line:', 'nice,', \"wits!'\", 'alice)--', 'speed', 'pleasure', 'mine,', \"that's\", 'hippopotamus,', 'custody', 'crawling', \"cards!'\", 'croquet', 'lesson', 'knave.', 'yelp', 'party', 'advice,', 'adoption', 'knocking,', 'hurriedly', 'bat!', \"dream!'\", 'ii', 'confused', \"wonder?'\", 'pitied', 'notion', 'suppressed.', 'burnt,', 'frowning', 'jaw,', \"`--where's\", 'asking', '`flamingoes', 'down.', \"ever,'\", 'dance.', 'its', '`from', 'pool?', 'accident,', 'edgar', \"brother's\", \"next!'\", \"mushroom,'\", 'question.', \"finished,'\", 'them', 'pretend', 'us', 'geography.', 'flower-beds', \"idea,'\", 'england', 'again:', '`off', 'fish,', 'speech.', 'mice--oh,', \"bill,'\", \"do,'\", 'disagree', 'sharp', 'eggs', \"it!'\", \"think,'\", '`hand', 'uneasy:', 'towards', 'mouse--a', '`curiouser', \"asleep,'\", 'occurred', 'pattering', 'rich', 'dance', 'shoulders.', 'number', 'expression', 'purring', 'crash', 'asking!', 'hours,', '`did', 'see--how', 'terrier,', 'land', 'argued', 'children;', \"cats?'\", 'your', 'hurry;', 'hatter;', 'lips.', 'inquired', \"trying.'\", 'lost', 'baby,', 'run', 'head:', 'clean', 'growl', 'part', 'trembling', 'hair', 'low', 'rustling', 'joys,', 'absurd', 'paper.', 'bear?--mind', \"`wouldn't\", \"`never!'\", 'nine', 'succeeded', 'creature,', 'cut', '`two', 'ix', 'x', '(and,', 'sister,', 'excellent', 'rosetree;', 'declared', 'hurry,', \"seems,'\", '`seals,', 'me', 'other', 'seeing', 'presently', '`but', 'sing', \"`it'll\", \"figures!'\", \"william,'\", 'royal', 'home;', 'humbly:', 'be,', 'pieces', '`their', 'thoughtfully:', 'over;', 'eyes.', 'ugh,', \"m?'\", 'curtsey', 'round', \"needn't\", 'way--never', 'it', 'have', '`wake', 'off;', 'hoping', 'hands,', '(before', 'gained', \"afraid,'\", \"`poison,'\", 'dry', 'march,', 'grand', \"did!'\", 'lodging', 'out.', 'gravely.', 'haste,', 'face.', 'it.', 'circumstances.', 'glass.', 'liked', 'same', '`ten', 'just', '`well!', 'rabbit', \"up.'\", 'mournfully.', 'what?', 'try', 'merrily', 'now?', 'left,', 'glanced', 'trotting', \"was,'\", '`right,', \"do?'\", 'wants', 'brought', 'cackled', \"handwriting?'\", 'officers', 'familiarly', 'for?\"\\'', 'advance!', 'earls', \"fact.'\", 'handsome', 'law:', \"window!'\", 'supple', 'remarked,', 'crab', 'nearly', \"conversation?'\", 'hated', 'goose!', 'ma', 'talking.', 'addressed', 'turtle:', 'below', 'seen--everything', 'execute', 'paw', 'executioner:', 'miss', \"prizes.'\", \"won?'\", 'mouse.', 'turtle.', 'comes,', 'she,', 'garden.\"\\'', 'game.', 'high', 'crimson', 'locks', '`--yes,', 'dodo', 'direction', \"mind,'\", 'quadrille,', 'life', 'feeble,', \"treacle,'\", 'shouting', 'well', 'are!', '`it', \"fig?'\", 'worth', \"myself,'\", 'altogether,', 'ladder?--why,', 'millennium', 'also', 'himself,', 'merely', 'unrolled', 'coaxing', 'tremble.', 'open', 'tale', 'cheered.', 'small', \"thimble';\", 'using', \"sir,'\", 'interrupting', 'deepest', 'argument', '`call', 'questions', 'asleep', 'pack', 'wonderland', 'begged', 'say,', 'muchness\"--did', 'be\"--or', 'time,', \"whiting,'\", \"invited,'\", 'immense', \"stairs!'\", 'fumbled', \"`don't\", \"`they--you've\", 'inches', 'wept', \"fellow!'\", 'could,', \"dear!'\", 'yawned', '`sure', 'printed', 'four', 'treading', \"choice!'\", \"suppose.'\", 'spoken', 'loud', 'now', 'whispers', 'interrupted.', \"crazy!'\", 'miss,', \"music.'\", \"a--'\", 'manner', 'pressing', \"ada,'\", 'howling', 'doorway;', 'another!', 'enough', 'repeating', '`\"what', '`why,', 'all!', 'pounds!', 'conduct', 'spectacles.', 'engaged', 'pointing', 'shrill', 'normans--\"', 'tail', 'civil,', 'jogged', 'uncomfortably', \"`yes!'\", 'room,', 'deal:', 'hollow', 'soldiers', '`and', 'forgetting', 'tails', 'advise', '\"with', \"people,'\", 'snatch', \"doing?'\", 'snout', 'emphasis,', 'eyes--and', 'far!\"', 'box', 'ferrets!', '\"keep', 'banks,', 'company', '`are', 'livery,', 'about,', 'telescope!', 'son,', 'down,', 'hurried', 'hatching', 'explain', \"mayn't\", 'through', 'pleased.', 'croquet-ground.', 'played', 'bones', 'minutes.', 'noise', 'dropped', 'tiny', 'clamour', 'tulip-roots', 'lessen', 'jumped', 'means,', 'cunning', 'him.', 'politely;', 'suppose', 'violent', 'clever', 'turns', 'yours:', 'seen:', 'boxed', 'slowly,', 'attempt', '`eat', 'win,', 'itself,)', 'noises,', 'hatter.', '`come,', 'latitude', 'nose', 'mad--at', 'creature', 'man,', 'raven', 'deserved', 'prisoner', 'often,', 'heavy', 'laid', 'please:', '`rule', 'loveliest', 'child,', 'clearer', 'trial:', \"you.'\", \"window.'\", 'speak', \"confusing.'\", 'who', 'more', 'shoulder', '`--or', 'holding', 'they', 'rather', \"she's\", 'table,', \"mystery,'\", '--the', \"lesson-books!'\", 'rose-tree', '(and', 'added', 'gryphon', 'arms', \"`i'd\", 'in.', 'jack-in-the-box,', 'other.', 'solemnly.', 'outside,', 'long,', 'miles', 'vague', '`repeat,', 'both', 'submitted', 'pale', 'reeds--the', 'guard', 'frontispiece', 'taught', \"that'll\", \"window?'\", 'officers:', 'antipathies,', 'choke', 'remembering', \"ask.'\", 'get', \"hot-tempered,'\", 'back,', 'pepper-box', 'sight', 'ask', \"begin.'\", 'snappishly.', 'sitting', 'lessons', 'directly.', '`same', 'search', 'boy,', 'why,', '`for', \"answers.'\", 'nose.', 'toss', \"you,'\", 'smile:', 'more--as', 'exclamation', 'globe', 'nevertheless', \"cats.'\", 'least,', \"it--'\", 'rose', 'likely', 'herself,', 'took', 'knelt', \"enough!'\", 'well!', 'generally', 'obstacle', 'is--\"oh,', '`bring', 'play', 'twelve?', 'wider.', 'stool', 'uncommon', 'dates', 'shook', '`what', 'air.', 'feeling', \"egg!'\", 'signifies', 'trial,', 'climb', 'a-piece', 'matters', 'finds', 'understood', 'usual,', 'save', \"tongue!'\", 'audibly.', 'stopped', 'spades,', 'changing', 'pegs.', 'knowing', 'edge', '`w.', 'fellows', 'solemnly,', \"`i'm\", 'bent', 'remarking,', 'quietly,', \"evidence,'\", \"pocket?'\", \"mind.'\", 'air:', 'pencil', 'leading', \"sort!'\", 'yelled', 'trumpet,', 'either', 'plate', 'different.', 'walrus', '`give', 'person,', 'glaring', 'zigzag,', 'otherwise.\"\\'', 'cold', \"kind,'\", 'was!', 'thunderstorm.', 'saucepan', \"fancy--who's\", 'moving', \"didn't,'\", \"eggs,'\", 'denied,', 'paris', \"caterpillar's\", 'lovely', 'flower-pot', 'rome--no,', 'listen.', 'visit', 'temper,', \"names,'\", 'chose', \"`you!'\", '`stupid', \"onions.'\", 'him!', 'flamingo', 'proceed.', 'word', 'finished', 'wooden', 'certain', 'sorrowful', 'chimney?--nay,', 'altogether.', 'without--maybe', 'once.', 'pity', 'blades', 'wherever', 'abide', 'voices--`hold', 'sleepy,', 'off', 'makes', \"`they'd\", 'could.', 'slipped,', 'tea', 'on.', 'passage,', 'flock', 'livery', 'sighing.', 'tucked', 'pocket', 'rock,', 'crown', 'patted', 'double', 'shiver.', 'mind', 'clock', \"removed!'\", 'interrupt', 'easy', 'none,', 'puzzled,', 'nearer', 'conversations', 'course', 'riddles', 'uncomfortable,', 'afraid', 'tureen!', '`one,', 'poured', 'treat.', 'interest', \"alone!'\", 'unless', 'herself;', \"different,'\", 'sharply;', 'pointed', 'footman,', 'front', 'talk', 'head!\"\\'', '`fury', \"shall!'\", 'alas', 'expecting', 'read:--', 'rattling', 'children', 'help', \"weeks!'\", 'one!', 'hard', 'tea-things', 'patience', \"me.'\", 'majesty', 'over,', 'least', 'licking', \"which?'\", 'bathing', \"`well!'\", 'smallest', 'all,', 'yourself', 'many', 'wood.', 'cake.', 'listen', 'patiently.', 'pig,', \"yet!'\", 'up', \"day--'\", \"accusation!'\", 'written', 'undertone,', 'note-book', \"is.'\", 'but,', 'beds', 'muscular', 'way?', 'fork', \"caucus-race.'\", 'milk-jug', 'seem', 'crawled', 'turn', 'soup', 'farm-yard--while', 'suet;', \"duchess's\", \"spot.'\", 'afraid,', \"i!'\", 'for', \"`moral,'\", 'queer-looking', \"footman's\", 'down:', 'salt', 'slate', 'shakespeare,', 'listeners', 'knocked.', \"holiday?'\", 'helpless', 'steady', 'replied.', 'which', 'riper', 'said', 'neck,', \"bed!'\", 'certainly:', 'more;', \"watch!'\", \"way--'\", 'checked', 'seated', 'upset,', 'whisper', 'faintly', 'must', \"answer?'\", 'cook', 'triumphantly,', 'bound', \"dance,'\", 'footman.', 'swim.', 'large', \"pardon,'\", 'low.', 'indignantly,', 'name:', 'leap', 'diamonds,', 'capering', 'love,', 'my', 'opposite', 'child:', 'three-legged', \"trouble!'\", 'cat;', \"find?'\", 'ending', 'very', '`the', 'hookah,', 'lory,', \"weren't\", 'chance', 'looking-', 'night-air', 'know', 'savage', \"more.'\", 'blown', 'flung', 'dears!', 'tired', 'key,', 'him,)', 'looking', 'violently,', 'queen:', 'louder', 'wonder', 'rome,', \"proceed,'\", \"better,'\", 'tidy', 'interesting', 'narrow,', 'crowd', \"sea,'\", 'pretending', 'good-naturedly', 'foot,', \"sister's\", 'nowhere', 'ringlets', 'said;', 'uncorked', 'flapper', 'jaws', 'chimney', 'presented', 'skurried', 'tinkling', 'go.', 'may', 'that?--it', \"adventures.'\", 'catching', 'yet--oh!', 'tortoise', 'that--only', '`very', 'window,', 'tortoise,', \"them--'\", 'piteous', 'list', '`seven', 'one;', 'esq.', 'favourite', \"baby?'\", 'distance--but', '`allow', 'pigs,', \"one?'\", 'avoid', 'surprised', \"executioner's\", 'pat!', '`twinkle,', 'it,)', 'rabbit!', \"right?'\", 'books,', 'locks,', 'guests', \"pun!'\", 'pebbles', 'two,', 'wrong', 'duchess;', 'understand.', 'once', 'please,', 'ran.', 'ornamented', 'hanging', 'politely:', 'hers', 'over)', 'instance,', 'directed', \"didn't!'\", 'happens;', 'doubt', 'lock,', 'is', 'sight;', 'appear', 'begin', 'blame', 'harm', 'cucumber-frames', 'anxious', \"with,'\", \"dogs.'\", \"that.'\", 'court,\"', 'sharply', 'tight', 'corners:', 'twinkled', '\"i\\'ll', \"not,'\", 'prizes.', 'low,', 'stop.', 'kissed', '\"edwin', 'waste', '`up,', '`twenty-four', '`mary', 'mistake;', 'letter,', 'remained', 'place', '`at', 'mouse--o', \"`you'll\", \"puzzle!'\", 'panther', 'anger', 'then,', \"`shan't,'\", 'waited', 'while', 'sound.]', 'remembered', \"ache!'\", \"usual,'\", 'tiptoe,', 'what', 'rubbing', 'kindly,', 'effect,', 'different,', 'modern,', 'do', 'certain!', 'seaside', 'confused,', 'if--if', 'gloves', 'subdued', 'pleased,', 'fellow?', 'capital', \"beheaded!'\", 'doing', \"remarks,'\", 'france--', 'ring,', 'time).', 'air!', 'existence;', \"now!'\", 'decidedly,', '`does', 'curving', 'trampled', 'present--', \"below!'\", 'bee,\"', 'roughly', 'attended', '`would', 'disappeared;', 'neatly', 'remarkable', 'game', 'fetch', 'six', 'then', 'sixpence.', 'say', 'like,', 'things', 'puppy', 'turtle,', 'losing', 'scratching', 'is!', 'sneeze', \"serpent!'\", 'scroll', 'rubbed', 'as', 'race', 'moved', 'dinah!', 'lobsters', 'waistcoat-', \"`arrum.')\", 'refused', 'noticed,', \"`he's\", 'time!', 'squeezed', 'fall', 'examining', 'second', 'cat', \"bird,'\", 'mile', 'soldier', \"say--that's\", 'kindly', 'here;', 'finishing', 'long', 'tea,', 'steam-engine', 'sure', 'little--\"\\'', 'hoped)', 'kid', 'caterpillar', \"talk,'\", \"say!'\", 'games', 'five', 'nose,', \"we've\", 'mouse-traps,', 'busily', 'flat,', \"christmas.'\", 'draw,', 'wild', '`which', 'fellow!', \"lines!'\", 'now,', 'up,', '`shall', 'mine--a', 'see:', 'effect', 'king:', \"somebody.'\", 'solid', \"from?'\", 'provoking', 'muddle', 'reasonable', 'word,', \"maybe,'\", 'again:--', 'deal', 'youth,', 'flashed', '`i--i', '(for,', \"`here!'\", 'notice', 'evidently', '`go', 'afterwards,', 'eaten', 'meaning', '(not', 'poky', 'give', 'found', \"cup,'\", \"o'clock\", 'first,', 'dispute', 'kiss', \"she'd\", 'sobs.', 'pet:', 'ancient', 'plan', 'order', 'oneself', 'past', \"likes.'\", 'choosing', 'mabel,', 'quadrille', \"happen,'\", 'interrupted:', 'please', 'pigeon.', 'incessantly', 'teaching', \"shan't!\", 'contempt.', \"matter,'\", '--come,', 'raised', 'right-hand', \"pleases!'\", 'butter,', 'considered', 'chorus,', 'kitchen.', 'hands', '\"up', \"story.'\", \"i'd\", '`consider,', 'pair', 'story.', \"advantage,'\", \"couple?'\", 'advice', '`first', 'meat,', 'puzzled.', 'creatures,', 'speak,', 'corner--no,', 'court,', 'wood', \"now--don't\", 'telescope', 'peeped', 'sprawling', \"hedge!'\", '`behead', 'everybody', '(in', '`important--unimportant--', 'inclined', 'at!\"', 'label', \"prison,'\", '\"--said', 'passing', '`till', \"believe.'\", '`change', 'empty:', \"sir'\", 'lobsters,', 'tea-tray', 'lasted', 'again', \"won't,\", 'seven', 'duck.', 'snail.', 'salmon,', 'head.', 'house,', '(`which', 'go', 'busy', 'minding', 'did:', 'mouse?', '`no,', '`she', 'yesterday', 'stand,', 'unhappy.', \"off?'\", \"shorter.'\", 'room', 'days.', 'you?', \"knot!'\", \"curiouser!'\", '`then,', 'important', 'question,', 'them--and', '`i', 'dry,', 'feathers,', 'tipped', 'foot!', 'thought;', \"sorrow?'\", 'yours.\"\\'', 'cheeks,', 'extraordinary', 'make', 'gather', 'earnestly.', 'setting', 'feel', 'taste', 'wig,', 'fitted!', 'ugly', '`certainly', 'stupidly', 'night!', 'sage,', 'carefully,', 'away.', 'comfortable,', \"mouse!')\", 'leaves', \"wrong!'\", \"course.'\", 'kings', '`prizes!', 'stood', \"finished.'\", 'queen!', \"off.'\", 'purring,', 'opportunity', 'doubtfully,', 'chorus', 'sits', \"much!'\", 'more,', 'king;', 'delay', 'parts', 'something', \"guinea-pigs!'\", \"draw?'\", 'branches', \"are,'\", 'curiosity.', \"crumbs,'\", 'doubt:', 'laughter.', 'inside,', 'would,', 'liked,', '(for', 'bread-and-butter', 'answered,', \"table,'\", 'this.', 'long;', 'soldiers,', 'flew', 'daughter', 'think;', '(when', 'largest', 'moderate.', 'lose', 'doth', 'present', 'gallons', 'locked;', 'hatter,', 'tillie;', 'mostly', \"`you're\", 'already', 'declare', 'argue.', \"majesty?'\", 'rabbits.', 'puzzled.)', \"liked.'\", 'tie', 'snail', 'drawing', '`--well', \"garden!'\", 'under', 'tree', \"caucus-race?'\", 'spoke,', 'each', 'slate-pencil,', 'again.', 'appeared', \"`fifteenth,'\", 'proves', 'voice:--', 'sound', \"haven't\", 'them--all', 'open,', \"hadn't\", 'confusing', \"extremely--'\", \"is--'\", \"pie--'\", 'takes', 'life!', 'trees,', 'alive', 'truth:', '`cheshire', 'reminding', 'key;', 'lost,', 'funny', 'winter', 'from:', 'arranged;', 'tells', 'thump!', \"direction,'\", 'regular', 'pity!\"?\\'', 'actually', \"he'd\", 'bowed,', \"works!'\", 'cushion;', \"water-well,'\", 'it!--that', 'went,', 'eels,', 'distance', 'use', '`nine', \"teases.'\", 'natural);', 'ledge', 'hastily', 'day.', 'fur.', 'complained', 'people!', 'conclusion,', 'about.', 'lacie,', 'grave', 'duchess!', 'furrows;', 'right,', 'simply', \"savage!'\", \"whatever?'\", \"don't\", \"go,'\", \"`i--i'm\", 'dreadful', 'keep,', 'quick,', 'somebody', 'move', 'you,\"\\'', 'frog;', 'another', 'hastily,', 'courtiers,', 'a', 'understand', \"grin.'\", 'judge,', 'lizard)', 'stupid),', 'decidedly', 'vegetable.', 'ground', '--but', 'seemed', 'mallets', \"couldn't\", 'difficulty', \"they'd\", 'room.', 'watched', 'rapidly;', 'shock', \"refreshments!'\", 'began.', \"pardon!'\", 'absence,', 'strange', 'scream', \"to--'\", 'foot.', 'fan', 'cross-examine', 'listening,', 'wander', 'impatiently:', 'share', '`of', \"won't\", 'paint', \"sad?'\", 'older', 'place,', 'fly', \"tasted--'\", \"far,'\", 'gay', 'alice,', '`well,', 'waited.', \"jurors.'\", 'rabbit-hole--and', 'meekly:', 'fact,', \"witness.'\", 'things,', 'mischief,', 'cried', '`when', \"less,'\", 'saying,', 'impatiently;', 'riddles.--i', \"she,'\", 'gryphon:', 'nose--', 'energetic', 'side,', 'puppy;', 'trumpet', \"railway,'\", 'arrow.', 'hastily.', 'yours', \"like!'\", 'telescopes:', '`thinking', 'twenty-four', 'do,', 'such', 'back-somersault', 'yet,', 'vote', \"manage?'\", 'house', 'on?', 'railway', 'remark.', 'advance', 'slates;', 'lefthand', 'absurd,', 'grand,', 'when', 'drink', 'roots', 'moral,', 'pattern', 'glad', \"again.'\", \"all,'\", '`until', '`consider', 'indeed', 'sleepy;', 'ears', 'boldly:', 'complaining', 'thought:', 'else\"--but,', 'knuckles.', 'severely', 'grin', \"school,'\", '\"too', 'longer', 'week:', 'finding', 'know--no', 'rule:', 'hedgehogs;', 'moment.', 'upstairs,', 'useful,', 'sister;', \"`let's\", 'sorts', 'finger', \"`idiot!'\", \"means.'\", \"opinion,'\", \"fun?'\", \"wood,'\", 'tone,', 'since', \"again!'\", 'stuff', 'proud', 'sulkily', 'fanning', 'head,', 'thing', \"lessons,'\", 'all:', 'telling', '`nor', \"mouse's\", 'nearer,', 'o', \"be!'\", 'sharply.', 'our', 'added,', \"dormouse!'\", 'birthday', 'gryphon.', 'cannot', 'mouse,', 'sisters--they', '`\"--found', \"unimportant--important--'\", 'together', 'lately,', 'break.', 'quick', \"two!'\", '(though', 'again,', 'shining', 'terribly', 'reading', 'treated', \"ann!'\", \"toes?'\", \"verdict,'\", 'silence.', 'cushion,', 'mouths', 'rules', 'broken', 'cried.', 'cares', \"then,'\", 'angry.', 'not,', 'are;', 'ridges', 'wag', 'hoarse,', 'ann!', 'jurymen', 'smiling', 'life,', 'up:', 'begins', 'pity.', 'hare.', \"this!'\", '`explain', 'distant', 'gloomily:', 'beak--', 'branch', 'remark', 'drawling-master', 'solemnly', 'engraved', 'half', 'guinea-pig', 'arithmetic--', \"haven't,'\", 'nervous,', 'executes', 'no', 'think', \"d,'\", \"whatever,'\", \"it?'\", 'barking', 'eager', 'arches.', \"mine,'\", 'softly', 'closed', 'spread', \"indeed!'\", 'severity;', 'maps', 'this', \"any,'\", 'agony', '`write', 'spreading', 'directions,', 'farmer,', 'choked', 'pig', 'passage:', 'highest', 'together.', 'instead', \"too.'\", 'limbs', 'arm-chair', 'home!', \"them!'\", 'found:', 'favoured', 'grown', 'way!', 'remarking', 'upsetting', \"dogs?'\", \"happens!'\", 'itself', 'so,', 'first;', 'soup?', '(we', 'never-ending', 'uneasily', 'red.', 'grey', 'first.', 'mineral,', 'hurt,', 'ate', 'hare', 'whisper,', 'music,', 'carroll', \"temper!'\", 'are,', 'variations.', 'way', 'though,', 'whiting', 'eat\"', 'door', 'should', 'course--', '`you', '`silence', 'whiskers,', 'entrance', 'flamingoes,', 'words:--', 'repeat', 'garden--how', 'rose-tree,', 'cartwheels,', 'leant', 'schoolroom,', 'porpoise', 'eyelids,', 'must,', 'so--and', \"sort,'\", 'act', '\"you', \"home,'\", \"begin?'\", '`herald,', 'face,', 'go,', 'sneezes:', 'stairs!', \"house!'\", 'raving', 'knee,', 'comfort,', 'dormouse!', 'cheated', '`talking', 'vi', 'hall', 'cakes', 'birds!', 'simply--\"never', 'wrote', 'is,', 'skirt,', 'theirs,', 'mabel!', 'wasting', 'triumphantly.', 'trials,', 'began', 'general', 'distraction,', 'chorus.', 'courage,', 'fit', '`thank', 'cats', \"beginning!'\", 'still', 'pig-baby', 'bat,', 'hers--she', 'knee.', 'knew,', \"you?'\", \"tea--'\", 'two--\"', 'roast', 'pat,', 'boots', 'seriously,', 'lastly,', 'faster?\"', 'head', 'evidence', 'grinned', 'alive;', \"what?'\", 'newspapers,', '(a', 'pencils', '`because', 'chief', 'speech,', 'whereupon', 'usually', 'march--just', \"lower,'\", 'creatures', \"sky-rocket!'\", 'rearing', 'alarmed', 'children.', '\"coming', '`here!', 'there', \"things?'\", 'business,', 'were.', 'ye;', 'french', 'personal', 'persisted.', 'eel', 'with', 'ours', 'uncomfortable', 'sigh.', \"twice--'\", 'list,', 'turn;', 'furrow', 'making', \"turtle's\", 'further', 'caucus-race', '`nearly', 'continued,', 'real', 'tittered', 'wondered', 'waters', 'dodo.', 'feather', 'cheered,', 'sending', 'cheap', 'brain;', 'i,', 'lad!--here,', 'growing,', 'fifth', 'educations--in', 'some', 'used--and', '(if', 'tears!', 'gone,', 'kill', 'move.', 'wrapping', '*', \"bite,'\", 'at', 'alarm.', '`either', 'want', \"`who's\", 'i', \"history,'\", 'instantly,', 'queer,', 'father;', \"plan!'\", 'wise', \"`it's\", \"prizes?'\", 'slates.', \"think?'\", \"life.'\", 'sadly', 'speak.', 'tasted', '`o', 'result', '`than', \"idiotic!'\", 'turkey,', 'chimneys', 'court!', \"see!'\", 'fairy-tales,', \"others!'\", 'interrupted', 'staring', 'seen,', 'curls', 'turned', '`after', 'true--\"', 'curious', 'sure,', 'serpents', 'guess', 'remark,', 'getting', \"say,'\", 'death.\"\\'', 'it:', 'night?', 'respect.', '`perhaps', 'away,', 'directly,', 'fond', 'wretched', 'indeed,', 'listen,', 'other,', 'scale!', 'wriggling', 'hurry:', 'hate', 'said:', 'dark', 'mary', \"honour!'\", 'words:', 'sharks', 'dear!\"', 'diligently', 'shrieks,', 'high).', 'mouse', 'sheep-', 'particular.', 'possible', 'while,', 'desperately:', 'moon,', 'knowledge,', \"`nonsense!'\", \"coils.'\", 'come,', 'garden:', 'wrong,', \"beginning,'\", 'showing', \"this,'\", 'these', 'dodo,', 'small,', 'neither', 'happen:', 'natured,', 'same,', 'book-shelves;', 'surprise.', 'door--', 'encouraged', \"story!'\", 'blow', \"first.'\", 'other--bill!', 'ready', \"what's\", \"king,'\", 'mixed', \"to-day.'\", \"did,'\", 'already,', 'fulcrum', 'hurry', 'cost', 'jury.', 'crouched', '\"poison\"', 'about', \"right,'\", \"heads!'\", 'then?', 'white,', 'taking', 'trouble', 'myself', 'dodged', 'way.', 'beautiful', 'rat-hole:', 'creep', 'not', '`please', 'it!', \"all!'\", 'outside.', 'lap', \"crumbs.'\", 'lady', 'iii', 'you--all', 'enormous', 'round!\"\\'', '(sounds', 'sobbed', \"experiment?'\", 'series', 'sends', 'paws', 'sands', 'thought),', 'rope--will', 'passion,', 'caterpillar;', 'moment', \"bit.'\", 'sooner', 'door--i', '`read', '`stand', 'soup!', 'something;', 'yawning', 'forgotten', 'coaxing.', 'belt', 'fury,', 'placed', 'far,', 'court;', '`whoever', 'crash)--`now,', \"english,'\", 'time', 'creatures.', 'party.', 'faces,', 'quietly', 'managing', 'wood--(she', 'close,', 'tears', 'then--i', '\"such', \"suppose?'\", 'queen,', \"then.'\", 'thoughts', 'believed', 'oh,', \"book,'\", 'exclaimed', 'everything', '`--for', 'queens,', 'marked', 'kitchen', 'minutes', \"isn't,'\", 'next.', 'underneath', 'allow', 'carried', 'glass', \"lessons?'\", 'roses', 'bit', 'that!', 'perfectly', 'take', 'tone.', \"me'\", 'simple', 'broken.', 'guests,', 'choking', 'always', \"business!'\", 'angry,', 'alice;', 'answer,', 'feeble', 'lest', 'king.', \"elbow.'\", \"sing?'\", 'bread-', 'sentenced', '\"there\\'s', 'thanked', \"shouldn't\", 'downward!', 'leave', \"morning,'\", \"partners--'\", 'yards', 'swallow', 'best,', 'field', \"mad.'\", 'seem,', 'bottom', 'cause', 'possibly', \"know--'\", \"down!'\", 'himself', 'though.', \"waiting!'\", 'desperate', 'spoke.', 'signed', 'adventures--beginning', 'stick,', \"him,'\", 'themselves.\"\\'', 'around', 'say.)', 'knock,', 'crying', \"said--'\", 'upon', 'fly,', \"pardoned.'\", \"person!'\", \"wow!'\", 'hearing.', 'business', 'seaography:', 'am!', 'neighbouring', 'faster', 'stole', 'cook,', 'her,', 'fashion,', \"the--'\", \"shan't\", 'sleep,', 'ask:', 'quite', 'appearance', 'court', '`all', \"cutting,'\", 'different', 'branches,', 'forty-two.', 'bore', 'opened', \"a--i'm\", 'shut.', 'two:', 'hand', 'years,', '`who', 'together,', 'finish', 'is--\"take', 'particular', 'saw.', 'closely', 'writing-desks,', 'asked.', 'hardly', \"right!'\", 'croqueting', 'journey,', 'introduce', \"yourself.'\", \"first,'\", \"dancing.'\", 'nobody,', \"judge,'\", 'hookah', \"you!'\", 'ever', \"star-fish,'\", 'bough', 'came,', 'sir,', 'dinah,', 'door,', 'fancying', 'growl,', 'fell', 'joined):--', '`never', 'happen,', 'retire', 'tunnel', 'this),', 'banquet--]', \"here.'\", '`keep', 'rule', 'circle,', 'to,', 'exclaimed,', \"serpent?'\", 'spoon:', 'anxious.)', 'her;', 'bird', 'breath,', 'me?', 'between', 'middle.', 'begin,', 'guinea-pig,', 'consider', 'laughing:', 'happened,', \"`yes,'\", 'nurse--and', 'obliged', 'daresay', 'meekly', 'producing', 'caterpillar.', 'sobbing', 'says', '`suppose', '`pray', \"late.'\", \"remember,'\", 'ambition,', 'overhead;', 'yesterday,', 'water,', 'might,', 'nothing', \"saying.'\", 'pink', 'in', \"australia?'\", 'ever;', 'fire,', 'slowly', 'it--once', 'her:', 'paused', '\"i', '`--you', 'rest,', 'contemptuously.', 'thoroughly', 'here.', \"witness!'\", \"clever?'\", 'silent.', 'ran;', 'and', 'size?', 'loose', 'morning', 'wildly', 'not.', 'acceptance', \"croquet?'\", '\"\\'tis', '`sh!', 'walk', 'picture.)', '(as', 'vinegar', 'paris,', 'shared', 'rippling', 'smaller,', 'answer', \"wasn't\", 'fright.', 'alice,)', 'silent,', \"alive!'\", 'so', 'say.', '(he', 'shore.', 'anything,', \"where--'\", '`we', 'pleaded', '`to', \"minute!'\", '`\"miss', 'next!', 'eyes,', 'on!\"', 'kick', 'other:', \"rude.'\", 'cards,', 'work', \"`why,'\", \"`no,'\", 'roof.', \"heard!'\", \"throat!'\", 'invent', 'cart-horse,', \"indeed,'\", 'said.', 'please!', 'straight', 'expressing', \"day,'\", 'downwards,', 'flinging', 'surprise', 'considering', \"hatter's\", \"march.'\", 'much,', 'way:--', 'listened,', 'garden.', 'proved', \"breathe.'\", 'child', 'content', 'mabel', 'do:', 'tears,', \"sea.'\", \"do!'\", 'here!', 'good,', 'face--and', 'woman;', 'pope,', 'sense', 'magpie', \"and-butter--'\", 'sea,', \"certainly,'\", '`fetch', \"conqueror.'\", \"time,'\", 'velvet', 'hedgehogs,', 'die.', 'mouths.', \"last!'\", 'startled', '`unimportant,', 'practice', 'sticks', 'went', \"hatter.'\", 'serpent;', 'shriek,', 'an', 'truthful', \"behind?'\", 'folded', \"whiting!'\", \"i'll\", 'sleepy', \"question,'\", 'hot', 'eye,', 'age', \"executed.'\", 'mistake', 'broke', '`get', \"well,'\", 'dive', 'unwillingly', \"he?'\", \"lobsters!'\", 'minded', 'vanished', '\"what', 'uglify', 'shifting', \"now?'\", 'angrily,', 'english);', \"wine,'\", 'despair', 'hundred', \"speak?'\", 'is--oh', 'know,', '`exactly', \"better';\", 'execution.', 'usual.', '`hold', 'perhaps', 'master', 'explanation;', 'sharply,', '\"william', 'back.', 'experiment', 'prize', \"simpleton.'\", 'bit.', \"`where's\", 'thinking', 'opening', 'things!', 'rapped', 'angrily.', 'jelly-fish', 'silent', \"croquet.'\", 'parchment', 'twelve,', 'brown', 'three', 'hearts,', 'fancy', \"be,'\", 'straightened', 'you,', 'relieved', 'had,', 'clapping', 'lark,', 'remarks,', \"`i'll\", 'dainties', 'able!', 'editions', 'nothing.', 'wearily.', 'undo', \"carrier,'\", 'shoes', 'pour', 'crowded', 'wish', 'ordered.', 'shower', 'sit', 'poor', 'down--here,', 'fond--of--of', 'mournful', '`yes,', 'child;', 'grunted,', 'edwin', \"do.'\", 'throwing', 'unusually', 'attends', 'become', 'pale,', 'drawling--the', 'brass', 'rustled', 'cattle', 'morcar,', 'gloves:', 'dears?', 'dismay,', 'lonely', 'ear,', 'best', 'doors', 'knot,', 'heap', \"verses.'\", '\"he\\'s', 'butter', 'askance--', \"man,'\", 'tea;', 'thing,', 'direction,', 'doubtful', \"alice's,\", 'i?', 'low-spirited.', 'ventured', \"ma!'\", \"growling,'\", 'goldfish', '`your', 'm,', 'fifteen', 'fit--\"', 'cats:', 'shilling', \"can--'\", 'shrill,', 'plates,', 'sister', 'trot', 'end,', 'again.)', 'nothing;', 'grew', 'eggs,', \"hat,'\", 'impossible.', 'contemptuous', 'twelve', 'then--always', 'conger-eel,', 'ointment--one', \"dormouse,'\", 'today.', 'dormouse.', 'denied', \"once.'\", 'playing', 'shaking', 'soo--oop!', 'met', \"in.'\", 'tumbling', 'shutting', '`how', 'concert', \"say.'\", \"things!'\", '`then', 'hedgehogs', 'flappers,', \"doing!'\", 'entirely', '`ou', 'timidly;', 'neat', 'condemn', 'venture', 'escape', 'him:', 'bank,', 'bone', 'bats,', \"business,'\", 'rude,', 'hearing', 'jumped;', 'see,', 'nonsense.', 'shall', 'pass', 'escape;', 'sudden', \"child!'\", 'like', 'failure.', '`a', \"extras?'\", 'whiting.', 'grant', 'never', 'dormouse', \"me?'\", 'seen', 'felt', \"fashion.'\", 'fat;', '`soles', 'mouse--of', 'honour:', 'shillings', 'larger', \"words.'\", 'court.', 'treacle-well--eh,', 'by', 'disappeared.', 'below,', 'hair.\"', 'dream:--', 'carry', 'persisted', 'voice;', 'toys', 'mad,', 'pocket)', 'treacle', 'thin--and', \"sing,'\", 'rate,', 'ask.', 'this:', 'breathe\"!\\'', 'blows', 'violence', 'shoulder,', 'happened.)', 'soft', \"important,'\", 'sluggard,\"\\'', 'song', 'raising', 'fall,', 'thought,', 'blacking,', 'sleep', 'turns,', 'earth', \"won't'\", 'scream,', \"is!'\", 'girls', 'prosecute', 'difficult', 'buttered', \"trial's\", 'severely.', 'lazy', 'punching', 'sense,', 'dishes', 'wandering', 'so.', 'again--\"before', 'hair!', 'fact', 'right;', 'painting', 'with;', 'sour--and', 'sorrow,', \"off--'\", 'round.', 'smoke', \"never!'\", 'advantage', 'reason,', 'encourage', 'change,', 'scaly', 'exact', 'song,', 'slates', \"bill's\", \"dog's\", 'received', 'read', 'fly;', 'weak', 'grunted', 'beheading', 'cat:', 'mushroom,', 'civil', 'whether', 'stirring', 'myself,', 'loud.', \"witness,'\", 'mine', \"were',\", 'late', 'pool', 'subject!', 'fits,', \"away,'\", 'languid,', \"we're\", 'bother', 'fit)', 'minutes,', 'room!', 'use,', 'above', 'queen.', 'along--`catch', 'jury,\"', 'loud,', 'pray', \"housemaid,'\", 'lessons:', 'twice', 'panting,', 'only', 'delight,', \"begun.'\", \"to.'\", 'choice,', \"they're\", 'it.)', 'nibbled', 'frog-footman', 'xi', 'owl,', 'meal,', 'offended,', 'growled', \"else's\", 'caterpillar,', \"let's\", 'passed', 'managed?', 'somebody,', 'several', 'footsteps,', 'pressed', 'friend.', 'draw', \"`she's\", \"one,'\", 'tricks', '\"there', \"head's\", 'trying,', 'out-of-the-way', 'minute', '`living', \"think--'\", 'courage', 'english,', 'once:', 'dripping', 'unfortunate', 'coming', 'died', 'jurymen.', 'denial;', \"don't!'\", 'fury:', 'uncomfortable.', 'baby', 'continued', 'half-past', \"fourth.'\", \"to-day?'\", 'feet', 'which),', 'on,', 'pinch', 'readily:', 'quicker.', \"procession,'\", 'quiet', 'writing', 'charges', 'alas!', 'stupidest', \"whiting?'\", 'wind,', 'powdered', 'northumbria--\"\\'', 'unpleasant', \"of?'\", 'asleep.', 'shake', 'find', 'doubling', 'undertone', 'trims', 'gravely,', 'station.)', 'humble', 'leaves:', 'meaning.', 'dears', '(look', 'zealand', 'thick', 'turn-up', 'exclaimed.', 'lewis', \"derision.'\", 'comfits,', \"warning,'\", 'tarts?', 'sun.', '`an', '(the', 'wet', 'off.', 'wondering', 'drop', 'things--i', 'silence,', \"rabbit's--`pat!\", \"there's\", 'ringlets,', \"yourself!'\", 'buttons,', 'smile.', 'minute,', 'friends', 'dish?', 'pretexts', \"time.'\", 'various', '(which', \"part.'\", 'size,', 'gardeners', 'thunder,', 'done,', 'woman--', '\"how', \"moment's\", 'learn', \"that,'\", 'protection.', \"with?'\", \"soup!'\", 'why', 'repeated,', 'along', 'escape,', 'brave', 'this,', '`nothing', 'saw', 'pairs', 'upset', 'fanned', 'eagerly', 'passed;', \"he'll\", 'crown.', 'was,', 'uncivil.', \"like,'\", 'short', \"no!'\", \"know?'\", 'hate--c', 'alone', '`on', 'garden,', 'well.', 'appeared;', 'rises', \"all?'\", 'chuckled.', 'offer', '`--mystery,', \"from,'\", 'brush,', 'gloves,', 'flamingo:', \"would,'\", 'sighed', \"these?'\", 'ran,', 'childhood:', 'melancholy', 'humbly;', 'ground,', \"english!'\", 'crashed', 'soup,', \"`once,'\", 'finish,', 'washing--extra.\"\\'', 'bear:', 'last,', 'asked', 'offended.', 'altogether;', 'rush', 'chanced', 'saucepans,', 'tut,', 'feet,', 'or', 'fish', '3.0', \"porpoise.'\", 'rabbit;', 'show', 'hall,', 'drew', 'young', 'elegant', 'sort', 'yer', '`anything', 'arch', '`some', 'manner,', \"court!'\", 'being', 'tone;', 'answered', \"mostly,'\", 'new', 'forgot', \"about,'\", 'constant', 'itself.', 'archbishop', '`beautiful', 'ink,', 'flavour', \"you're\", 'law,', 'finished.', '`besides,', \"was.'\", 'occasional', 'tell', 'processions;', \"giddy.'\", 'labelled', 'voice,', '`\"we', 'asleep,', 'thoughtfully', 'question;', 'hall.', \"sh!'\", \"coming!'\", \"before.'\", 'aloud.', '`take', 'toast,)', 'pennyworth', 'worry', 'month,', 'happens', 'conversation', 'done.', 'thistle,', 'anxiously', 'hedge.', 'tree.', 'eyes', 'thistle', '`but,', 'smiled', 'nicely', 'fast', 'it,', \"puppy's\", 'bad', 'old', 'resting', 'eat', '`he', 'kitchen,', 'mentioned', \"chose,'\", 'dropped,', 'send', 'you.', '`oh,', 'replied', \"won't!'\", \"tea,'\", 'tongue,', \"speaker,'\", 'panted', '`boots', 'candle.', \"`you've\", 'fish)--and', 'deeply,', 'but', 'and,', '`--so', 'after', 'wood,', 'itself,', 'happened.', 'affectionately', \"not?'\", 'beauti--ful', 'swim--\"', 'looked', '`without', 'you:', 'yet--and', \"well--'\", 'story', 'squeaking', 'first--they', 'worm.', 'flame', 'sadly:--', 'alice', 'eaglet.', 'ravens', 'secret,', \"curious!'\", 'baked', 'stand', 'rate!', \"butter,'\", 'hall:', 'air', 'red-hot', 'near', 'rushed', 'wait,', 'you!', \"words,'\", 'let', 'form', \"dear?'\", 'cat.', 'even', 'door:', 'voice:', '`oh', 'subject', 'grinned;', 'secondly,', \"stop.'\", 'corner,', 'daisy-chain', 'vii', 'round,', 'flurry', 'curious,', 'reason', 'rise', \"never')\", 'her', 'all.', 'beating.', 'cheerfully', \"animal's\", '`have', 'good-', \"dinah!'\", \"yet--it's\", 'kind', 'end:', 'dogs', 'bringing', 'questions.--how', '`mine', '`reeling', 'mouths;', 'boy--and', 'beau--ootiful', 'less', 'soothing', \"grin,'\", 'camomile', 'that.', 'signify:', 'cook.', 'am', 'execution--once', 'temper', 'suit', 'arm-in-arm', \"you've\", 'cleared', 'bank--the', 'laugh;', \"doesn't\", 'was', 'hearth', \"curious.'\", 'twenty', 'ear', 'evening,', 'home', 'world', 'sneeze,', 'paper', 'down', 'throne', 'leaving', 'box--', 'impatiently,', 'arrived,', \"execution.'\", '\"turtle', \"`we're\", 'easily', 'hearts', 'queer', 'fright', 'if', 'addressing', 'dressed,', 'good', 'surprise,', 'tail.', 'cautiously:', 'great', 'kick,', 'shedding', 'edition', 'whiskers!', '`orange', 'quarrelled', 'hearthrug,', 'hope', 'angrily:', 'mean', 'person', 'stay', 'beasts', 'lay', 'v', 'screaming', 'sort.', 'flown', \"(`that's\", \"song?'\", 'juror', 'then--she', 'trusts', 'hint', '`wow!', 'pie', 'spectacles,', 'tide', 'shoulders', \"getting!'\", \"everything's\", 'consented', \"nonsense.'\", 'crash,', 'splashing', \"lobster--'\", 'memorandum', 'follow,', 'mustard-mine', 'nervous', 'high:', 'manners', \"perhaps?'\", 'cry', 'reasons.', 'crossed', '`really,', 'usual', 'procession', 'any.', 'with.', 'houses,', 'dunce?', 'own.', \"can,'\", 'attempted', 'key', 'lory', \"much,'\", 'grief,', \"growing.'\", 'expected:', '(`the', '`can', 'muttered', '`only', 'wore', 'invitation', 'mercia', 'jury-box', 'grow', 'exactly', 'murdering', 'his', 'said,)', 'besides', 'sneezed', 'turtle;', 'folded,', 'candle', \"cakes,'\", 'year', 'graceful', '(`i', \"little!'\", 'dear:', 'purple.', 'spite', 'swallowing', 'five.', 'folding', \"trying--'\", \"there,'\", 'delighted', '`so', 'toffee,', 'lying', 'suddenly,', \"outside,'\", 'fainting', 'someone', 'clock.', 'tea--not', 'bitter--and--and', \"order,'\", \"here?'\", 'sat', 'drunk', 'violently', 'speaking,', 'hungry', 'sent', \"enough,'\", '`digging', 'stretching', 'solemn', \"enough.'\", \"it.'\", 'stalk', \"sobbing,'\", 'worse.', 'left', 'politely', 'trees', 'were', \"pig!'\", 'interesting,', 'annoy,', 'owl', \"old,'\", \"jury--'\", 'pine-apple,', 'doubtfully:', \"throat,'\", '\"they', \"something!'\", 'cherry-tart,', 'dishes.', 'animals', \"prizes!'\", 'common', '`was,', 'bread-and-butter,', 'disgust,', 'porpoise,', '`--as', 'stoop?', 'ago', 'little,', \"somewhere,'\", 'puzzling', 'knew)', 'to?', 'call', 'close', 'bark', 'more:', 'clubs;', 'slate.', 'eyes.--`tell', 'furious', 'viii', 'asking,', 'among', 'pepper', 'shade:', \"sell,'\", '`mouse', 'slippery;', 'again!', 'learning', 'knows', 'hurry.', 'been', 'settling', 'dream.', 'eats', 'dreamed', 'gone', 'lizard,', 'loudly', 'he', 'him,', 'queen', \"home?'\", 'livery:', 'hatters', \"really?'\", \"majesty,'\", 'smoking', 'will', 'heads.', \"well?'\", 'head--brandy', 'white;', 'fan!', \"better.'\", 'began:', 'drive', 'fidgeted.', 'day,', \"in?'\", 'corner', 'blew', '`is', \"ill.'\", 'one', 'mouth', '`come', 'knew', 'putting', 'learned', '`sentence', 'encouraging', 'alice:', 'adding,', \"they'll\", 'patiently', 'name', 'questions,', 'courtiers;', 'denying', '`there', 'happen', \"alice!'\", 'precious', 'faces', 'sink', 'immediate', \"course?'\", 'come', 'hopeful', 'love).', 'can', '\"much', 'singers', \"mouse!'\", 'roses.', 'enough--i', 'presents', '`sure,', \"to,'\", 'sobs,', 'are', 'footsteps', 'height', \"offended!'\", 'beginning', 'turtle', 'faster,', 'shelves', 'attempts', 'beating', 'procession,', \"can't\", 'wonderland,', 'helped', 'can;', 'puffed', 'living', \"first!'\", 'dish', 'into', 'sounded', 'and--oh', 'doubled-up', 'trickling', 'join', 'attending', 'fix', 'rest', 'sight:', 'cupboards', '(it', 'nodded.', 'little!', 'taller', 'aloud,', \"figure!'\", 'look!', 'anger,', 'live', 'beautiful,', 'crossly:', 'delightful', 'after-time,', 'to', 'enough;', 'custard,', 'week', 'conversation.', 'killing', 'side.', \"waist,'\", 'frying-pan', \"more!'\", '`hush!', \"whiles.'\", 'changes', 'hastily;', 'trembled', 'settled', 'plenty', 'others', 'sobs', 'dream,', 'little', 'unable', 'hatter:', 'voices', 'couples:', \"ground.'\", 'latin', 'anxiously.', '`this', 'like\"!\\'', 'sky.', \"`silence!'\", 'stop', 'balls', 'last', 'high,', \"knocking,'\", 'puzzled', 'bright-eyed', \"be?'\", 'was)', 'brushing', 'toes', 'deep,', 'stretched', 'feelings', 'now!', 'live.', \"`'tis\", 'invited', 'stays', 'master,', 'lowing', 'leaves,', 'jumping', 'on', '`any', 'now--but', 'middle', 'peeping', 'slates,', 'case', 'feared', \"again?'\", '\"purpose\"?\\'', '`chop', 'crumbs', 'declare,', \"rate,'\", 'paws.', 'much', 'change:', 'rudeness', \"done,'\", \"`dinah's\", \"her,'\", 'flamingo.', \"this?'\", \"you'd\", 'shrimp', 'talk.', 'sorry', 'tied', 'goose,', 'garden', \"jaws!'\", \"head!'\", 'respectful', \"child?'\", 'promise.', 'reality--the', '`--it', '`drink', 'had', 'cheshire', 'squeaked.', \"had!'\", 'certainly', 'meet', 'currants.', 'hedgehog,', 'collected', '`explanations', \"business?'\", 'curled', \"sir--'\", 'laughing', 'spoke;', 'swallowed', 'fan,', 'gloves.', 'free', 'here?', 'hand.', 'tremulous', 'bristling', \"somewhere.'\", 'uneasily,', \"explained,'\", 'him', \"us,'\", \"roses?'\", \"game.'\", 'passage', \"moment!'\", 'timidly,', 'settle', '`somebody', 'executioner,', 'suppressed', '`his', \"dull!'\", 'dead', 'irritated', 'manage', 'standing', \"creatures,'\", 'either,', 'cardboard.)', 'dull', 'dormouse;', 'arm,', 'us!\"\\'', 'somersault', 'end', 'frighten', 'sang', 'instantly', 'king,', 'hiss', 'finished,', '`begin', 'cool', 'until', \"cat,'\", 'none', 'est', 'heard', 'foot', 'unhappy', '`--i', 'time.)', 'honest', 'child-life,', '`what!', \"nothing.'\", 'swim,', 'nice', 'baby:', '(she', 'witness', 'bats?', 'reading,', 'else.', 'ago:', 'atom', 'went.', 'replied,', 'duck', \"hedges,'\", 'ashamed', 'am,', 'them:', 'slightest', 'she', 'cakes,', 'leaders,', \"know,'\", 'elbows', 'anywhere', '`however,', 'gryphon;', 'does,', 'atheling', \"`there's\", 'cur,', 'turtles', \"rabbit's\", 'hurrying', 'jury-box,', 'dipped', \"see,'\", 'driest', 'too', 'heart', \"`treacle,'\", \"queen's\", 'wags', 'within', \"myself.'\", 'it;', 'led', \"time!'\", 'fighting', \"learn?'\", 'buttercup', \"telescope.'\", 'country', '`they', 'eagerly.', 'feebly', 'recovered', 'reply', 'know--and', '(luckily', 'hearts.', 'right', 'delight', 'family', 'in:', 'how', 'breeze', 'line', 'extremely', 'jar', \"places!'\", 'there.', 'vulgar', 'dare', 'spell', 'except', 'did', 'about;', '`ah!', 'till', 'do.\"', 'tea-party', \"watch,'\", 'stamping', '\"who', 'shorter,', 'by--the', \"think.'\", 'out.\"', 'woke', 'bottle.', '`no', 'appeared,', 'ah,', 'sea', 'dig', \"all.'\", 'caused', \"means--to--make--anything--prettier.'\", \"up!'\", 'nibbling', 'twinkle--\"\\'', 'going,', 'reduced', 'whispered,', 'turtle--we', 'centre', \"before,'\", \"over!'\", 'grumbled:', 'pigeon', 'tarts', 'pretty', '`three', 'nursing', 'game,', '`chorus', 'best.', 'strings:', 'conqueror,', \"bit,'\", 'ordered', 'follow', '`--and', \"said,'\", 'affair,', 'permitted', 'directions', \"`jury-men'\", '`whenever', '`--that', \"coward!'\", \"to?'\", \"grunt,'\", 'pigeon;', \"concert!'\", 'spectacles', 'butterfly,', \"then!'\", 'english.', 'stigand,', 'thought.', 'courage.', 'turtles,', '`only,', 'set', 'dozing', 'comes', '`--but', 'chin:', 'floor,', 'therefore', 'awfully', 'ones', 'gently', 'appearing', 'muchness--', 'tale,', 'back', 'dormouse,', \"'tis\", 'teacups', 'lullaby', 'work,', 'bad,', \"not!'\", 'chains,', \"little,'\", 'murder', 'asked,', 'sulky', 'cross,', 'replied;', \"escape!'\", \"for?'\", 'crab,', 'accidentally', \"now,'\", 'life;', 'offended', 'verse', 'letters.', 'it),', 'burn', '`--change', 'executioner', \"through,'\", 'dear,', \"thing,'\", 'rate:', 'difficulties,', 'bawled', \"sea--'\", \"i,'\", 'see', 'pool--she', 'shut', 'fountains,', \"trial.'\", 'things--everything', 'means', 'animal', 'words', 'believe', \"i--'\", 'marked,', 'done', 'guinea-pigs', '`serpent,', 'timidly', 'lobster;', \"yourself,'\", 'somehow', 'know.', 'impatient', 'got', 'life.', 'frog', 'rising', 'others.', 'ear.', 'pause:', '`unless', 'knave', \"things--'\", 'elbow', 'hung', 'rats', 'nonsense', 'remember', 'me!', 'water', 'proposal.', 'too,', 'scrambling', 'minute.', 'suppose,', 'grins', 'tougher', \"he's\", 'days', '`tell', 'knife', 'anything.', 'faces.', 'state', 'pleasanter', 'soon', 'shrink', 'sadly.', \"verse,'\", 'barley-sugar', \"`stupid,'\", 'names', 'giving', 'pool,', 'dance?', \"day.'\", 'look-out', 'followed', \"size,'\", 'angry', 'pack,', 'then;', 'wet,', 'bring', \"muchness?'\", 'began,', \"`creatures,'\", 'whose', 'talking:', \"sisters,'\", 'well,', 'quiver', 'sea!\"', 'stuff?', 'without', 'e--e--evening,', 'feet!', 'bowing', 'ridiculous', 'morning,', \"pig,'\", 'occasionally;', 'pronounced', \"`alice!'\", 'eagerly:', 'introduced', \"twelfth?'\", 'stockings', 'appeared.', 'imagine', 'him),', 'disappointment', 'canvas', 'suddenly:', \"marmalade',\", 'iv', 'hands;', \"so.'\", 'given', 'going', 'sternly.', \"jury-box,'\", 'off).', '\"let', 'song.', 'alone.', 'beautifully', 'dried', 'elsie,', 'us.', 'curtain', 'taller,', \"not.'\", 'commotion', 'go?\"', 'fender,', 'gazing', 'impossible', 'sentence', 'safe', 'draggled', 'put', 'for,', \"plan.'\", 'twist', 'further:', 'cries', '`swim', \"verse.'\", 'insult', 'returning,', 'ten', 'all', \"day!'\", '`with', 'ought!', 'reply,', 'scolded', 'comfortably', \"prisoner's\", 'whisper.)', 'backs', 'leaning', 'meanwhile', 'whistling.', 'advisable--\"\\'', 'tea-time.', 'remarked;', '`pepper,', \"wig.'\", \"that!'\", '`--likely', 'messages', '`please,', \"`important,'\", 'because', 'any', 'indignant', 'tried.', 'jurors', 'of', 'only,', 'arguments', 'bleeds;', 'lory.', 'improve', 'tones', 'pigeon,', 'size', 'nest.', 'otherwise', 'upright', 'pleasant', 'executed,', '(alice', 'speaking', '`ah,', 'ridge', \"high,'\", 'white', 'mean,', 'longitude', \"yet?'\", 'duchess:', '`now,', 'could', 'lasted.)', 'sob,', 'cause,', 'advisable', 'like:', 'offend', 'feelings.', 'positively', 'vanishing', 'wandering,', \"writing-desk?'\", 'deny', \"dreadful,'\", 'get\"', \"'em\", 'did.', 'last:', 'them--`i', 'before', 'counting', 'queer-', \"figure,'\", 'twinkling!', 'fills', 'adventures', '`tut,', 'executions', 'people.', \"think!'\", 'as,', 'name,', 'punished', 'chin', 'moment,', \"him.'\", 'shepherd', 'beast,', 'chapter', 'once;', 'loudly.', 'thought', \"case,'\", 'uglification,', 'rabbit-hole', 'pardon,', 'table:', 'true.)', 'few', 'cautiously', 'hunting', \"are!'\", \"partner!'\", 'eaglet,', 'twentieth', 'twice,', 'two', 'bill,', 'body', 'wow!', 'natural', 'time.', 'grass', 'listening:', 'gardeners,', 'history.', 'fluttered', \"didn't\", 'dormouse:', 'off,', 'why.', 'indeed:', \"dear,'\", 'full', 'serpents!', 'walk!\"', 'kettle', 'narrow', 'caught', \"stupid?'\", 'bowed', 'sounds', 'tumbled', 'plainly', 'you', 'fine', 'see\"!\\'', 'pictured', 'hot,', '`where', \"down,'\", 'lazily', 'thatched', 'closer', 'neighbour', \"end.'\", 'paws!', '(or', 'began:--', 'away:', 'was:', 'riddle', 'ceiling,', 'assembled', \"i've\", \"wouldn't\", 'immediately', \"it's\", 'happened', 'linked', 'stopping', 'accident', \"axis--'\", '`not', 'dream', \"shoes.'\", 'fire-irons', 'pigs', \"say?'\", 'held', 'fish-footman', 'entangled', 'nurse!', 'size:', \"nonsense!'\", 'legs', 'alice!', 'sometimes', 'bells,', 'swimming', 'justice', '`nobody', 'becoming.', \"on?'\", 'sighing', 'unlocking', '`by-the-bye,', 'scroll,', 'follows:--', \"talking!'\", 'saves', 'high.', 'question', 'sneezing.', \"away!'\", 'changed,', 'sad', '(with', 'hold', 'eyes;', \"afterwards.'\", 'chimney,', 'darkness', 'far', \"yet,'\", 'morsel', '`each', 'eye;', 'screamed', 'glass;', 'places--', 'cat.)', 'knowledge.', \"mad?'\", 'thank', 'singers.', 'tops', '`do', 'sky!', 'accounts', \"clearly,'\", 'worse', 'mouth,', 'blasts', 'told', 'enough,', 'calmly,', 'tail;', 'interesting.', 'lives', 'soup.', 'became', 'singing', \"majesty!'\", 'holding,', 'grin,', 'bend,', 'shriek', 'shore,', 'lamps', 'that,', \"attending!'\", 'one,', 'wash', 'trouble,', \"altered.'\", 'brown,', 'apples,', 'sneezing', \"treacle-well.'\", 'digging', 'rabbit,', 'tea-time,', 'whole', 'passionate', \"sea-shore--'\", 'picked', 'otherwise,', 'changed', 'roared', 'fixed', 'father', 'needs', 'him--how', 'goes', 'been.', 'this:--', '`turn', \"mind!'\", \"`dinah'll\", 'swim', 'away', 'girl', 'ourselves,', 'heads', 'glass.)', \"`nothing,'\", 'whistle', '(pointing', 'red', 'missed', 'bread-and-butter.', 'air,', 'joined', \"meant,'\", 'politely,', \"instead!'\", \"cats!'\", 'better', \"`stolen!'\", 'particular--', \"either!'\", \"bill!'\", 'teeth,', '`one', 'it?)', '\"come', 'hall;', 'wink', 'contradicted', 'turning', \"tale!'\", 'footman', 'william', 'face', \"`serpent!'\", '`once', 'carrying', 'twinkling', \"thimble,'\", '`may', '`back', 'nose;', 'strength,', 'day', 'players,', 'william,\"\\'', \"`what's\", 'planning', 'day;', 'himself:', '`let', 'lost:', 'used', 'clinging', 'their', 'guess,', \"alice's\", 'sugar', 'on:', 'morals', 'shouted', 'free,', 'almost', 'stupid', '`found', 'finger,', 'generally,', 'burning', 'pleasing', 'hedgehog.', 'matter', 'saying', 'dreamy', 'sulky,', 'waistcoat-pocket,', 'eaglet', \"is,'\", \"other.'\", 'sharing', 'dear', 'imitated', 'ignorant', 'mind,', 'small.', 'where', \"on!'\", 'sell', 'repeated', 'mouse:', 'decided', 'breath.\"', 'frightened', '`everybody', 'hedgehog', 'doubt,', 'english', 'doze;', 'them.', 'cake,', 'earnestly,', 'him--it', 'bit,', 'late,', 'finger;', 'sight,', 'luckily', 'row', 'people', 'rate', \"one.'\", 'clear', 'london', 'fortunately', '[later', 'hare:', \"were,'\", 'times', 'fair', \"then!--bill's\", 'grammar,', 'comfits:', 'fact.', 'angrily', 'unjust', \"feeling!'\", 'distance.', \"know.'\", 'aloud;', 'hint;', 'paw,', 'coming.', 'calling', \"`everything's\", 'memory,', 'pause.', 'mock', \"`sixteenth,'\", 'bag,', 'hid', 'fancy,', \"annoyed,'\", 'furiously,', 'replied:', 'respectable', 'thoughtfully.', \"bats?'\", 'anything;', 'distance,', 'particular;', 'beasts,', 'alternately', 'passion.', 'tossing', 'length', 'beheaded,', 'prove', 'sure!', 'five!', 'burst', 'remarked:', '`really', \"`it's--it's\", 'porpoise?\"\\'', 'race-course,', 'cucumber-frame,', 'within--a', 'moral', 'muttering', 'throw', 'across', \"together.'\", 'piece', 'nurse', \"fun!'\", 'lizard', 'miserable', 'nor', 'recognised', 'also,', 'tone', 'tail,', '`if', 'most', 'terror.', \"bat?'\", 'wide', 'large,', 'canary', \"know!'\", 'look', 'splash!', 'tastes!', 'nobody', 'adjourn,', 'confusion', 'old,', 'cauldron', 'rumbling', 'sizes', 'surprised,', 'figure', '`in', 'produced', 'two.', 'squeeze', \"chatte?'\", 'eye', 'talk:', 'no,', 'fireplace', 'magic', 'day:', \"bread-knife.'\", 'concluded', \"toes.'\", \"too,'\", 'curiosity,', \"it,'\", \"it'll\", 'slipped', \"impertinent,'\", 'struck', 'claws', 'seldom', 'glass,', 'running', \"talk!'\", 'the', 'taken', 'noticing', \"about!'\", 'cards:', 'fun', 'nile', '_i_', 'bright', 'grazed', \"where.'\", \"again,'\", 'wife;', 'duchess.', 'moment:', 'is--\"be', 'lives.', \"slates'll\", 'kept', 'growls', 'dropping', \"does.'\", \"ma'am,\", 'herself', 'heels', 'rabbit:', \"chimney!'\", 'label,', 'least--at', 'relief.', \"temper,'\", 'dinah:', 'dreaming', 'called', 'shrinking', 'inkstand', 'waiting', 'think!', 'resource,', 'birds', \"for.'\", 'watch', 'breathe', 'patriotic', 'oldest', 'dinn', 'later.', '`my', '`that', 'inquisitively,', 'man', 'world!', \"oyster!'\", \"t!'\", 'poker', 'milk', \"remedies--'\", 'timidly:', 'ready?', 'tone:', 'pie-crust,', 'mouth;', 'proper', 'has', 'sneezing,', '`hm!', 'next', 'bend', 'managed', 'timid', '`as', 'never!', 'picking', 'remarked.', \"three.'\", 'hide', \"bit!'\", \"quadrille?'\", 'much.', 'tried', 'sure;', 'players', 'hare,)', 'overcome', 'lie', 'table.', '`look', 'timidly.', \"was!'\", 'walking', 'faint', 'near.', 'stoop', 'hours', 'promised', 'drowned', 'head!', 'lifted', \"`unimportant.'\", \"youth,'\", 'sometimes,', 'said,', 'righthand', \"mine.'\", 'words,', \"`can't\", 'course;', 'came', \"them.'\", 'touch', 'animals,', \"fairly,'\", 'saucer', 'consultation', 'word)', 'mouse--to', 'known', 'age,', 'ever:', 'voice.', 'sight.', 'started', 'remarks', 'writhing,', 'pictures', 'however,', 'once,', \"king's\", '`now', 'stairs.', 'those', 'plate.', 'there,', 'further.', 'beat', 'ran', 'pinched', 'does.', 'change', 'effect:', 'knowledge', 'yourself,', 'than', 'herself.', 'did,', 'judging', 'eleventh', 'shyly,', 'voice--the', 'knife,', \"feet!'\", 'wings.', 'king', \"game's\", 'splendidly', 'rattle', 'night', 'middle,', 'gave', 'father,', 'sky', 'all;', 'frowning,', 'flamingo,', 'boon,', '`leave'}\n",
      "Average sentence length: 7.4\n",
      "Vocabulary diversity: 0.1870\n"
     ]
    }
   ],
   "source": [
    "def assess_data_quality(texts):\n",
    "    \"\"\"Analyze text data quality for Word2Vec training\"\"\"\n",
    "\n",
    "    stats = {\n",
    "        'total_documents': len(texts),\n",
    "        'total_words': 0,\n",
    "        'unique_words': set(),\n",
    "        'sentence_lengths': [],\n",
    "        'word_frequencies': {}\n",
    "    }\n",
    "\n",
    "    for text in texts:\n",
    "        words = text.lower().split()\n",
    "        stats['total_words'] += len(words)\n",
    "        stats['sentence_lengths'].append(len(words))\n",
    "        stats['unique_words'].update(words)\n",
    "\n",
    "        for word in words:\n",
    "            stats['word_frequencies'][word] = stats['word_frequencies'].get(word, 0) + 1\n",
    "\n",
    "    stats['vocabulary_size'] = len(stats['unique_words'])\n",
    "    stats['avg_sentence_length'] = sum(stats['sentence_lengths']) / len(stats['sentence_lengths'])\n",
    "\n",
    "    # Find most common words\n",
    "    sorted_words = sorted(stats['word_frequencies'].items(), key=lambda x: x[1], reverse=True)\n",
    "    stats['top_words'] = sorted_words[:20]\n",
    "\n",
    "    # Quality indicators\n",
    "    stats['quality_score'] = {\n",
    "        'vocabulary_diversity': stats['vocabulary_size'] / stats['total_words'],\n",
    "        'avg_word_frequency': stats['total_words'] / stats['vocabulary_size'],\n",
    "        'rare_words_ratio': sum(1 for count in stats['word_frequencies'].values() if count == 1) / stats['vocabulary_size']\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Example usage\n",
    "quality_report = assess_data_quality(texts)\n",
    "print(f\"Total documents: {quality_report['total_documents']:,}\")\n",
    "print(f\"Vocabulary size: {quality_report['vocabulary_size']:,}\")\n",
    "print(f\"Unique Words: {quality_report['unique_words']}\")\n",
    "print(f\"Average sentence length: {quality_report['avg_sentence_length']:.1f}\")\n",
    "print(f\"Vocabulary diversity: {quality_report['quality_score']['vocabulary_diversity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6b041-933b-4a18-9474-382c97c9a3cc",
   "metadata": {},
   "source": [
    "This code **analyzes the text dataset and gives a detailed quality report.**\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "- Counts total documents, words, and unique vocabulary\n",
    "\n",
    "- Calculates average sentence length and word frequencies\n",
    "\n",
    "- Finds the 20 most common words\n",
    "\n",
    "- Measures vocabulary diversity (how varied the words are)\n",
    "\n",
    "- Identifies rare words that appear only once\n",
    "\n",
    "- Generates quality scores to assess if the dataset is good for Word2Vec training\n",
    "\n",
    "**Result:** We get statistics about Alice in Wonderland text - like how many unique words it has, average sentence length, and whether the vocabulary is rich enough for effective Word2Vec training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013945f-14a4-419b-adf1-0f548bd78ce1",
   "metadata": {},
   "source": [
    "### **3.3 Text Preprocessing Pipeline**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50b0a263-eb7e-41b9-9b4b-4a72fb475afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./lib/python3.9/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in ./lib/python3.9/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./lib/python3.9/site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in ./lib/python3.9/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "\n",
    "#Import Packages\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66ea207d-a0ef-40c9-b13e-d3c72f69cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/macbookairm4chip/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0be9b684-7a34-47b7-8698-e593cc61fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedTextPreprocessor:\n",
    "    \"\"\"Comprehensive text preprocessing for Word2Vec training\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 lowercase=True,\n",
    "                 remove_punctuation=True,\n",
    "                 remove_numbers=False,\n",
    "                 remove_stopwords=False,\n",
    "                 min_word_length=2,\n",
    "                 max_word_length=50,\n",
    "                 lemmatize=False,\n",
    "                 remove_urls=True,\n",
    "                 remove_emails=True,\n",
    "                 keep_sentences=True):\n",
    "\n",
    "        self.lowercase = lowercase\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.remove_numbers = remove_numbers\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.min_word_length = min_word_length\n",
    "        self.max_word_length = max_word_length\n",
    "        self.lemmatize = lemmatize\n",
    "        self.remove_urls = remove_urls\n",
    "        self.remove_emails = remove_emails\n",
    "        self.keep_sentences = keep_sentences\n",
    "\n",
    "        if remove_stopwords:\n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        if lemmatize:\n",
    "            self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean individual text string\"\"\"\n",
    "\n",
    "        # Remove URLs\n",
    "        if self.remove_urls:\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "        # Remove email addresses\n",
    "        if self.remove_emails:\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "        #Combined\n",
    "         #(r'https?://\\S+|www\\.\\S+|<.*?>|\\S+@\\S+\\.\\S+|@\\w+|#\\w+|[^A-Za-z0-9\\s])\n",
    "\n",
    "        return text\n",
    "\n",
    "    def tokenize_text(self, text):\n",
    "        \"\"\"Tokenize text into sentences or words\"\"\"\n",
    "\n",
    "        if self.keep_sentences:\n",
    "            # Tokenize into sentences first\n",
    "            sentences = sent_tokenize(text)\n",
    "            processed_sentences = []\n",
    "\n",
    "            for sentence in sentences:\n",
    "                words = self.process_sentence(sentence)\n",
    "                if len(words) >= 3:  # Keep sentences with at least 3 words\n",
    "                    processed_sentences.append(words)\n",
    "\n",
    "            return processed_sentences\n",
    "        else:\n",
    "            # Return single list of words\n",
    "            return self.process_sentence(text)\n",
    "\n",
    "    def process_sentence(self, sentence):\n",
    "        \"\"\"Process individual sentence\"\"\"\n",
    "\n",
    "        # Lowercase\n",
    "        if self.lowercase:\n",
    "            sentence = sentence.lower()\n",
    "\n",
    "        # Tokenize into words\n",
    "        words = word_tokenize(sentence)\n",
    "\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "\n",
    "            # Remove punctuation\n",
    "            if self.remove_punctuation:\n",
    "                word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            # Skip if empty after punctuation removal\n",
    "            if not word:\n",
    "                continue\n",
    "\n",
    "            # Remove numbers\n",
    "            if self.remove_numbers and word.isdigit():\n",
    "                continue\n",
    "\n",
    "            # Check word length\n",
    "            if len(word) < self.min_word_length or len(word) > self.max_word_length:\n",
    "                continue\n",
    "\n",
    "            # Remove stopwords\n",
    "            if self.remove_stopwords and word in self.stop_words:\n",
    "                continue\n",
    "\n",
    "            # Lemmatize\n",
    "            if self.lemmatize:\n",
    "                word = self.lemmatizer.lemmatize(word)\n",
    "\n",
    "            processed_words.append(word)\n",
    "\n",
    "        return processed_words\n",
    "\n",
    "    def preprocess_corpus(self, texts):\n",
    "        \"\"\"Preprocess entire corpus\"\"\"\n",
    "\n",
    "        all_sentences = []\n",
    "\n",
    "        for text in texts:\n",
    "            if not isinstance(text, str):\n",
    "                continue\n",
    "\n",
    "            # Clean text\n",
    "            cleaned_text = self.clean_text(text)\n",
    "\n",
    "            # Tokenize and process\n",
    "            processed = self.tokenize_text(cleaned_text)\n",
    "\n",
    "            if self.keep_sentences:\n",
    "                all_sentences.extend(processed)\n",
    "            else:\n",
    "                all_sentences.append(processed)\n",
    "\n",
    "        return all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b81f3-adeb-441b-b727-f35da412a55b",
   "metadata": {},
   "source": [
    "**What it does:**\n",
    "\n",
    "- **Cleans text**: Removes URLs, emails, extra spaces, and punctuation\n",
    "\n",
    "- **Converts to lowercase**: Makes all words consistent \n",
    "\n",
    "- **Tokenizes**: Splits text into sentences and individual words\n",
    "\n",
    "- **Filters words**: Removes very short/long words, numbers, and stopwords if needed\n",
    "\n",
    "- **Processes entire dataset**: Takes raw text and converts it into clean, organized sentences\n",
    "\n",
    "- **Customizable**: turn different cleaning options on/off\n",
    "\n",
    "**Result:** Transforms messy raw text like \"Alice's Adventures in Wonderland!\" into clean word lists like [\"alice\", \"adventures\", \"wonderland\"] that Word2Vec can effectively learn from. This preprocessing step is crucial for good Word2Vec performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b20243d-0896-4fe7-ac9d-88d4ce789873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2941 sentences\n",
      "Sample sentence: ['alice', 'adventures', 'in', 'wonderland']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "preprocessor = AdvancedTextPreprocessor(\n",
    "    lowercase=True,\n",
    "    remove_punctuation = True,\n",
    "    remove_numbers=True,\n",
    "    remove_stopwords=False,  # Keep stopwords for Word2Vec\n",
    "    lemmatize=False,  # Usually not needed for Word2Vec\n",
    "    keep_sentences=True\n",
    ")\n",
    "\n",
    "# Processing corpus\n",
    "processed_sentences = preprocessor.preprocess_corpus(texts)\n",
    "print(f\"Processed {len(processed_sentences)} sentences\")\n",
    "print(f\"Sample sentence: {processed_sentences[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0c09f-fc4b-47ca-b4f6-fc1475d36863",
   "metadata": {},
   "source": [
    "\n",
    "This code **creates a text preprocessor with specific settings and cleans the Alice in Wonderland text**.\n",
    "\n",
    "**What it does:**\n",
    "- **Creates preprocessor**: Sets up cleaning rules (lowercase, remove punctuation/numbers, keep stopwords)\n",
    "- **Processes your dataset**: Runs the preprocessor on the text\n",
    "- **Converts raw text**: Transforms messy text into clean sentences of word lists\n",
    "- **Shows results**: Displays how many sentences were processed and shows a sample cleaned sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9bf7bda-5143-418d-88c1-97c5cbfdcefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['alice', 'adventures', 'in', 'wonderland'],\n",
       " ['the', 'millennium', 'fulcrum', 'edition'],\n",
       " ['down', 'the', 'rabbithole']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ee4be-4863-4b57-bb25-0aca97183ff5",
   "metadata": {},
   "source": [
    "### **3.4 Training Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41c5a45b-9d16-4b05-ac4c-1813f89a5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_parameters(corpus_size, vocab_size, domain_type, computing_resources):\n",
    "    \"\"\"\n",
    "    Recommend Word2Vec parameters based on corpus characteristics\n",
    "\n",
    "    Args:\n",
    "        corpus_size: Number of sentences/documents\n",
    "        vocab_size: Unique words in vocabulary\n",
    "        domain_type: 'general', 'technical', 'social_media', 'academic'\n",
    "        computing_resources: 'limited', 'moderate', 'high'\n",
    "    \"\"\"\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    # Vector size based on corpus and vocab size\n",
    "    if corpus_size < 10000:\n",
    "        recommendations['vector_size'] = 50\n",
    "    elif corpus_size < 100000:\n",
    "        recommendations['vector_size'] = 100\n",
    "    elif corpus_size < 1000000:\n",
    "        recommendations['vector_size'] = 200\n",
    "    else:\n",
    "        recommendations['vector_size'] = 300\n",
    "\n",
    "    # Window size based on domain\n",
    "    domain_windows = {\n",
    "        'general': 5,\n",
    "        'technical': 3,  # More syntactic focus\n",
    "        'social_media': 4,\n",
    "        'academic': 6    # More semantic focus\n",
    "    }\n",
    "    recommendations['window'] = domain_windows.get(domain_type, 5)\n",
    "\n",
    "    # Min count based on corpus size\n",
    "    if corpus_size < 10000:\n",
    "        recommendations['min_count'] = 1\n",
    "    elif corpus_size < 100000:\n",
    "        recommendations['min_count'] = 2\n",
    "    elif corpus_size < 1000000:\n",
    "        recommendations['min_count'] = 5\n",
    "    else:\n",
    "        recommendations['min_count'] = 10\n",
    "\n",
    "    # Algorithm selection\n",
    "    if domain_type in ['technical', 'academic']:\n",
    "        recommendations['sg'] = 1  # Skip-gram for rare technical terms\n",
    "    else:\n",
    "        recommendations['sg'] = 0  # CBOW for general text\n",
    "\n",
    "    # Epochs based on corpus size and resources\n",
    "    if computing_resources == 'limited':\n",
    "        recommendations['epochs'] = 5\n",
    "    elif corpus_size < 100000:\n",
    "        recommendations['epochs'] = 15\n",
    "    else:\n",
    "        recommendations['epochs'] = 10\n",
    "\n",
    "    # Hierarchical softmax vs negative sampling\n",
    "    if vocab_size > 100000:\n",
    "        recommendations['hs'] = 1\n",
    "        recommendations['negative'] = 0\n",
    "    else:\n",
    "        recommendations['hs'] = 0\n",
    "        recommendations['negative'] = 10\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4cbcf-dd0d-4aa5-9366-624e0db0c851",
   "metadata": {},
   "source": [
    "\n",
    "This code **automatically suggests the best Word2Vec training settings** based on the dataset characteristics.\n",
    "\n",
    "**What it does:**\n",
    "- **Analyzes the data**: Takes corpus size, vocabulary size, text type, and computing power as input\n",
    "- **Recommends vector size**: Bigger datasets get higher-dimensional word vectors (50-300 dimensions)\n",
    "- **Sets window size**: How many surrounding words to consider (3-6 words)\n",
    "- **Chooses algorithm**: CBOW for general text, Skip-gram for technical/academic text\n",
    "- **Determines training time**: More epochs for smaller datasets, fewer for larger ones\n",
    "- **Optimizes performance**: Selects best training method based on vocabulary size\n",
    "\n",
    "**Result:** Instead of guessing Word2Vec parameters, we get smart recommendations tailored to  dataset - like \"use 100-dimension vectors, 5-word window, CBOW algorithm, 15 epochs\" for optimal training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5793ce6d-23a8-4d0f-808a-0b5bfbd3a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Size: 2941\n",
      "Vocabulary Size: 2519\n"
     ]
    }
   ],
   "source": [
    "corpus_size = len(processed_sentences)\n",
    "print(f\"Corpus Size: {corpus_size}\")\n",
    "\n",
    "# Calculate vocabulary size (unique words in vocabulary)\n",
    "vocab = set(word for sentence in processed_sentences for word in sentence)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7719410-4745-4935-99cd-a4fb8f420e96",
   "metadata": {},
   "source": [
    "- Calculates key statistics about processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac2f3839-d17f-4cf1-b3b2-2fad0a7cc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended parameters: {'vector_size': 50, 'window': 6, 'min_count': 1, 'sg': 1, 'epochs': 15, 'hs': 0, 'negative': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = recommend_parameters(\n",
    "    corpus_size=corpus_size,\n",
    "    vocab_size=vocab_size,\n",
    "    domain_type='academic',\n",
    "    computing_resources='moderate'\n",
    ")\n",
    "print(\"Recommended parameters:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b677a-1849-4117-976e-bf055d651e66",
   "metadata": {},
   "source": [
    "This code **gets personalized Word2Vec training recommendations** for the specific dataset.\n",
    "\n",
    "**What it does:**\n",
    "- **Uses data stats**: Takes actual corpus size and vocabulary size\n",
    "- **Sets domain type**: Specifies 'general' text (since Alice is general literature, not technical)\n",
    "- **Sets computing power**: Uses 'moderate' resources (standard laptop/desktop)\n",
    "- **Gets recommendations**: Returns optimal parameter settings tailored to your dataset\n",
    "- **Shows results**: Displays the recommended settings like vector size, window size, epochs, etc.\n",
    "\n",
    "**Result:** output like \"Recommended parameters: {'vector_size': 100, 'window': 5, 'min_count': 2, 'sg': 0, 'epochs': 15}\" - gives the perfect settings to train Word2Vec effectively on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77f41e-84b7-4a6f-9f74-c8a27c2e71ed",
   "metadata": {},
   "source": [
    "### **3.5 Step-by-Step Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04beb293-9f10-4454-8a95-77a2bdf60945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./lib/python3.9/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in ./lib/python3.9/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in ./lib/python3.9/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./lib/python3.9/site-packages (from gensim) (7.3.1)\n",
      "Requirement already satisfied: wrapt in ./lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f96074-a056-4c41-9bdf-abf6ec567306",
   "metadata": {},
   "source": [
    "**Gensim** is a Python library specifically designed for topic modeling and document similarity analysis. \n",
    "\n",
    "Main Purpose:\n",
    "\n",
    "- Processes large collections of text documents\n",
    "- Extracts semantic patterns and relationships between words\n",
    "- Creates mathematical representations of text meaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ccb511e-36e4-44ae-b49f-76535d4425c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import time\n",
    "import multiprocessing\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \"\"\"Callback to log information about training progress\"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.start_time = time.time()\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"Epoch #{self.epoch} start\")\n",
    "    def on_epoch_end(self, model):\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"Epoch #{self.epoch} end - Time elapsed: {elapsed:.2f}s\")\n",
    "        self.epoch += 1\n",
    "def train_word2vec_model(sentences, save_path=None, **params):\n",
    "    \"\"\"\n",
    "    Train Word2Vec model with given parameters\n",
    "    Args:\n",
    "        sentences: List of tokenized sentences\n",
    "        save_path: Path to save the model\n",
    "        **params: Word2Vec parameters\n",
    "    \"\"\"\n",
    "    # Set default parameters optimized for Alice in Wonderland dataset\n",
    "    default_params = {\n",
    "        'vector_size': 150,\n",
    "        'window': 8,\n",
    "        'min_count': 2,\n",
    "        'workers': multiprocessing.cpu_count() - 1,\n",
    "        'sg': 1,  # Skip-gram\n",
    "        'epochs': 50,\n",
    "        'alpha': 0.025,\n",
    "        'min_alpha': 0.0001,\n",
    "        'hs': 0,\n",
    "        'negative': 15\n",
    "    }\n",
    "    # Update with provided parameters\n",
    "    default_params.update(params)\n",
    "    print(\"Training Word2Vec model with parameters:\")\n",
    "    for key, value in default_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    # Add callback for progress monitoring\n",
    "    epoch_logger = EpochLogger()\n",
    "    # Train the model\n",
    "    print(f\"\\nTraining on {len(sentences)} sentences...\")\n",
    "    start_time = time.time()\n",
    "    model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        callbacks=[epoch_logger],\n",
    "        **default_params\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Vocabulary size: {len(model.wv)} words\")\n",
    "    # Save model if path provided\n",
    "    if save_path:\n",
    "        model.save(save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc3d8f-6d27-4bd4-b99a-35dbb1f32b1a",
   "metadata": {},
   "source": [
    "- Sets up the complete Word2Vec training infrastructure with progress monitoring and customizable parameters.\n",
    "\n",
    "- A complete Word2Vec training system that will show real-time progress as it learns word relationships from the dataset. When we call this function later, it will train the model and give detailed feedback about the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ab17e9f-3209-4ecd-92ba-8ca8f40da4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec model with parameters:\n",
      "  vector_size: 150\n",
      "  window: 8\n",
      "  min_count: 2\n",
      "  workers: 9\n",
      "  sg: 1\n",
      "  epochs: 50\n",
      "  alpha: 0.025\n",
      "  min_alpha: 0.0001\n",
      "  hs: 0\n",
      "  negative: 15\n",
      "  compute_loss: True\n",
      "\n",
      "Training on 2941 sentences...\n",
      "Epoch #0 start\n",
      "Epoch #0 end - Time elapsed: 0.07s\n",
      "Epoch #1 start\n",
      "Epoch #1 end - Time elapsed: 0.11s\n",
      "Epoch #2 start\n",
      "Epoch #2 end - Time elapsed: 0.16s\n",
      "Epoch #3 start\n",
      "Epoch #3 end - Time elapsed: 0.21s\n",
      "Epoch #4 start\n",
      "Epoch #4 end - Time elapsed: 0.26s\n",
      "Epoch #5 start\n",
      "Epoch #5 end - Time elapsed: 0.30s\n",
      "Epoch #6 start\n",
      "Epoch #6 end - Time elapsed: 0.35s\n",
      "Epoch #7 start\n",
      "Epoch #7 end - Time elapsed: 0.40s\n",
      "Epoch #8 start\n",
      "Epoch #8 end - Time elapsed: 0.45s\n",
      "Epoch #9 start\n",
      "Epoch #9 end - Time elapsed: 0.49s\n",
      "Epoch #10 start\n",
      "Epoch #10 end - Time elapsed: 0.54s\n",
      "Epoch #11 start\n",
      "Epoch #11 end - Time elapsed: 0.59s\n",
      "Epoch #12 start\n",
      "Epoch #12 end - Time elapsed: 0.64s\n",
      "Epoch #13 start\n",
      "Epoch #13 end - Time elapsed: 0.69s\n",
      "Epoch #14 start\n",
      "Epoch #14 end - Time elapsed: 0.74s\n",
      "Epoch #15 start\n",
      "Epoch #15 end - Time elapsed: 0.79s\n",
      "Epoch #16 start\n",
      "Epoch #16 end - Time elapsed: 0.83s\n",
      "Epoch #17 start\n",
      "Epoch #17 end - Time elapsed: 0.88s\n",
      "Epoch #18 start\n",
      "Epoch #18 end - Time elapsed: 0.93s\n",
      "Epoch #19 start\n",
      "Epoch #19 end - Time elapsed: 0.98s\n",
      "Epoch #20 start\n",
      "Epoch #20 end - Time elapsed: 1.03s\n",
      "Epoch #21 start\n",
      "Epoch #21 end - Time elapsed: 1.07s\n",
      "Epoch #22 start\n",
      "Epoch #22 end - Time elapsed: 1.12s\n",
      "Epoch #23 start\n",
      "Epoch #23 end - Time elapsed: 1.17s\n",
      "Epoch #24 start\n",
      "Epoch #24 end - Time elapsed: 1.22s\n",
      "Epoch #25 start\n",
      "Epoch #25 end - Time elapsed: 1.27s\n",
      "Epoch #26 start\n",
      "Epoch #26 end - Time elapsed: 1.31s\n",
      "Epoch #27 start\n",
      "Epoch #27 end - Time elapsed: 1.36s\n",
      "Epoch #28 start\n",
      "Epoch #28 end - Time elapsed: 1.41s\n",
      "Epoch #29 start\n",
      "Epoch #29 end - Time elapsed: 1.46s\n",
      "Epoch #30 start\n",
      "Epoch #30 end - Time elapsed: 1.51s\n",
      "Epoch #31 start\n",
      "Epoch #31 end - Time elapsed: 1.56s\n",
      "Epoch #32 start\n",
      "Epoch #32 end - Time elapsed: 1.61s\n",
      "Epoch #33 start\n",
      "Epoch #33 end - Time elapsed: 1.65s\n",
      "Epoch #34 start\n",
      "Epoch #34 end - Time elapsed: 1.70s\n",
      "Epoch #35 start\n",
      "Epoch #35 end - Time elapsed: 1.75s\n",
      "Epoch #36 start\n",
      "Epoch #36 end - Time elapsed: 1.80s\n",
      "Epoch #37 start\n",
      "Epoch #37 end - Time elapsed: 1.85s\n",
      "Epoch #38 start\n",
      "Epoch #38 end - Time elapsed: 1.89s\n",
      "Epoch #39 start\n",
      "Epoch #39 end - Time elapsed: 1.94s\n",
      "Epoch #40 start\n",
      "Epoch #40 end - Time elapsed: 1.99s\n",
      "Epoch #41 start\n",
      "Epoch #41 end - Time elapsed: 2.04s\n",
      "Epoch #42 start\n",
      "Epoch #42 end - Time elapsed: 2.08s\n",
      "Epoch #43 start\n",
      "Epoch #43 end - Time elapsed: 2.13s\n",
      "Epoch #44 start\n",
      "Epoch #44 end - Time elapsed: 2.18s\n",
      "Epoch #45 start\n",
      "Epoch #45 end - Time elapsed: 2.23s\n",
      "Epoch #46 start\n",
      "Epoch #46 end - Time elapsed: 2.28s\n",
      "Epoch #47 start\n",
      "Epoch #47 end - Time elapsed: 2.32s\n",
      "Epoch #48 start\n",
      "Epoch #48 end - Time elapsed: 2.37s\n",
      "Epoch #49 start\n",
      "Epoch #49 end - Time elapsed: 2.42s\n",
      "\n",
      "Training completed in 2.42 seconds\n",
      "Vocabulary size: 1396 words\n",
      "Model saved to my_word2vec_model.model\n"
     ]
    }
   ],
   "source": [
    "# Example usage optimized for Alice in Wonderland dataset\n",
    "model = train_word2vec_model(\n",
    "    sentences=processed_sentences,\n",
    "    save_path='my_word2vec_model.model',\n",
    "    vector_size=150,\n",
    "    window=8,\n",
    "    min_count=2,\n",
    "    epochs=50,\n",
    "    sg=1,\n",
    "    negative=15,\n",
    "    compute_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad9156-b306-4f43-8b45-f6d941668776",
   "metadata": {},
   "source": [
    "- Trains the model on the dataset using the training function defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60bdc9ba-676a-48f6-bfe3-85e81c715c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 1396\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(model.wv.index_to_key)\n",
    "print(\"Vocabulary Size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e3442-dac5-4bdb-b58d-33bc12e8cbde",
   "metadata": {},
   "source": [
    "- Checks how many unique words trained Word2Vec model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "884740b3-f199-4be0-a3a2-67a35aa0fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Words in Vocabulary: ['the', 'and', 'to', 'it', 'she', 'of', 'said', 'you', 'in', 'was']\n"
     ]
    }
   ],
   "source": [
    "all_words = model.wv.index_to_key\n",
    "print(\"All Words in Vocabulary:\", all_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7901893-0c7f-4aa4-ae76-db33d5fefacd",
   "metadata": {},
   "source": [
    "### **3.6 Model Evaluation and Validation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ead98127-e9b7-43d9-8bfb-bad029ba607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class Word2VecEvaluator:\n",
    "    \"\"\"Comprehensive evaluation suite for Word2Vec models\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.wv = model.wv\n",
    "\n",
    "    def evaluate_word_similarity(self, word_pairs_with_scores):\n",
    "        \"\"\"\n",
    "        Evaluate model on word similarity datasets\n",
    "\n",
    "        Args:\n",
    "            word_pairs_with_scores: List of tuples (word1, word2, human_score)\n",
    "\n",
    "        Returns:\n",
    "            Spearman correlation with human judgments\n",
    "        \"\"\"\n",
    "\n",
    "        model_similarities = []\n",
    "        human_similarities = []\n",
    "\n",
    "        for word1, word2, human_score in word_pairs_with_scores:\n",
    "            try:\n",
    "                model_sim = self.wv.similarity(word1, word2)\n",
    "                model_similarities.append(model_sim)\n",
    "                human_similarities.append(human_score)\n",
    "            except KeyError:\n",
    "                # Skip if words not in vocabulary\n",
    "                continue\n",
    "\n",
    "        if len(model_similarities) < 3:\n",
    "            print(\"Warning: Too few valid word pairs for reliable evaluation\")\n",
    "            return None\n",
    "\n",
    "        correlation, p_value = spearmanr(human_similarities, model_similarities)\n",
    "\n",
    "        print(f\"Word Similarity Evaluation:\")\n",
    "        print(f\"Valid pairs: {len(model_similarities)}\")\n",
    "        print(f\"Spearman correlation: {correlation:.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "        return correlation\n",
    "\n",
    "    def evaluate_analogies(self, analogy_dataset):\n",
    "        \"\"\"\n",
    "        Evaluate model on word analogy tasks\n",
    "\n",
    "        Args:\n",
    "            analogy_dataset: List of tuples (word_a, word_b, word_c, word_d)\n",
    "                           representing \"word_a is to word_b as word_c is to word_d\"\n",
    "\n",
    "        Returns:\n",
    "            Accuracy on analogy task\n",
    "        \"\"\"\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        #('alice', 'girl', 'rabbit', 'animal'),\n",
    "        for word_a, word_b, word_c, expected_d in analogy_dataset:\n",
    "            try:\n",
    "                # Predict word_d\n",
    "                result = self.wv.most_similar(\n",
    "                    positive=[word_b, word_c],\n",
    "                    negative=[word_a],\n",
    "                    topn=1\n",
    "                )\n",
    "\n",
    "                predicted_d = result\n",
    "\n",
    "                if predicted_d[0][0].lower() == expected_d.lower():\n",
    "                    correct += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "            except (KeyError, IndexError):\n",
    "                # Skip if words not in vocabulary\n",
    "                continue\n",
    "\n",
    "        if total == 0:\n",
    "            print(\"Warning: No valid analogies found\")\n",
    "            return 0\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f\"Analogy Evaluation:\")\n",
    "        print(f\"Valid analogies: {total}\")\n",
    "        print(f\"Correct predictions: {correct}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def evaluate_odd_one_out(self, word_groups):\n",
    "        \"\"\"\n",
    "        Evaluate model's ability to identify odd words in groups\n",
    "\n",
    "        Args:\n",
    "            word_groups: List of lists, each containing words where one doesn't belong\n",
    "\n",
    "        Returns:\n",
    "            Accuracy on odd-one-out task\n",
    "        \"\"\"\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for group in word_groups:\n",
    "            if len(group) < 3:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Find the word that doesn't match others\n",
    "                odd_word = self.wv.doesnt_match(group)\n",
    "\n",
    "                # This is tricky - we need ground truth to evaluate properly\n",
    "                # For now, just check if the model can identify AN odd word\n",
    "                correct += 1  # Placeholder - you'd need labeled data\n",
    "                total += 1\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        if total == 0:\n",
    "            return 0\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f\"Odd-One-Out Evaluation:\")\n",
    "        print(f\"  Valid groups: {total}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def analyze_vocabulary_coverage(self, test_texts):\n",
    "        \"\"\"\n",
    "        Analyze how well model vocabulary covers test texts\n",
    "\n",
    "        Args:\n",
    "            test_texts: List of text strings\n",
    "\n",
    "        Returns:\n",
    "            Coverage statistics\n",
    "        \"\"\"\n",
    "\n",
    "        vocab = set(self.wv.index_to_key)\n",
    "\n",
    "        total_words = 0\n",
    "        covered_words = 0\n",
    "        unknown_words = set()\n",
    "\n",
    "        for text in test_texts:\n",
    "            words = text.lower().split()\n",
    "            total_words += len(words)\n",
    "\n",
    "            for word in words:\n",
    "                if word in vocab:\n",
    "                    covered_words += 1\n",
    "                else:\n",
    "                    unknown_words.add(word)\n",
    "\n",
    "        coverage_ratio = covered_words / total_words if total_words > 0 else 0\n",
    "\n",
    "        print(f\"Vocabulary Coverage Analysis:\")\n",
    "        print(f\"  Total words in test: {total_words}\")\n",
    "        print(f\"  Covered words: {covered_words}\")\n",
    "        print(f\"  Coverage ratio: {coverage_ratio:.4f}\")\n",
    "        print(f\"  Unknown words: {len(unknown_words)}\")\n",
    "\n",
    "        return {\n",
    "            'coverage_ratio': coverage_ratio,\n",
    "            'unknown_words': list(unknown_words)[:20],  # Show first 20\n",
    "            'total_unknown': len(unknown_words)\n",
    "        }\n",
    "\n",
    "    def compare_with_baseline(self, baseline_model, test_words):\n",
    "        \"\"\"\n",
    "        Compare model performance with baseline model\n",
    "\n",
    "        Args:\n",
    "            baseline_model: Another Word2Vec model to compare against\n",
    "            test_words: List of words to test\n",
    "\n",
    "        Returns:\n",
    "            Comparison statistics\n",
    "        \"\"\"\n",
    "\n",
    "        common_words = []\n",
    "        for word in test_words:\n",
    "            if word in self.wv and word in baseline_model.wv:\n",
    "                common_words.append(word)\n",
    "\n",
    "        if len(common_words) < 3:\n",
    "            print(\"Warning: Too few common words for reliable comparison\")\n",
    "            return None\n",
    "\n",
    "        # Compare similarity patterns\n",
    "        similarities = []\n",
    "\n",
    "        for i, word1 in enumerate(common_words[:10]):  # Test subset\n",
    "            for word2 in common_words[i+1:11]:  # Avoid too many comparisons\n",
    "\n",
    "                sim1 = self.wv.similarity(word1, word2)\n",
    "                sim2 = baseline_model.wv.similarity(word1, word2)\n",
    "\n",
    "                similarities.append((sim1, sim2))\n",
    "\n",
    "        model_sims = [s[0] for s in similarities]\n",
    "        baseline_sims = [s[1] for s in similarities]\n",
    "\n",
    "        correlation, _ = spearmanr(model_sims, baseline_sims)\n",
    "\n",
    "        print(f\"Model Comparison:\")\n",
    "        print(f\"  Common vocabulary: {len(common_words)}\")\n",
    "        print(f\"  Similarity correlation: {correlation:.4f}\")\n",
    "\n",
    "        return correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50020e3d-058a-45ce-ba27-1ac50301933f",
   "metadata": {},
   "source": [
    "- Creates a comprehensive evaluation toolkit that tests how well the model performs across different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9095893-566c-4261-9321-3805657e2ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Similarity Evaluation:\n",
      "Valid pairs: 4\n",
      "Spearman correlation: 0.4000\n",
      "P-value: 0.6000\n",
      "Analogy Evaluation:\n",
      "Valid analogies: 3\n",
      "Correct predictions: 1\n",
      "Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Example evaluation datasets optimized for Alice in Wonderland\n",
    "word_similarity_pairs = [\n",
    "    ('alice', 'girl', 8.5),\n",
    "    ('rabbit', 'hare', 9.2),\n",
    "    ('queen', 'king', 8.3),\n",
    "    ('mad', 'crazy', 7.8),\n",
    "    ('tea', 'party', 6.1),\n",
    "    ('big', 'small', 2.1),\n",
    "]\n",
    "\n",
    "analogy_examples = [\n",
    "    ('alice', 'girl', 'rabbit', 'animal'),\n",
    "    ('queen', 'hearts', 'king', 'hearts'),\n",
    "    ('big', 'bigger', 'small', 'smaller'),\n",
    "    ('mad', 'hatter', 'march', 'hare'),\n",
    "]\n",
    "\n",
    "# Usage example\n",
    "evaluator = Word2VecEvaluator(model)\n",
    "sim_score = evaluator.evaluate_word_similarity(word_similarity_pairs)\n",
    "analogy_score = evaluator.evaluate_analogies(analogy_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e30225-ec0f-40bc-a64d-db895405c8df",
   "metadata": {},
   "source": [
    "- Creates improved evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8aee9453-8a69-4ec9-9efc-f6b830d942b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'alice':\n",
      "uncomfortable: 0.5413\n",
      "she: 0.5239\n",
      "grave: 0.4982\n",
      "thoughtfully: 0.4899\n",
      "cautiously: 0.4886\n",
      "quickly: 0.4841\n",
      "pleaded: 0.4795\n",
      "feelings: 0.4762\n",
      "proud: 0.4733\n",
      "absurd: 0.4728\n"
     ]
    }
   ],
   "source": [
    "word = \"alice\"\n",
    "if word in model.wv:\n",
    "    similar_words = model.wv.most_similar(word, topn=10)\n",
    "    print(f\"Most similar words to '{word}':\")\n",
    "    for similar_word, similarity in similar_words:\n",
    "        print(f\"{similar_word}: {similarity:.4f}\")\n",
    "else:\n",
    "    print(\"Word is not in the vocabulary.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31b143-d38a-44b4-9fab-030ca85f376e",
   "metadata": {},
   "source": [
    " - Tests if the word \"alice\" exists in your model and shows the 10 most similar words to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ee3cc88-3c89-4da4-8028-0eb35dd9c9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2926585"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('alice', 'rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c82640-68ce-4628-9d4a-d363a31678ac",
   "metadata": {},
   "source": [
    "- Calculates the direct similarity score between the words \"alice\" and \"rabbit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a307f6-9075-40c6-9f3f-bfa75878f396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
